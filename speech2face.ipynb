{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech2face.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "822c9fc1731147428533ce670255f767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8a759ded0c0b4d1ba0fbf6fad2777466",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1d63a8aa18f147eeada7e5031d261c37",
              "IPY_MODEL_5196440ff7624c7dab9af8212d77ef23"
            ]
          }
        },
        "8a759ded0c0b4d1ba0fbf6fad2777466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d63a8aa18f147eeada7e5031d261c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7a410a2061b54e15b7119e5ac156da13",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c00d9824851447898c3867a8b232d227"
          }
        },
        "5196440ff7624c7dab9af8212d77ef23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b516697e8e9c4d2fbe273d62d7d0b7e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:31&lt;00:00, 17.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c33380f62b14cfa9b9fa462eb33f048"
          }
        },
        "7a410a2061b54e15b7119e5ac156da13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c00d9824851447898c3867a8b232d227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b516697e8e9c4d2fbe273d62d7d0b7e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c33380f62b14cfa9b9fa462eb33f048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rnjsdn12332/speech2face/blob/main/speech2face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFmlfrqjQ6pR",
        "outputId": "07996d71-9850-40a6-b8f7-6ecba1513405"
      },
      "source": [
        "!pip install pytube moviepy youtube_dl #pytube 영상 저장 , moviepy : 비디오처리 youtube_dl : 유튜브 다운"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytube\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/2e/92c42ac4fd8b702bb9fcac5a61bcb9740506376008aaa2c2093f6cbf4cb6/pytube-10.9.2-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (0.2.3.5)\n",
            "Collecting youtube_dl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/43/1f586e49e68f8b41c4be416302bf96ddd5040b0e744b5902d51063795eb9/youtube_dl-2021.6.6-py2.py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 12.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.41.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from moviepy) (1.19.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy) (2.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.1.2)\n",
            "Installing collected packages: pytube, youtube-dl\n",
            "Successfully installed pytube-10.9.2 youtube-dl-2021.6.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2m0EmfWRZYD",
        "outputId": "1d0dbc61-3a81-4f77-f12b-73a8a5858a81"
      },
      "source": [
        "!pip install opencv-python dlib torchvision #dlib : 얼굴 검출"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.7/dist-packages (19.18.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchvision) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj-D2EJ_RkCb",
        "outputId": "cb1b242d-6a08-4751-c556-5c18036dc19c"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHvRwujKRvS7",
        "outputId": "b243e494-a072-4f1e-d227-2f69a1679ac6"
      },
      "source": [
        "!pip install face_recognition\n",
        "import cv2\n",
        "import face_recognition\n",
        "import torch \n",
        "from torch import nn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Using cached https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566184 sha256=23057d932e41395b1a608d3d55131c9f26a658763773e47c9e0722f98282f5be\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kGVq3wCR29b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a92804-82a3-452e-c9d3-eb93b3c85c2b"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms,models\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import youtube_dl\n",
        "import moviepy.editor as mp\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import librosa\n",
        "import dlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3506176/45929032 bytes (7.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6782976/45929032 bytes (14.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b10641408/45929032 bytes (23.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b14606336/45929032 bytes (31.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b18317312/45929032 bytes (39.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b22290432/45929032 bytes (48.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b26132480/45929032 bytes (56.9%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b30162944/45929032 bytes (65.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b34037760/45929032 bytes (74.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b37928960/45929032 bytes (82.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41697280/45929032 bytes (90.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45506560/45929032 bytes (99.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seiMuQEmR85g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4cb1624-6964-4a6f-f3f6-cf5c59ecb285"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVQr-Kjl7s4P"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgQojs7h3u-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db80a8b-a4d4-492a-ad7d-8b9d9ad88d0a"
      },
      "source": [
        "! wget http://dlib.net/files/mmod_human_face_detector.dat.bz2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-18 06:10:25--  http://dlib.net/files/mmod_human_face_detector.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 694709 (678K)\n",
            "Saving to: ‘mmod_human_face_detector.dat.bz2’\n",
            "\n",
            "\r          mmod_huma   0%[                    ]       0  --.-KB/s               \rmmod_human_face_det 100%[===================>] 678.43K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-07-18 06:10:25 (18.7 MB/s) - ‘mmod_human_face_detector.dat.bz2’ saved [694709/694709]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgNOW9EV8kzD"
      },
      "source": [
        "!bzip2 -dk mmod_human_face_detector.dat.bz2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZwUsYhW8tbO"
      },
      "source": [
        "%rm mmod_human_face_detector.dat.bz2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo6HQEgBdzKm"
      },
      "source": [
        "cnn_face_detector = dlib.cnn_face_detection_model_v1(\"/content/mmod_human_face_detector.dat\")\n",
        "hog_face_detector = dlib.get_frontal_face_detector()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7FHcQgF44d9"
      },
      "source": [
        "# 얼굴 추출 함수\n",
        "def extract_face(frame): \n",
        "  \n",
        "    faces_cnn = cnn_face_detector(frame, 2)\n",
        "\n",
        "    x,y,w,h = 0,0,0,0\n",
        "    for face in faces_cnn:\n",
        "        \n",
        "        x = face.rect.left()\n",
        "        y = face.rect.top()\n",
        "        w = face.rect.right() - x\n",
        "        h = face.rect.bottom() - y\n",
        "\n",
        "    if (x<=0 or y<=0 or w<=0 or h<=0):\n",
        "        return None\n",
        "\n",
        "    frame = frame[y:y + h,x:x+w]\n",
        "    return frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCxlLmMt5AEo"
      },
      "source": [
        "# vgg 모델 생성\n",
        "def create_vgg_model() : \n",
        "\n",
        "    PATH = \"http://www.robots.ox.ac.uk/~albanie/models/pytorch-mcn/vgg_face_dag.pth\"\n",
        "    PATH2 = \"http://www.robots.ox.ac.uk/~albanie/models/pytorch-mcn/vgg_m_face_bn_dag.pth\"\n",
        "    model = models.vgg16(pretrained=PATH)\n",
        "    layers = list(model.classifier.children())\n",
        "    #print(layers)\n",
        "    layers.pop()\n",
        "    layers.pop()\n",
        "    new_classifier = torch.nn.Sequential(*layers)\n",
        "    model.classifier = new_classifier\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el9-LAMz5A17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "822c9fc1731147428533ce670255f767",
            "8a759ded0c0b4d1ba0fbf6fad2777466",
            "1d63a8aa18f147eeada7e5031d261c37",
            "5196440ff7624c7dab9af8212d77ef23",
            "7a410a2061b54e15b7119e5ac156da13",
            "c00d9824851447898c3867a8b232d227",
            "b516697e8e9c4d2fbe273d62d7d0b7e7",
            "8c33380f62b14cfa9b9fa462eb33f048"
          ]
        },
        "outputId": "a8d0fdba-51fb-4726-b30d-5a09de66244b"
      },
      "source": [
        "vgg_model = create_vgg_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "822c9fc1731147428533ce670255f767",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuZGJeD05DXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5376e3d0-fd9e-4a4b-8250-2cae968115c2"
      },
      "source": [
        "vgg_model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGC2Sxqt5FIh"
      },
      "source": [
        "for param in vgg_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nge5TVD85I7X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff455389-ef63-41c0-8207-97a1e6e5ee51"
      },
      "source": [
        "vgg_model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8sM3Mec5OFv"
      },
      "source": [
        "얼굴 이미지 쉐이프 조정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8inyIOn5Lyj"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EpboXVj5XqC"
      },
      "source": [
        "배치에 사용할 이미지 특징 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5pjUt7L5Td7"
      },
      "source": [
        "#이미지 특징 검출\n",
        "\n",
        "def extract_image_features(image_path_list):\n",
        "\n",
        "\n",
        "    face_batch = []\n",
        "\n",
        "    for image_path in image_path_list: \n",
        "        frame = Image.open(image_path)\n",
        "    \n",
        "        frame_arr = np.asarray(frame) \n",
        "        face_arr = extract_face(frame_arr)\n",
        "\n",
        "    if(face_arr is None):\n",
        "        return None\n",
        "\n",
        "    face = Image.fromarray(np.uint8(face_arr)).convert('RGB') #넘파이 배열을 PIL 이미지로 변환\n",
        "    \n",
        "    face_tensor = transform(face) #이미지 조정(텐서 + 리사이즈)\n",
        "   \n",
        "    face_batch.append(face_tensor.numpy()) #다시 넘파이로 변환한 값 리스트에 추가\n",
        "  \n",
        "\n",
        "    face_batch = torch.tensor(face_batch).to(device)\n",
        "   \n",
        "    face_features = vgg_model(face_batch)\n",
        "\n",
        "    return face_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRr7ycFT5x7w"
      },
      "source": [
        "#텐서로 변환한 페이스 배치 리턴\n",
        "def extract_faces_features(image_path_list):\n",
        "    face_batch = []\n",
        "\n",
        "    for image_path in image_path_list: \n",
        "\n",
        "        frame = Image.open(image_path)\n",
        "  \n",
        "        frame_arr = np.asarray(frame)\n",
        "        face_arr = extract_face(frame_arr)\n",
        "    if(face_arr is None):\n",
        "        return None\n",
        "\n",
        "    face = Image.fromarray(np.uint8(face_arr)).convert('RGB')\n",
        "    #face = Image.fromarray(face_arr)\n",
        "    face_tensor = transform(face)\n",
        "    #print(face_tensor.shape)\n",
        "    face_batch.append(face_tensor.numpy())\n",
        "    #print(face_tensor.device)\n",
        "\n",
        "    face_batch = torch.tensor(face_batch).to(device)\n",
        "    return face_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQQXjjAA6Eho"
      },
      "source": [
        "\n",
        "def get_spectrogram(audio_path):\n",
        "\n",
        "  wav_file , sr = librosa.load(audio_path,sr = 16000, duration = 6.0 ,mono = True) #wav_file은 파형의 amplitude, sr은 sampling rate\n",
        "  stft = librosa.core.stft(wav_file, n_fft = 512, hop_length = int(np.ceil(0.01 * sr)),win_length = int(np.ceil(0.025 * sr)) , window='hann', center=True,pad_mode='reflect')\n",
        "  #stft는 스펙트로그램\n",
        "\n",
        "  if stft.shape[1] < 598:\n",
        "    stft = np.concatenate((stft,stft[:,0:598 - stft.shape[1]]),axis = 1)\n",
        "  else:\n",
        "    stft = stft[:,:598]\n",
        "\n",
        "  real = np.sign(stft.real) * ( np.abs(stft.real) ** 0.3 )\n",
        "  imag = np.sign(stft.imag) * ( np.abs(stft.imag) ** 0.3 )\n",
        "\n",
        "  stft = np.stack((real,imag),axis=-1)\n",
        "  \n",
        "  return stft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVMhJyQd6Qli"
      },
      "source": [
        "class AudioEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(2, 32, kernel_size=(4,4) , stride=(1,1) )\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(4,4) , stride=(1,1) )\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=(4,4) , stride=(1,1) )\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d((2,1),stride=(2,1))\n",
        "\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=(4,4) , stride=(1,1) )\n",
        "        self.bn4 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d((2,1),stride=(2,1))\n",
        "\n",
        "        self.conv5 = nn.Conv2d(64, 64, kernel_size=(4,4) , stride=(1,1) )\n",
        "        self.bn5 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d((2,1),stride=(2,1))\n",
        "\n",
        "        self.conv6 = nn.Conv2d(64, 128, kernel_size=(4,4) , stride=(1,1) )\n",
        "        self.bn6 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.pool4 = nn.MaxPool2d((2,1),stride=(2,1))\n",
        "\n",
        "        self.conv7 = nn.Conv2d(128, 256, kernel_size=(4,4) , stride=(1,1) )\n",
        "        self.bn7 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv8 = nn.Conv2d(256, 256, kernel_size=(4,4) , stride=(2,2) )\n",
        "        self.bn8 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv9 = nn.Conv2d(256, 256, kernel_size=(4,4) , stride=(2,2) )\n",
        "\n",
        "        self.avg1  = nn.AvgPool2d((1,1),1)\n",
        "        self.bn9 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        #self.fc1 = nn.Linear(419328,256)\n",
        "        self.fc1 = nn.Linear(87552,256)\n",
        "        self.fc2 = nn.Linear(256,1024)\n",
        "        self.fc3 = nn.Linear(1024,4096)\n",
        "        self.fc4 = nn.Linear(4096,4096)\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        x = self.bn1(F.relu(self.conv1(x)))\n",
        "        #print(x.shape)\n",
        "        x = self.bn2(F.relu(self.conv2(x)))\n",
        "        #print(x.shape)\n",
        "        x = self.bn3(F.relu(self.conv3(x)))\n",
        "        #print(x.shape)\n",
        "\n",
        "        x = self.pool1(x)\n",
        "        #print(x.shape)\n",
        "\n",
        "        x = self.bn4(F.relu(self.conv4(x)))\n",
        "        #print(x.shape)\n",
        "        x = self.pool2(x)\n",
        "        #print(x.shape)\n",
        "\n",
        "        x = self.bn5(F.relu(self.conv5(x)))\n",
        "        #print(x.shape)\n",
        "        x = self.pool3(x)\n",
        "        #print(x.shape)\n",
        "\n",
        "        x = self.bn6(F.relu(self.conv6(x)))\n",
        "        #print(x.shape)\n",
        "        x = self.pool4(x)\n",
        "        #print(x.shape)\n",
        "\n",
        "        x = self.bn7(F.relu(self.conv7(x)))\n",
        "        #print(x.shape)\n",
        "        x = self.bn8(F.relu(self.conv8(x)))\n",
        "        #print(x.shape)\n",
        "        x = self.conv9(x)\n",
        "        #print(x.shape)\n",
        "\n",
        "        x = self.bn9(F.relu(self.avg1(x)))\n",
        "        #print(x.shape)\n",
        "        x = self.flatten(x)\n",
        "        #print(x.shape)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        #print(x.shape)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        #print(x.shape)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        #print(x.shape)\n",
        "        x = self.fc4(x)\n",
        "        #print(x.shape)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7pP1KZJ6zza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71cffb94-d1cc-4ad5-bbaa-c2cd67329fae"
      },
      "source": [
        "audio_encoder = AudioEncoder()\n",
        "audio_encoder.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AudioEncoder(\n",
              "  (conv1): Conv2d(2, 32, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(32, 32, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool1): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv4): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool2): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv5): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv6): Conv2d(64, 128, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool4): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv7): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv8): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2))\n",
              "  (bn8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv9): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2))\n",
              "  (avg1): AvgPool2d(kernel_size=(1, 1), stride=1, padding=0)\n",
              "  (bn9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=87552, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=1024, bias=True)\n",
              "  (fc3): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "  (fc4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRe4Ht9X6tnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa4b90e-0944-4610-ead6-af614a190c69"
      },
      "source": [
        "for p in audio_encoder.parameters():\n",
        "\n",
        "  if p.requires_grad:\n",
        "    print(p.numel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1024\n",
            "32\n",
            "32\n",
            "32\n",
            "16384\n",
            "32\n",
            "32\n",
            "32\n",
            "32768\n",
            "64\n",
            "64\n",
            "64\n",
            "65536\n",
            "64\n",
            "64\n",
            "64\n",
            "65536\n",
            "64\n",
            "64\n",
            "64\n",
            "131072\n",
            "128\n",
            "128\n",
            "128\n",
            "524288\n",
            "256\n",
            "256\n",
            "256\n",
            "1048576\n",
            "256\n",
            "256\n",
            "256\n",
            "1048576\n",
            "256\n",
            "256\n",
            "256\n",
            "22413312\n",
            "256\n",
            "262144\n",
            "1024\n",
            "4194304\n",
            "4096\n",
            "16777216\n",
            "4096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6xqZR6v62VR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17079191-6b6e-40dd-92d7-ae317d849265"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "count_parameters(audio_encoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46593664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9En-S0Pc64tb"
      },
      "source": [
        "root_dir_path = '/content'\n",
        "path = os.path.join(root_dir_path,'images')\n",
        "os.mkdir(path)\n",
        "path = os.path.join(root_dir_path,'videos')\n",
        "os.mkdir(path)\n",
        "path = os.path.join(root_dir_path,'audios')\n",
        "os.mkdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJjKgqs3ANVl"
      },
      "source": [
        "root_dir_path = '/content'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctz99jub66qZ"
      },
      "source": [
        "\n",
        "def extract_frame(id,start,end):\n",
        "\n",
        "  video_path = root_dir_path + '/videos/' + id + '.mp4'\n",
        "  image_path = root_dir_path + '/images/' + id + '.jpg'\n",
        "\n",
        "  clip = mp.VideoFileClip(video_path)\n",
        "  dur = clip.duration\n",
        "  end = min(end,dur)\n",
        "  if(start>=end):\n",
        "    return\n",
        "\n",
        "  clip = clip.subclip(start, end)\n",
        "  \n",
        "  clip.save_frame(image_path, t = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guASnRx768px"
      },
      "source": [
        "\n",
        "def extract_audio(id,start,end):\n",
        "\n",
        "  video_path = root_dir_path + '/videos/' + id + '.mp4'\n",
        "  audio_path = root_dir_path + '/audios/' + id + '.wav'\n",
        "\n",
        "  clip = mp.VideoFileClip(video_path)\n",
        "  dur = clip.duration\n",
        "  end = min(end,dur)\n",
        "  if (start >= end):\n",
        "    print('start more than video total length')\n",
        "    return None\n",
        "    \n",
        "  clip = clip.subclip(start, end)\n",
        "  \n",
        "  clip.audio.write_audiofile(audio_path)\n",
        "\n",
        "  stft = get_spectrogram(audio_path)\n",
        "\n",
        "  return stft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEdQ6OY96-kJ"
      },
      "source": [
        "ydl_opts = {'format': 'best' , 'outtmpl':'/content/videos/%(id)s.mp4'}\n",
        "ydl = youtube_dl.YoutubeDL(ydl_opts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-v6DHm1_TUt"
      },
      "source": [
        "def download_video(id,start,end):\n",
        "\n",
        "  video_link=\"https://www.youtube.com/watch?v=\" + id \n",
        "  #print(video_link)\n",
        "  try: \n",
        "      ydl.download([video_link.strip()])\n",
        "  except: \n",
        "    print('error in downloading videos')\n",
        "    return\n",
        "\n",
        "  stft = extract_audio(id,start,end)\n",
        "  if (stft is None):\n",
        "    print('stft is none')\n",
        "    return None\n",
        "  extract_frame(id,start,end)\n",
        "  video_path = '/content/videos/' + id + '.mp4'\n",
        "  %rm $video_path\n",
        "  return stft"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz4WiBu07Cg8"
      },
      "source": [
        "데이터셋\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ekVZrBm7B1t"
      },
      "source": [
        "file = pd.read_csv('/content/drive/MyDrive/avspeech_csv/avspeech_test.csv',names=['id','start','end','X','Y'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHW0EaADPcVq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukN1qsOa-0Qj"
      },
      "source": [
        "def preprocess_data(batch_no , batch_size , reference = False):\n",
        "\n",
        "\n",
        "  spectrogram_dict = {}\n",
        "  image_path_list = []\n",
        "\n",
        "  for i in range(batch_no*batch_size , (batch_no+1)*batch_size):\n",
        "    id , start , end , X ,Y = file.iloc[i]\n",
        "\n",
        "    spectrogram = download_video(id,start,end)\n",
        "\n",
        "    if (spectrogram is None):\n",
        "            continue\n",
        "\n",
        "    if (type(spectrogram) == np.ndarray):\n",
        "      spectrogram_dict[id] = spectrogram\n",
        "\n",
        "      path = '/content/images/' + id + '.jpg'\n",
        "      image_path_list.append(path)\n",
        "    \n",
        "  image_features = extract_image_features(image_path_list)\n",
        "    #return\n",
        "  if (image_features is None or image_features.shape[0] != len(spectrogram_dict.keys())):\n",
        "      return\n",
        "\n",
        "  if (reference):\n",
        "      image_feat_file = '/content/reference/vgg_image_features_' + str(batch_no)\n",
        "  else:  \n",
        "      image_feat_file = '/content/vgg_image_features_' + str(batch_no)\n",
        "\n",
        "  torch.save(image_features,image_feat_file)\n",
        "  if (reference):\n",
        "      spec_pickle_file = '/content/reference/spectrograms_' + str(batch_no) + '.pk' \n",
        "  else:\n",
        "      spec_pickle_file = '/content/spectrograms_' + str(batch_no) + '.pk' \n",
        "\n",
        "  f = open(spec_pickle_file, 'wb')\n",
        "  pickle.dump(spectrogram_dict, f)\n",
        "  f.close()\n",
        "\n",
        "  if (reference) :\n",
        "    for image_path in image_path_list:\n",
        "      image_id = image_path.split('/content/images/')[1]\n",
        "      drive_path = '/content/reference/' + image_id\n",
        "\n",
        "      %mv $image_path $drive_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnNPKWEM_GXu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37365bc4-50e6-4dd7-9f22-74923b256fdc"
      },
      "source": [
        "train_size = 10000\n",
        "batch_size = 10\n",
        "n_batches = int(train_size / batch_size)\n",
        "\n",
        "for i in range(1002,1100):\n",
        "\n",
        "  preprocess_data(i,batch_size,True)\n",
        "  #break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[download]  41.5% of 100.58MiB at 40.52KiB/s ETA 24:46error in downloading videos\n",
            "[youtube] B-aIq_36MAQ: Downloading webpage\n",
            "[download] Destination: /content/videos/B-aIq_36MAQ.mp4\n",
            "[download] 100% of 53.35MiB in 00:01\n",
            "[MoviePy] Writing audio in /content/audios/B-aIq_36MAQ.wav\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 322/322 [00:00<00:00, 2354.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[youtube] M3A9SNadRcY: Downloading webpage\n",
            "[download] Destination: /content/videos/M3A9SNadRcY.mp4\n",
            "[download]  24.3% of 192.88MiB at  2.16MiB/s ETA 01:07error in downloading videos\n",
            "[youtube] lNGtzaocsAA: Downloading webpage\n",
            "[download] Destination: /content/videos/lNGtzaocsAA.mp4\n",
            "[download] 100% of 167.41MiB in 00:06\n",
            "[MoviePy] Writing audio in /content/audios/lNGtzaocsAA.wav\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 67/67 [00:00<00:00, 505.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[youtube] IrXRtlkG6A4: Downloading webpage\n",
            "[download] Destination: /content/videos/IrXRtlkG6A4.mp4\n",
            "[download] 100% of 78.65MiB in 00:05\n",
            "[MoviePy] Writing audio in /content/audios/IrXRtlkG6A4.wav\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 67/67 [00:00<00:00, 1132.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[youtube] -nZq0E39E34: Downloading webpage\n",
            "[youtube] -nZq0E39E34: Downloading MPD manifest\n",
            "[download] Destination: /content/videos/-nZq0E39E34.mp4\n",
            "[download]   6.0% of 55.43MiB at 59.28KiB/s ETA 14:59error in downloading videos\n",
            "[youtube] jyDpmNK1C3o: Downloading webpage\n",
            "[download] Destination: /content/videos/jyDpmNK1C3o.mp4\n",
            "[download] 100% of 37.35MiB in 00:03\n",
            "[MoviePy] Writing audio in /content/audios/jyDpmNK1C3o.wav\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 78/78 [00:00<00:00, 573.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[youtube] lR6FSKOaRRM: Downloading webpage\n",
            "[download] Destination: /content/videos/lR6FSKOaRRM.mp4\n",
            "[download] 100% of 80.05MiB in 00:01\n",
            "[MoviePy] Writing audio in /content/audios/lR6FSKOaRRM.wav\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 289/289 [00:00<00:00, 2202.06it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[youtube] jSeN7rsynks: Downloading webpage\n",
            "[download] Destination: /content/videos/jSeN7rsynks.mp4\n",
            "[download] 100% of 76.38MiB in 00:14\n",
            "[MoviePy] Writing audio in /content/audios/jSeN7rsynks.wav\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 125/125 [00:00<00:00, 1579.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[MoviePy] Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[youtube] __1fNpsZC_U: Downloading webpage\n",
            "[download] Destination: /content/videos/__1fNpsZC_U.mp4\n",
            "[download] 100% of 25.57MiB in 00:00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-23f035db96a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1002\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;31m#break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-aecb265e3447>\u001b[0m in \u001b[0;36mpreprocess_data\u001b[0;34m(batch_no, batch_size, reference)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mid\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mspectrogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mspectrogram\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-c7c5e810b9ba>\u001b[0m in \u001b[0;36mdownload_video\u001b[0;34m(id, start, end)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mstft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstft\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stft is none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-175604985448>\u001b[0m in \u001b[0;36mextract_audio\u001b[0;34m(id, start, end)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_audiofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-149>\u001b[0m in \u001b[0;36msubclip\u001b[0;34m(self, t_start, t_end)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-148>\u001b[0m in \u001b[0;36msubclip\u001b[0;34m(self, t_start, t_end)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mapply_to_mask\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     27\u001b[0m         the clip created with f \"\"\"\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnewclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mnewclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-147>\u001b[0m in \u001b[0;36msubclip\u001b[0;34m(self, t_start, t_end)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mapply_to_audio\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     39\u001b[0m         the clip created with f \"\"\"\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'audio'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnewclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mnewclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36msubclip\u001b[0;34m(self, t_start, t_end)\u001b[0m\n\u001b[1;32m    389\u001b[0m                              \"duration (%.02f).\" % self.duration)\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt_end\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduration\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mfl_time\u001b[0;34m(self, t_func, apply_to, keep_duration)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         return self.fl(lambda gf, t: gf(t_func(t)), apply_to,\n\u001b[0;32m--> 190\u001b[0;31m                        keep_duration=keep_duration)\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mfl\u001b[0;34m(self, fun, apply_to, keep_duration)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-171>\u001b[0m in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36moutplace\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"\"\" Applies f(clip.copy(), *a, **k) and returns clip.copy()\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnewclip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \"\"\"\n\u001b[1;32m    668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moutplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-124>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mapply_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         return self.fl(lambda gf, t: gf(t_func(t)), apply_to,\n\u001b[0m\u001b[1;32m    190\u001b[0m                        keep_duration=keep_duration)\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-124>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/video/io/VideoFileClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# Make a reader for the audio, if any.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/video/io/ffmpeg_reader.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/moviepy/video/io/ffmpeg_reader.py\u001b[0m in \u001b[0;36mread_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mnbytes\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qbX6_miBKVW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "19be63bf-4257-4eec-dc72-233c4a42fb03"
      },
      "source": [
        "f = open('/content/drive/MyDrive/spectrograms_811.pk','rb')\n",
        "d = pickle.load(f)\n",
        "x = torch.te"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-6b942fcacd1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/spectrograms_811.pk'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/spectrograms_811.pk'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS_B_wbu7KbM",
        "outputId": "4c42dccb-a5a9-453c-bc64-49666298a78f"
      },
      "source": [
        "import shutil\n",
        "def convert_spectrogram() :\n",
        "  path_wav='/content/audios/'\n",
        "  file_list=os.listdir(path_wav)\n",
        "  file_list.sort()\n",
        "  print(file_list)\n",
        "\n",
        "  path_img='/content/images/'\n",
        "  file_list2=os.listdir(path_img)\n",
        "  file_list2.sort()\n",
        "  print(file_list2)\n",
        "\n",
        "  for i in range(len(file_list)) : \n",
        "    audio_path=path_wav+file_list[i]\n",
        "    spectrogram=get_spectrogram(audio_path)\n",
        "\n",
        "    spec_pickle_file = './reference/spectrograms_' + str(i) + '.pk' \n",
        "\n",
        "    f = open(spec_pickle_file, 'wb')\n",
        "    pickle.dump(spectrogram, f)\n",
        "    f.close()\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "convert_spectrogram()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['-BpOTjCxfYk.wav', '07KxzYP1NV8.wav', '0CYkVREA0Ow.wav', '0PUSmVK5izI.wav', '0XNF-595fz8.wav', '25r47NR9U2A.wav', '2OqdDTMIevU.wav', '4KFTacxqkcQ.wav', '4h02Hi0NvhY.wav', '5Lkc6vNFm18.wav', '6nuo6RuvjgI.wav', '7W_oDZHjCUI.wav', '7YcCwbTDQ7I.wav', '8sGAnPbkYiU.wav', '9nVTJabDh4Y.wav', 'AQctpzKey8k.wav', 'B-aIq_36MAQ.wav', 'B12cakJGWX0.wav', 'B2Fi1Ev8ivg.wav', 'BND-NOAfn44.wav', 'C1D3PJEwE3s.wav', 'C_6NPCmuegg.wav', 'DF0yEsDHKSs.wav', 'DJcTM_AocNE.wav', 'DznoRk27Jdg.wav', 'EjkoVOXNZqU.wav', 'FTkmxeuNBf4.wav', 'FdRp7GHrcVU.wav', 'GkR_FUincaw.wav', 'H6hYLZpfP_c.wav', 'I-JTrsszeaw.wav', 'I5LO2DPPy8Q.wav', 'IazyrSKQTo0.wav', 'IfHH2FdDzeY.wav', 'IrXRtlkG6A4.wav', 'JF_5q7HHYS4.wav', 'LiggtFXbiN8.wav', 'NSqFG0mXr5I.wav', 'NdI0bcPvH38.wav', 'Np9lMxFWJLU.wav', 'O5D-K6Qi-sg.wav', 'Pf0uaiPM104.wav', 'PtonUAFO-8s.wav', 'Qvz5sWmE19Y.wav', 'R6WaIkjVuXc.wav', 'Ru5V5isGoiY.wav', 'SrJw3gKJT_Y.wav', 'WC8AJ7Xn_pA.wav', 'ZI21I8xy2Ow.wav', '_RNovsn3cIM.wav', '_RueBPvH6ig.wav', '_etkmhZnL-c.wav', 'af8_9BRSG2E.wav', 'atVf8oqMSLw.wav', 'ck9Ra0MBSOs.wav', 'dFu4t5yGKfI.wav', 'dawLndLXnbM.wav', 'gbQgoAOHVZs.wav', 'h5BpEQW5uUA.wav', 'i7GnTmrf_cY.wav', 'ilMWKlTJMc0.wav', 'isF4AOQCMAk.wav', 'j7GV6zBlm-s.wav', 'jSeN7rsynks.wav', 'jcdpVfGHaG0.wav', 'jyDpmNK1C3o.wav', 'keezuPz4iO4.wav', 'kov2ZHrA04w.wav', 'lNGtzaocsAA.wav', 'lOc4P8ZN_vM.wav', 'lR6FSKOaRRM.wav', 'nDvuNlYeKaM.wav', 'nlIGPlKIOpU.wav', 'q946yP0qNq8.wav', 'sHSiC973JQ4.wav', 'sUX0ORtpfd4.wav', 'tiXabRd6GRo.wav', 'u9a_8x5p3QM.wav', 'ucpBrJjOCCg.wav', 'w9YkmluWDg4.wav', 'x_imtjYsg2A.wav', 'xb5NF1toj_U.wav', 'ydTXf9zp7XE.wav', 'z0JbaKdmEJs.wav', 'zYA9RHNAiVk.wav', 'zxrU96LQGWo.wav']\n",
            "['-BpOTjCxfYk.jpg', '07KxzYP1NV8.jpg', '0CYkVREA0Ow.jpg', '0PUSmVK5izI.jpg', '0XNF-595fz8.jpg', '25r47NR9U2A.jpg', '2OqdDTMIevU.jpg', '4KFTacxqkcQ.jpg', '4h02Hi0NvhY.jpg', '5Lkc6vNFm18.jpg', '6nuo6RuvjgI.jpg', '7W_oDZHjCUI.jpg', '7YcCwbTDQ7I.jpg', '8sGAnPbkYiU.jpg', '9nVTJabDh4Y.jpg', 'AQctpzKey8k.jpg', 'B-aIq_36MAQ.jpg', 'B12cakJGWX0.jpg', 'B2Fi1Ev8ivg.jpg', 'BND-NOAfn44.jpg', 'C1D3PJEwE3s.jpg', 'C_6NPCmuegg.jpg', 'DF0yEsDHKSs.jpg', 'DJcTM_AocNE.jpg', 'DznoRk27Jdg.jpg', 'EjkoVOXNZqU.jpg', 'FTkmxeuNBf4.jpg', 'FdRp7GHrcVU.jpg', 'GkR_FUincaw.jpg', 'H6hYLZpfP_c.jpg', 'I-JTrsszeaw.jpg', 'I5LO2DPPy8Q.jpg', 'IazyrSKQTo0.jpg', 'IfHH2FdDzeY.jpg', 'IrXRtlkG6A4.jpg', 'JF_5q7HHYS4.jpg', 'LiggtFXbiN8.jpg', 'NSqFG0mXr5I.jpg', 'NdI0bcPvH38.jpg', 'Np9lMxFWJLU.jpg', 'O5D-K6Qi-sg.jpg', 'Pf0uaiPM104.jpg', 'PtonUAFO-8s.jpg', 'Qvz5sWmE19Y.jpg', 'R6WaIkjVuXc.jpg', 'Ru5V5isGoiY.jpg', 'SrJw3gKJT_Y.jpg', 'WC8AJ7Xn_pA.jpg', 'ZI21I8xy2Ow.jpg', '_RNovsn3cIM.jpg', '_RueBPvH6ig.jpg', '_etkmhZnL-c.jpg', 'af8_9BRSG2E.jpg', 'atVf8oqMSLw.jpg', 'ck9Ra0MBSOs.jpg', 'dFu4t5yGKfI.jpg', 'dawLndLXnbM.jpg', 'gbQgoAOHVZs.jpg', 'h5BpEQW5uUA.jpg', 'i7GnTmrf_cY.jpg', 'ilMWKlTJMc0.jpg', 'isF4AOQCMAk.jpg', 'j7GV6zBlm-s.jpg', 'jSeN7rsynks.jpg', 'jcdpVfGHaG0.jpg', 'jyDpmNK1C3o.jpg', 'keezuPz4iO4.jpg', 'kov2ZHrA04w.jpg', 'lNGtzaocsAA.jpg', 'lOc4P8ZN_vM.jpg', 'lR6FSKOaRRM.jpg', 'nDvuNlYeKaM.jpg', 'nlIGPlKIOpU.jpg', 'q946yP0qNq8.jpg', 'sHSiC973JQ4.jpg', 'sUX0ORtpfd4.jpg', 'tiXabRd6GRo.jpg', 'u9a_8x5p3QM.jpg', 'ucpBrJjOCCg.jpg', 'w9YkmluWDg4.jpg', 'x_imtjYsg2A.jpg', 'xb5NF1toj_U.jpg', 'ydTXf9zp7XE.jpg', 'z0JbaKdmEJs.jpg', 'zYA9RHNAiVk.jpg', 'zxrU96LQGWo.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_XCP_FuCUCk",
        "outputId": "62343438-b6f7-4a95-893e-460984dae8b0"
      },
      "source": [
        "import shutil\n",
        "def move_spectrogram() :\n",
        "  path_ref='/content/reference/'\n",
        "  file_list=os.listdir(path_ref)\n",
        "  file_list.sort()\n",
        "  print(file_list)\n",
        "\n",
        "  path_img='/content/images/'\n",
        "  file_list2=os.listdir(path_img)\n",
        "  file_list2.sort()\n",
        "  print(file_list2)\n",
        "\n",
        "  for i in range(len(file_list)) : \n",
        "    path1=path_ref+file_list[i]\n",
        "    path2='/content/drive/MyDrive/reference/spectrogram'\n",
        "\n",
        "    shutil.move(path1, path2)\n",
        "\n",
        "\n",
        "  \n",
        "move_spectrogram()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['spectrograms_0.pk', 'spectrograms_1.pk', 'spectrograms_10.pk', 'spectrograms_11.pk', 'spectrograms_12.pk', 'spectrograms_13.pk', 'spectrograms_14.pk', 'spectrograms_15.pk', 'spectrograms_16.pk', 'spectrograms_17.pk', 'spectrograms_18.pk', 'spectrograms_19.pk', 'spectrograms_2.pk', 'spectrograms_20.pk', 'spectrograms_21.pk', 'spectrograms_22.pk', 'spectrograms_23.pk', 'spectrograms_24.pk', 'spectrograms_25.pk', 'spectrograms_26.pk', 'spectrograms_27.pk', 'spectrograms_28.pk', 'spectrograms_29.pk', 'spectrograms_3.pk', 'spectrograms_30.pk', 'spectrograms_31.pk', 'spectrograms_32.pk', 'spectrograms_33.pk', 'spectrograms_34.pk', 'spectrograms_35.pk', 'spectrograms_36.pk', 'spectrograms_37.pk', 'spectrograms_38.pk', 'spectrograms_39.pk', 'spectrograms_4.pk', 'spectrograms_40.pk', 'spectrograms_41.pk', 'spectrograms_42.pk', 'spectrograms_43.pk', 'spectrograms_44.pk', 'spectrograms_45.pk', 'spectrograms_46.pk', 'spectrograms_47.pk', 'spectrograms_48.pk', 'spectrograms_49.pk', 'spectrograms_5.pk', 'spectrograms_50.pk', 'spectrograms_51.pk', 'spectrograms_52.pk', 'spectrograms_53.pk', 'spectrograms_54.pk', 'spectrograms_55.pk', 'spectrograms_56.pk', 'spectrograms_57.pk', 'spectrograms_58.pk', 'spectrograms_59.pk', 'spectrograms_6.pk', 'spectrograms_60.pk', 'spectrograms_61.pk', 'spectrograms_62.pk', 'spectrograms_63.pk', 'spectrograms_64.pk', 'spectrograms_65.pk', 'spectrograms_66.pk', 'spectrograms_67.pk', 'spectrograms_68.pk', 'spectrograms_69.pk', 'spectrograms_7.pk', 'spectrograms_70.pk', 'spectrograms_71.pk', 'spectrograms_72.pk', 'spectrograms_73.pk', 'spectrograms_74.pk', 'spectrograms_75.pk', 'spectrograms_76.pk', 'spectrograms_77.pk', 'spectrograms_78.pk', 'spectrograms_79.pk', 'spectrograms_8.pk', 'spectrograms_80.pk', 'spectrograms_81.pk', 'spectrograms_82.pk', 'spectrograms_83.pk', 'spectrograms_84.pk', 'spectrograms_85.pk', 'spectrograms_9.pk']\n",
            "['-BpOTjCxfYk.jpg', '07KxzYP1NV8.jpg', '0CYkVREA0Ow.jpg', '0PUSmVK5izI.jpg', '0XNF-595fz8.jpg', '25r47NR9U2A.jpg', '2OqdDTMIevU.jpg', '4KFTacxqkcQ.jpg', '4h02Hi0NvhY.jpg', '5Lkc6vNFm18.jpg', '6nuo6RuvjgI.jpg', '7W_oDZHjCUI.jpg', '7YcCwbTDQ7I.jpg', '8sGAnPbkYiU.jpg', '9nVTJabDh4Y.jpg', 'AQctpzKey8k.jpg', 'B-aIq_36MAQ.jpg', 'B12cakJGWX0.jpg', 'B2Fi1Ev8ivg.jpg', 'BND-NOAfn44.jpg', 'C1D3PJEwE3s.jpg', 'C_6NPCmuegg.jpg', 'DF0yEsDHKSs.jpg', 'DJcTM_AocNE.jpg', 'DznoRk27Jdg.jpg', 'EjkoVOXNZqU.jpg', 'FTkmxeuNBf4.jpg', 'FdRp7GHrcVU.jpg', 'GkR_FUincaw.jpg', 'H6hYLZpfP_c.jpg', 'I-JTrsszeaw.jpg', 'I5LO2DPPy8Q.jpg', 'IazyrSKQTo0.jpg', 'IfHH2FdDzeY.jpg', 'IrXRtlkG6A4.jpg', 'JF_5q7HHYS4.jpg', 'LiggtFXbiN8.jpg', 'NSqFG0mXr5I.jpg', 'NdI0bcPvH38.jpg', 'Np9lMxFWJLU.jpg', 'O5D-K6Qi-sg.jpg', 'Pf0uaiPM104.jpg', 'PtonUAFO-8s.jpg', 'Qvz5sWmE19Y.jpg', 'R6WaIkjVuXc.jpg', 'Ru5V5isGoiY.jpg', 'SrJw3gKJT_Y.jpg', 'WC8AJ7Xn_pA.jpg', 'ZI21I8xy2Ow.jpg', '_RNovsn3cIM.jpg', '_RueBPvH6ig.jpg', '_etkmhZnL-c.jpg', 'af8_9BRSG2E.jpg', 'atVf8oqMSLw.jpg', 'ck9Ra0MBSOs.jpg', 'dFu4t5yGKfI.jpg', 'dawLndLXnbM.jpg', 'gbQgoAOHVZs.jpg', 'h5BpEQW5uUA.jpg', 'i7GnTmrf_cY.jpg', 'ilMWKlTJMc0.jpg', 'isF4AOQCMAk.jpg', 'j7GV6zBlm-s.jpg', 'jSeN7rsynks.jpg', 'jcdpVfGHaG0.jpg', 'jyDpmNK1C3o.jpg', 'keezuPz4iO4.jpg', 'kov2ZHrA04w.jpg', 'lNGtzaocsAA.jpg', 'lOc4P8ZN_vM.jpg', 'lR6FSKOaRRM.jpg', 'nDvuNlYeKaM.jpg', 'nlIGPlKIOpU.jpg', 'q946yP0qNq8.jpg', 'sHSiC973JQ4.jpg', 'sUX0ORtpfd4.jpg', 'tiXabRd6GRo.jpg', 'u9a_8x5p3QM.jpg', 'ucpBrJjOCCg.jpg', 'w9YkmluWDg4.jpg', 'x_imtjYsg2A.jpg', 'xb5NF1toj_U.jpg', 'ydTXf9zp7XE.jpg', 'z0JbaKdmEJs.jpg', 'zYA9RHNAiVk.jpg', 'zxrU96LQGWo.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hV-d3hsC_nE",
        "outputId": "b516db23-4697-4bae-f621-bc28143c8e45"
      },
      "source": [
        "import shutil\n",
        "def move_img() :\n",
        "  path_img='/content/drive/MyDrive/reference/'\n",
        "  file_list2=os.listdir(path_img)\n",
        "  file_list2.sort()\n",
        "  print(file_list2)\n",
        "\n",
        "  \n",
        "  for i in range(len(file_list2)) : \n",
        "    path1=path_img+file_list2[i]\n",
        "    path2='/content/drive/MyDrive/reference/'+str(i)+'.jpg'\n",
        "\n",
        "    shutil.move(path1, path2)\n",
        "\n",
        "\n",
        "  \n",
        "move_img()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['-BpOTjCxfYk.jpg', '07KxzYP1NV8.jpg', '0CYkVREA0Ow.jpg', '0PUSmVK5izI.jpg', '0XNF-595fz8.jpg', '25r47NR9U2A.jpg', '2OqdDTMIevU.jpg', '4KFTacxqkcQ.jpg', '4h02Hi0NvhY.jpg', '5Lkc6vNFm18.jpg', '6nuo6RuvjgI.jpg', '7W_oDZHjCUI.jpg', '7YcCwbTDQ7I.jpg', '8sGAnPbkYiU.jpg', '9nVTJabDh4Y.jpg', 'AQctpzKey8k.jpg', 'B-aIq_36MAQ.jpg', 'B12cakJGWX0.jpg', 'B2Fi1Ev8ivg.jpg', 'BND-NOAfn44.jpg', 'C1D3PJEwE3s.jpg', 'C_6NPCmuegg.jpg', 'DF0yEsDHKSs.jpg', 'DJcTM_AocNE.jpg', 'DznoRk27Jdg.jpg', 'EjkoVOXNZqU.jpg', 'FTkmxeuNBf4.jpg', 'FdRp7GHrcVU.jpg', 'GkR_FUincaw.jpg', 'H6hYLZpfP_c.jpg', 'I-JTrsszeaw.jpg', 'I5LO2DPPy8Q.jpg', 'IazyrSKQTo0.jpg', 'IfHH2FdDzeY.jpg', 'IrXRtlkG6A4.jpg', 'JF_5q7HHYS4.jpg', 'LiggtFXbiN8.jpg', 'NSqFG0mXr5I.jpg', 'NdI0bcPvH38.jpg', 'Np9lMxFWJLU.jpg', 'O5D-K6Qi-sg.jpg', 'Pf0uaiPM104.jpg', 'PtonUAFO-8s.jpg', 'Qvz5sWmE19Y.jpg', 'R6WaIkjVuXc.jpg', 'Ru5V5isGoiY.jpg', 'SrJw3gKJT_Y.jpg', 'WC8AJ7Xn_pA.jpg', 'ZI21I8xy2Ow.jpg', '_RNovsn3cIM.jpg', '_RueBPvH6ig.jpg', '_etkmhZnL-c.jpg', 'af8_9BRSG2E.jpg', 'atVf8oqMSLw.jpg', 'ck9Ra0MBSOs.jpg', 'dFu4t5yGKfI.jpg', 'dawLndLXnbM.jpg', 'gbQgoAOHVZs.jpg', 'h5BpEQW5uUA.jpg', 'i7GnTmrf_cY.jpg', 'ilMWKlTJMc0.jpg', 'isF4AOQCMAk.jpg', 'j7GV6zBlm-s.jpg', 'jSeN7rsynks.jpg', 'jcdpVfGHaG0.jpg', 'jyDpmNK1C3o.jpg', 'keezuPz4iO4.jpg', 'kov2ZHrA04w.jpg', 'lNGtzaocsAA.jpg', 'lOc4P8ZN_vM.jpg', 'lR6FSKOaRRM.jpg', 'nDvuNlYeKaM.jpg', 'nlIGPlKIOpU.jpg', 'q946yP0qNq8.jpg', 'sHSiC973JQ4.jpg', 'sUX0ORtpfd4.jpg', 'tiXabRd6GRo.jpg', 'u9a_8x5p3QM.jpg', 'ucpBrJjOCCg.jpg', 'w9YkmluWDg4.jpg', 'x_imtjYsg2A.jpg', 'xb5NF1toj_U.jpg', 'ydTXf9zp7XE.jpg', 'z0JbaKdmEJs.jpg', 'zYA9RHNAiVk.jpg', 'zxrU96LQGWo.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UqMa2UmFCbt"
      },
      "source": [
        "def vgg_img() :\n",
        "  path_img='/content/drive/MyDrive/reference/'\n",
        "  file_list2=os.listdir(path_img)\n",
        "  file_list2.sort()\n",
        "  image_path_list=[]\n",
        "\n",
        "  for i in range(len(file_list2)) :\n",
        "    image_path=path_img + file_list2[i]\n",
        "    image_path_list.append(image_path)\n",
        "    image_features = extract_image_features(image_path_list)\n",
        "    image_feat_file = '/content/drive/MyDrive/vgg/vgg_image_features_' + str(i)\n",
        "    torch.save(image_features,image_feat_file)\n",
        "\n",
        "\n",
        "vgg_img() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLwqzjbR6VnG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyhRm3FrBvNI"
      },
      "source": [
        "def contrastive_loss(a,b):\n",
        "  \n",
        "\n",
        "\n",
        "  a = torch.div(a,a.norm(dim=1).reshape(-1,1).tile((4096,)))\n",
        "  b = torch.div(b,b.norm(dim=1).reshape(-1,1).tile((4096,)))\n",
        "\n",
        "  c = torch.matmul(a,b.transpose(0,1))\n",
        "\n",
        "  c = torch.exp(c)\n",
        "\n",
        "  loss = 0\n",
        "  #print(c.shape)\n",
        "  for i in range(c.shape[1]):\n",
        "\n",
        "    sum = torch.sum(c[i])\n",
        "  #  print(sum.shape)\n",
        "    sum = torch.div(c[i][i],sum)\n",
        "   # print(sum.shape)\n",
        "    logit = torch.log(sum)\n",
        "  #  print(logit.shape)\n",
        "    loss += logit\n",
        "\n",
        "  return (-1.0/c.shape[0])*loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtbpI0dBBwaY"
      },
      "source": [
        "def l1_dist(a,b):\n",
        "\n",
        "  a = torch.div(a,a.norm(dim=1).reshape(-1,1).tile((4096,)))\n",
        "  b = torch.div(b,b.norm(dim=1).reshape(-1,1).tile((4096,)))\n",
        "\n",
        "  dist = torch.abs(a - b)\n",
        "  dist = dist.sum(1).mean()\n",
        "\n",
        "  return dist\n",
        "\n",
        "def l2_dist(a,b):\n",
        "\n",
        "  a = torch.div(a,a.norm(dim=1).reshape(-1,1).tile((4096,)))\n",
        "  b = torch.div(b,b.norm(dim=1).reshape(-1,1).tile((4096,)))\n",
        "\n",
        "  dist = (a-b)**2\n",
        "  dist = dist.sum(1).sqrt().mean()\n",
        "\n",
        "  return dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtl2a18DBzYL"
      },
      "source": [
        "def Loss1(a,b,device):\n",
        "  #a = torch.div( a, torch.norm(a))\n",
        "  #b = torch.div( b, torch.norm(b))\n",
        "  a.to(device)\n",
        "  b.to(device)\n",
        "\n",
        "  a = torch.div(a,a.norm(dim=1).reshape(-1,1).tile((4096,)))\n",
        "  b = torch.div(b,b.norm(dim=1).reshape(-1,1).tile((4096,)))\n",
        "  #print(a.shape,b.shape)\n",
        "  loss = torch.sum((a - b)**2, dim=1)\n",
        "  #print(loss.sum())nemani\n",
        "  return loss.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3Id7S5qB3ZW"
      },
      "source": [
        "def Loss2(a,b,device):\n",
        "  a.to(device)\n",
        "  b.to(device)\n",
        "  a = torch.div(a,2)\n",
        "  b = torch.div(b,2)\n",
        "  softmax = nn.Softmax(dim=1)\n",
        "  log_softmax = nn.LogSoftmax(dim=1)\n",
        "  #print(softmax(a).sum(dim=1),log_softmax(b).shape)\n",
        "  loss = torch.sum( -softmax(a) * log_softmax(b) , dim=1)\n",
        "  #print(loss.shape)\n",
        "  return loss.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGwBYnMyB4-Y"
      },
      "source": [
        "#audio_encoder.load_state_dict(torch.load('/content/drive/MyDrive/Audio_Encoder/model_weights_epoch_17_lr0.00001_reduced_norm.pt'))\n",
        "#audio_encoder.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IYC233-CEFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aee4e91-598c-4b43-eec4-960bb2f68c14"
      },
      "source": [
        "audio_encoder.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AudioEncoder(\n",
              "  (conv1): Conv2d(2, 32, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(32, 32, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool1): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv4): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool2): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv5): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv6): Conv2d(64, 128, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool4): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv7): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv8): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2))\n",
              "  (bn8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv9): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2))\n",
              "  (avg1): AvgPool2d(kernel_size=(1, 1), stride=1, padding=0)\n",
              "  (bn9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=87552, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=1024, bias=True)\n",
              "  (fc3): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "  (fc4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXhzGfwTCExP"
      },
      "source": [
        "l1_loss = torch.nn.L1Loss(reduction='sum').to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnheKI-5CR_R"
      },
      "source": [
        "#device = 'cpu'\n",
        "mse_loss = torch.nn.MSELoss(reduction='sum').to(device)\n",
        "#l1_loss = torch.nn.L1Loss(reduction='sum').to(device)\n",
        "optimizer = torch.optim.Adam(audio_encoder.parameters(),lr=1e-5 , weight_decay=1e-5)\n",
        "cosine_similarity = torch.nn.CosineSimilarity().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axT_oVe-CVfJ"
      },
      "source": [
        "def extract_vgg_features_decoder(image_path_list):\n",
        "\n",
        "  face_batch = []\n",
        "\n",
        "  for image_path in image_path_list: \n",
        "\n",
        "    frame = Image.open(image_path)\n",
        "    \n",
        "    frame_arr = np.asarray(frame)\n",
        "    face_arr = extract_face(frame_arr)\n",
        "\n",
        "    if(face_arr is None):\n",
        "      return None\n",
        "\n",
        "    face = Image.fromarray(np.uint8(frame_arr)).convert('RGB')\n",
        "    #face = Image.fromarray(frame_arr)\n",
        "    face_tensor = transform(face)\n",
        "    #print(\n",
        "\n",
        "    face_batch.append(face_tensor.numpy())\n",
        "    #print(face_tensor.device)\n",
        "\n",
        "  face_batch = torch.tensor(face_batch).to(device)\n",
        "  #print(face_batch.shape)\n",
        "  #return face_batch\n",
        "  vgg_features = vgg_model(face_batch)\n",
        "\n",
        "  return vgg_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8ja3aZHCZgI"
      },
      "source": [
        "def testing():\n",
        "\n",
        "  epochs = 1100\n",
        "  total_l2_distance = 0\n",
        "  total_l1_distance = 0\n",
        "  total_cosine_similarity = 0\n",
        "  batches = 0\n",
        "  total_examples = 0\n",
        "  total_loss = 0\n",
        "  audio_encoder.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for i in range(0,86):\n",
        "\n",
        "      try:\n",
        "        f = open('/content/drive/MyDrive/reference/spectrograms_'+str(i)+'.pk','rb')\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "      spec_dict = pickle.load(f)\n",
        "      \n",
        "      X = torch.tensor([np.transpose(spec_dict,(2,1,0))])\n",
        "      \n",
        "      y = torch.load('/content/drive/MyDrive/reference/vgg_image_features_'+str(i))\n",
        "      #y = y.to('cpu')\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "      #print(X.shape , y.shape)\n",
        "      y_pred = audio_encoder.forward(X)\n",
        "   \n",
        "\n",
        "      assert(y.shape == y_pred.shape)\n",
        "      loss = Loss1(y,y_pred,device) + mse_loss(y,y_pred)\n",
        "      l2_distance = l2_dist(y,y_pred)\n",
        "      total_loss += loss.item()\n",
        "      cosine_sim = cosine_similarity(y,y_pred).mean()\n",
        "      \n",
        "      #print(cosine_sim)\n",
        "      l1_distance = l1_dist(y,y_pred)\n",
        "\n",
        "      #print(loss.item())\n",
        "      batches += 1\n",
        "      total_l2_distance += l2_distance.item()\n",
        "      total_l1_distance += l1_distance.item()\n",
        "      total_cosine_similarity += cosine_sim.item()\n",
        "      total_examples += X.shape[0]\n",
        "\n",
        "      if(batches%20 == 0):\n",
        "        print('Current Batch is {} Loss is {} -L2 distance is : {}  L1 distance is : {} Cosine similarity is : {}'.format(batches,total_loss/batches , total_l2_distance/batches, total_l1_distance/batches,total_cosine_similarity/batches))\n",
        "        \n",
        "  print('*******************Test**************')\n",
        "  print('total batches processed : {}'.format(batches))\n",
        "  print('total examples processed : {}'.format(total_examples))\n",
        "  print('L2 loss is : {}'.format(total_l2_distance/batches))\n",
        "  print('L1 loss is : {}'.format(total_l1_distance/batches))\n",
        "  print('cosine similarity is : {}'.format(total_cosine_similarity/batches))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICj-6UKPCjRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b2228ee-7c19-41e6-c50c-b78c431ebdf9"
      },
      "source": [
        "epochs = 1000\n",
        "\n",
        "\n",
        "for x in range(20):\n",
        "  audio_encoder.train()\n",
        "  total_mse_loss = 0\n",
        "  #total_l1_loss = 0\n",
        "  total_l2_distance = 0\n",
        "  total_l1_distance = 0\n",
        "  total_cosine_similarity = 0\n",
        "  batches = 0\n",
        "  total_examples = 0\n",
        "\n",
        "  for i in range(86):\n",
        "\n",
        "    try:\n",
        "      f = open('/content/drive/MyDrive/spectrogram/spectrograms_'+str(i)+'.pk','rb')\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "    spec_dict = pickle.load(f)\n",
        "    X = torch.tensor([np.transpose(spec_dict,(2,1,0)) ])\n",
        "    \n",
        "    y = torch.load('/content/drive/MyDrive/vgg/vgg_image_features_'+str(i))\n",
        "\n",
        "    X = X[:].to(device)\n",
        "    y = y[:].to(device)\n",
        " \n",
        "    y_pred = audio_encoder.forward(X)\n",
        "\n",
        "    assert(y.shape == y_pred.shape)\n",
        "\n",
        "    loss = Loss1(y,y_pred,device)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      l1_distance = l1_dist(y,y_pred)\n",
        "      l2_distance = l2_dist(y,y_pred)\n",
        "      cosine_sim = cosine_similarity(y,y_pred).mean()\n",
        "      total_l1_distance += l1_distance.item()\n",
        "      total_l2_distance += l2_distance.item()\n",
        "      total_cosine_similarity += cosine_sim\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        " \n",
        "    batches += 1\n",
        "    total_mse_loss += loss.item()\n",
        "    \n",
        "    \n",
        "    total_examples += X.shape[0]\n",
        "\n",
        "    if(batches%50 == 0):\n",
        "      print('Current Batch is {} - loss is : {} and L2 distance is : {}  L1 distance is : {} Cosine similarity is : {}'.format(batches,total_mse_loss/batches , l2_distance, l1_distance , cosine_sim))\n",
        "\n",
        "  \n",
        "\n",
        "  print(\"Training EPOCH : \",x)\n",
        "  print('total batches processed : {}'.format(batches))\n",
        "  print('total examples processed : {}'.format(total_examples))\n",
        "  print('Total loss is : {}'.format(total_mse_loss/batches))\n",
        "  print('L2 distance is : {}'.format(total_l2_distance/batches))\n",
        "  print('L1 distance is : {}'.format(total_l1_distance/batches))\n",
        "  print('Cosine Similarity is : {}'.format(total_cosine_similarity/batches))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Batch is 50 - loss is : 1.4837388873100281 and L2 distance is : 0.9028978943824768  L1 distance is : 40.9581298828125 Cosine similarity is : 0.5923877358436584\n",
            "Training EPOCH :  0\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 1.165231729316157\n",
            "L2 distance is : 1.0565345578415448\n",
            "L1 distance is : 47.021176626515945\n",
            "Cosine Similarity is : 0.4173841178417206\n",
            "Current Batch is 50 - loss is : 0.5849627137184144 and L2 distance is : 0.583713948726654  L1 distance is : 21.627758026123047 Cosine similarity is : 0.8296389579772949\n",
            "Training EPOCH :  1\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.5525702397490657\n",
            "L2 distance is : 0.7331832584946655\n",
            "L1 distance is : 28.106948497683504\n",
            "Cosine Similarity is : 0.7237147688865662\n",
            "Current Batch is 50 - loss is : 0.5137342789769173 and L2 distance is : 0.5658022165298462  L1 distance is : 19.93787956237793 Cosine similarity is : 0.8399338126182556\n",
            "Training EPOCH :  2\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.5037238551087158\n",
            "L2 distance is : 0.6981740164202314\n",
            "L1 distance is : 24.317144349563954\n",
            "Cosine Similarity is : 0.7481380105018616\n",
            "Current Batch is 50 - loss is : 0.5022699758410454 and L2 distance is : 0.5610079169273376  L1 distance is : 19.7044677734375 Cosine similarity is : 0.8426349759101868\n",
            "Training EPOCH :  3\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.4935025848275007\n",
            "L2 distance is : 0.6909024847108264\n",
            "L1 distance is : 24.034877111745434\n",
            "Cosine Similarity is : 0.7532488703727722\n",
            "Current Batch is 50 - loss is : 0.492154523730278 and L2 distance is : 0.5557819604873657  L1 distance is : 19.683162689208984 Cosine similarity is : 0.8455532193183899\n",
            "Training EPOCH :  4\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.4832688247741655\n",
            "L2 distance is : 0.6838460685901864\n",
            "L1 distance is : 24.180621679439103\n",
            "Cosine Similarity is : 0.7583656311035156\n",
            "Current Batch is 50 - loss is : 0.47881974071264266 and L2 distance is : 0.5495138168334961  L1 distance is : 19.894641876220703 Cosine similarity is : 0.849017322063446\n",
            "Training EPOCH :  5\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.4684970113773679\n",
            "L2 distance is : 0.6736365532459214\n",
            "L1 distance is : 24.44874865509743\n",
            "Cosine Similarity is : 0.7657514810562134\n",
            "Current Batch is 50 - loss is : 0.4584094786643982 and L2 distance is : 0.539921760559082  L1 distance is : 20.148958206176758 Cosine similarity is : 0.854242205619812\n",
            "Training EPOCH :  6\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.4455608247324478\n",
            "L2 distance is : 0.6573923347994338\n",
            "L1 distance is : 24.54288979463799\n",
            "Cosine Similarity is : 0.7772193551063538\n",
            "Current Batch is 50 - loss is : 0.43132708728313446 and L2 distance is : 0.5284006595611572  L1 distance is : 20.03736686706543 Cosine similarity is : 0.8603963255882263\n",
            "Training EPOCH :  7\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.4189010532789452\n",
            "L2 distance is : 0.6380019669615945\n",
            "L1 distance is : 24.47179710033328\n",
            "Cosine Similarity is : 0.7905495166778564\n",
            "Current Batch is 50 - loss is : 0.4156151407957077 and L2 distance is : 0.5472341775894165  L1 distance is : 21.83228302001953 Cosine similarity is : 0.8502673506736755\n",
            "Training EPOCH :  8\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.4108822617766469\n",
            "L2 distance is : 0.6332685417214106\n",
            "L1 distance is : 25.17048354481542\n",
            "Cosine Similarity is : 0.7945588827133179\n",
            "Current Batch is 50 - loss is : 0.41259819000959397 and L2 distance is : 0.5388397574424744  L1 distance is : 23.068695068359375 Cosine similarity is : 0.8548258543014526\n",
            "Training EPOCH :  9\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.4047723039984703\n",
            "L2 distance is : 0.6295994142460268\n",
            "L1 distance is : 25.414457631665606\n",
            "Cosine Similarity is : 0.7976137399673462\n",
            "Current Batch is 50 - loss is : 0.3780839341878891 and L2 distance is : 0.5114907622337341  L1 distance is : 21.174816131591797 Cosine similarity is : 0.8691886067390442\n",
            "Training EPOCH :  10\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.3673362288364144\n",
            "L2 distance is : 0.5999261182408\n",
            "L1 distance is : 23.7915493499401\n",
            "Cosine Similarity is : 0.8163318037986755\n",
            "Current Batch is 50 - loss is : 0.34728616058826445 and L2 distance is : 0.5019506812095642  L1 distance is : 19.500513076782227 Cosine similarity is : 0.8740227222442627\n",
            "Training EPOCH :  11\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.33865706934485323\n",
            "L2 distance is : 0.5765462885069292\n",
            "L1 distance is : 22.70709388200627\n",
            "Cosine Similarity is : 0.8306712508201599\n",
            "Current Batch is 50 - loss is : 0.32308035880327224 and L2 distance is : 0.46414127945899963  L1 distance is : 18.84488868713379 Cosine similarity is : 0.8922864198684692\n",
            "Training EPOCH :  12\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.3150018049880516\n",
            "L2 distance is : 0.5568096093660178\n",
            "L1 distance is : 21.98383180485215\n",
            "Cosine Similarity is : 0.8424991369247437\n",
            "Current Batch is 50 - loss is : 0.3064300402998924 and L2 distance is : 0.46653738617897034  L1 distance is : 19.22720718383789 Cosine similarity is : 0.8911713361740112\n",
            "Training EPOCH :  13\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.30009058949559236\n",
            "L2 distance is : 0.5439802609210791\n",
            "L1 distance is : 21.686972396318303\n",
            "Cosine Similarity is : 0.8499547243118286\n",
            "Current Batch is 50 - loss is : 0.2932842060923576 and L2 distance is : 0.4918091297149658  L1 distance is : 18.62875747680664 Cosine similarity is : 0.8790618777275085\n",
            "Training EPOCH :  14\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.28763835253410563\n",
            "L2 distance is : 0.5330404556074808\n",
            "L1 distance is : 21.25101051774136\n",
            "Cosine Similarity is : 0.8561807870864868\n",
            "Current Batch is 50 - loss is : 0.2725632527470589 and L2 distance is : 0.44772040843963623  L1 distance is : 18.310810089111328 Cosine similarity is : 0.8997731804847717\n",
            "Training EPOCH :  15\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.26502164834460545\n",
            "L2 distance is : 0.5121409681647323\n",
            "L1 distance is : 20.58419406136801\n",
            "Cosine Similarity is : 0.8674890995025635\n",
            "Current Batch is 50 - loss is : 0.24750595450401305 and L2 distance is : 0.4213385283946991  L1 distance is : 16.829835891723633 Cosine similarity is : 0.9112368822097778\n",
            "Training EPOCH :  16\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.24334623214117315\n",
            "L2 distance is : 0.49110271001971045\n",
            "L1 distance is : 19.892080318096074\n",
            "Cosine Similarity is : 0.878326952457428\n",
            "Current Batch is 50 - loss is : 0.22854825973510742 and L2 distance is : 0.4216846525669098  L1 distance is : 16.380611419677734 Cosine similarity is : 0.9110909104347229\n",
            "Training EPOCH :  17\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.2264840666984403\n",
            "L2 distance is : 0.4739302362120429\n",
            "L1 distance is : 19.303853445274886\n",
            "Cosine Similarity is : 0.8867579698562622\n",
            "Current Batch is 50 - loss is : 0.21389028131961824 and L2 distance is : 0.4238723814487457  L1 distance is : 17.2268009185791 Cosine similarity is : 0.9101660251617432\n",
            "Training EPOCH :  18\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.21206111530231875\n",
            "L2 distance is : 0.4585989263168601\n",
            "L1 distance is : 18.847183282985245\n",
            "Cosine Similarity is : 0.8939692378044128\n",
            "Current Batch is 50 - loss is : 0.20102207973599434 and L2 distance is : 0.405842125415802  L1 distance is : 16.315948486328125 Cosine similarity is : 0.9176459908485413\n",
            "Training EPOCH :  19\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 0.19990212011129357\n",
            "L2 distance is : 0.4453096899182297\n",
            "L1 distance is : 18.432884914930476\n",
            "Cosine Similarity is : 0.9000489711761475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "FCvbJU_pT-j3",
        "outputId": "6e36d952-6726-4d6a-fefc-081ec79f5549"
      },
      "source": [
        "testing()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-a9ccd714e728>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-77-0b4804e34dae>\u001b[0m in \u001b[0;36mtesting\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mspec_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspec_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/vgg/vgg_image_features_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAyNOKDVCyaZ"
      },
      "source": [
        "model_weights_path = '/content/drive/MyDrive/audio_encoder_model_0718.pt'\n",
        "torch.save(audio_encoder.state_dict(),model_weights_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FHtDpmVC272"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdkaeJ2dC8ck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43b74b7e-41a0-4a45-d8e4-c3aa0793bcac"
      },
      "source": [
        "audio_encoder.load_state_dict(torch.load('/content/drive/MyDrive/audio_encoder_model_0718.pt'))\n",
        "audio_encoder.eval()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AudioEncoder(\n",
              "  (conv1): Conv2d(2, 32, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(32, 32, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool1): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv4): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool2): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv5): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv6): Conv2d(64, 128, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool4): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv7): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1))\n",
              "  (bn7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv8): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2))\n",
              "  (bn8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv9): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2))\n",
              "  (avg1): AvgPool2d(kernel_size=(1, 1), stride=1, padding=0)\n",
              "  (bn9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=87552, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=1024, bias=True)\n",
              "  (fc3): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "  (fc4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REWAX1E3C-RQ"
      },
      "source": [
        "def create_reference_dataset():\n",
        "\n",
        "  reference_size = 15000\n",
        "  batch_size = 10\n",
        "  n_batches_ref = int(reference_size / batch_size)\n",
        "\n",
        "  for i in range(1385,n_batches_ref):\n",
        "\n",
        "    preprocess_data(i,batch_size,True)\n",
        "\n",
        "  return create_reference_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNdCNkOVDBP2"
      },
      "source": [
        "create_reference_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcppecdoDERn"
      },
      "source": [
        "def create_reference_dict(n_batches_ref): # vgg_dict{ image_id : 4096_feature_vector}\n",
        "  \n",
        "  vgg_feature_dict = {}\n",
        "  spectrogram_dict = {}\n",
        "\n",
        "  for i in range(1000,1048):\n",
        "\n",
        "    try:\n",
        "      f = open('/content/drive/MyDrive/reference/spectrograms_'+str(i)+'.pk','rb')\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "    spec_dict = pickle.load(f)\n",
        "\n",
        "    vgg_features = torch.load('/content/drive/MyDrive/reference/vgg_image_features_'+str(i))\n",
        "\n",
        "    for index,key in enumerate(spec_dict.keys()):\n",
        "\n",
        "      vgg_feature_dict[key] = vgg_features[index]\n",
        "      spectrogram_dict[key] = spec_dict[key]\n",
        "\n",
        "\n",
        "  \n",
        "  vgg_feat_pickle_file = '/content/drive/MyDrive/reference/vgg_feature_dict.pk' \n",
        "  f = open(vgg_feat_pickle_file, 'wb')\n",
        "  pickle.dump(vgg_feature_dict, f)\n",
        "  f.close()\n",
        "\n",
        "  spec_pickle_file = '/content/drive/MyDrive/reference/spectrogram_dict.pk' \n",
        "  f = open(spec_pickle_file, 'wb')\n",
        "  pickle.dump(spectrogram_dict, f)\n",
        "  f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhbgKXrGDMsh"
      },
      "source": [
        "create_reference_dict(1385)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKa13mnPDPBQ"
      },
      "source": [
        "import cv2\n",
        "def plot_images(image_id,image_id_list,k):\n",
        "\n",
        "  w=10\n",
        "  h=10\n",
        "  fig=plt.figure(figsize=(16, 16))\n",
        "  columns = k+1\n",
        "  rows = 1\n",
        "\n",
        "  image = '/content/drive/MyDrive/reference/' + image_id + '.jpg'\n",
        "  fig.add_subplot(rows, columns, 1)\n",
        "  frame = Image.open(image)\n",
        "  frame_arr = np.asarray(frame)\n",
        "  face_arr = extract_face(frame_arr)\n",
        "  #img = cv2.imread(image)[:,:,::-1]\n",
        "  plt.imshow(face_arr)\n",
        "\n",
        "  for i in range(2, k+2):\n",
        "    image = '/content/drive/MyDrive/reference/' + image_id_list[i-2] + '.jpg'\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    frame = Image.open(image)\n",
        "    frame_arr = np.asarray(frame)\n",
        "    face_arr = extract_face(frame_arr)\n",
        "    #img = cv2.imread(image)[:,:,::-1]\n",
        "    plt.imshow(face_arr)\n",
        "    \n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOlzSGLADRpZ"
      },
      "source": [
        "cosine_similarity = torch.nn.CosineSimilarity()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9pYZpXeDUn5"
      },
      "source": [
        "\n",
        "f = open('/content/drive/MyDrive/reference/spectrogram_dict.pk','rb')\n",
        "spec_dict = pickle.load(f)\n",
        "f = open('/content/drive/MyDrive/reference/vgg_feature_dict.pk','rb')\n",
        "vgg_feature_dict = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wbDMgsjDXiT"
      },
      "source": [
        "def get_top_k_face_ids(image_id , k): # spectrogam in batch=1\n",
        "\n",
        "  \n",
        "  with torch.no_grad():\n",
        "\n",
        "    query_spectrogram = spec_dict[image_id]\n",
        "    query_spectrogram = torch.tensor(query_spectrogram).permute(2,1,0).unsqueeze(0).to(device)\n",
        "    #print(query_spectrogram.shape , type(query_spectrogram))\n",
        "    query_vector = audio_encoder(query_spectrogram)\n",
        "    score_dict = {}\n",
        "\n",
        "    for id in list(vgg_feature_dict.keys()):\n",
        "      #print(query_vector.shape , vgg_feature_dict[id].unsqueeze(0).shape)\n",
        "      #y = torch.div(query_vector,torch.norm(query_vector))\n",
        "      #y_pred = torch.div(vgg_feature_dict[id].unsqueeze(0),torch.norm(vgg_feature_dict[id].unsqueeze(0)))\n",
        "      #score = cosine_similarity(query_vector , vgg_feature_dict[id].unsqueeze(0)).mean()\n",
        "      #score = cosine_similarity(query_vector , vgg_feature_dict[id].unsqueeze(0))\n",
        "      #score = l1_dist(query_vector , vgg_feature_dict[id].unsqueeze(0)).item()\n",
        "      score = Loss1(query_vector,vgg_feature_dict[id].unsqueeze(0),device).item()\n",
        "      score_dict[id] = score\n",
        "      #print(id,score, end=\" \")\n",
        "    sorted_score_ids = sorted(score_dict , key = score_dict.get)\n",
        "\n",
        "  \n",
        "  #print(image_id)\n",
        "  #for id in sorted_score_ids:\n",
        "    #print(id , score_dict[id] ,end=' ')\n",
        "  #rint('')\n",
        "  if (image_id in sorted_score_ids[:k]):\n",
        "    plot_images(image_id,sorted_score_ids[:k],k)\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn9ZJ1PODbEi"
      },
      "source": [
        "def find_recall(query_image_ids , k):\n",
        "\n",
        "  tp = 0\n",
        "  matched_ids = []\n",
        "\n",
        "  for image_id in query_image_ids:\n",
        "\n",
        "    if(get_top_k_face_ids(image_id,k)):\n",
        "      tp += 1\n",
        "      matched_ids.append(image_id)\n",
        "\n",
        "  recall = tp/len(query_image_ids)\n",
        "\n",
        "  return recall , matched_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7BqHksLDeep"
      },
      "source": [
        "\n",
        "image_id_list = [key for key in spec_dict.keys()]\n",
        "len(image_id_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNDnCyj3DgzM"
      },
      "source": [
        "recall , matched_ids = find_recall(image_id_list[:],10)\n",
        "print(model_weights_path , recall)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SdyG_IeDjRW"
      },
      "source": [
        "def extract_vgg_features_decoder(image_path_list):\n",
        "\n",
        "  face_batch = []\n",
        "\n",
        "  for image_path in image_path_list: \n",
        "\n",
        "    frame = Image.open(image_path)\n",
        "    \n",
        "    frame_arr = np.asarray(frame)\n",
        "    face_arr = extract_face(frame_arr)\n",
        "\n",
        "    if(face_arr is None):\n",
        "      print('face not extracted')\n",
        "      return None\n",
        "\n",
        "    face = Image.fromarray(np.uint8(frame_arr)).convert('RGB')\n",
        "    #face = Image.fromarray(frame_arr)\n",
        "    face_tensor = transform(face)\n",
        "    #print(face_tensor.shape)\n",
        "    face_batch.append(face_tensor.numpy())\n",
        "    #print(face_tensor.device)\n",
        "\n",
        "  face_batch = torch.tensor(face_batch).to(device)\n",
        "  #print(face_batch.shape)\n",
        "  #return face_batch\n",
        "  vgg_features = vgg_model(face_batch)\n",
        "\n",
        "  return vgg_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "batc0vd3Dx0w"
      },
      "source": [
        "def extract_faces_features_decoder(image_path_list):\n",
        "\n",
        "  face_batch = []\n",
        "  #print(image_path_list)\n",
        "  for image_path in image_path_list: \n",
        "    #print(image_path)\n",
        "    frame = Image.open(image_path)\n",
        "    \n",
        "    frame_arr = np.asarray(frame)\n",
        "    face_arr = extract_face(frame_arr)\n",
        "\n",
        "\n",
        "    if(face_arr is None):\n",
        "      return None\n",
        "\n",
        "    face = Image.fromarray(np.uint8(frame_arr)).convert('RGB')\n",
        "    #face = Image.fromarray(frame_arr)\n",
        "    \n",
        "    face_tensor = transform(face)\n",
        "    #print(face_tensor.shape)\n",
        "    face_batch.append(face_tensor.numpy())\n",
        "    #print(face_tensor.device)\n",
        "\n",
        "  face_batch = torch.tensor(face_batch).to(device)\n",
        "  #print(face_batch.shape)\n",
        "  return face_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC0NvTQzD1Cz"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.ReLU = nn.ReLU()\n",
        "        self.fc4 = nn.Linear(4096, 14 * 14 * 64)\n",
        "        self.fc_bn4 = nn.BatchNorm1d(14 * 14 * 64)\n",
        "\n",
        "        def TransConv( i, kernal = 5, stride = 2, inp = None):\n",
        "            if not inp:\n",
        "                inp = max(256//2**(i-1), 32)\n",
        "\n",
        "            layer =  nn.Sequential(\n",
        "                nn.ConvTranspose2d(inp, max(256//2**i, 32), \n",
        "                       kernal, stride=stride, padding=2, output_padding=1, \n",
        "                                dilation=1, padding_mode='zeros'),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm2d(max(256//2**i, 32)))\n",
        "            return layer\n",
        "\n",
        "        self.T1_ = TransConv(1, inp = 64)\n",
        "        self.T2_ = TransConv(2)\n",
        "        self.T3_ = TransConv(3)\n",
        "        self.T4_ = TransConv(4)\n",
        "    \n",
        "        self.ConvLast = nn.Sequential(\n",
        "            nn.Conv2d(32, 3, (1,1), stride=1),\n",
        "            nn.BatchNorm2d(3),\n",
        "            nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        #print(x.shape)\n",
        "        T0 = self.fc4(x) \n",
        "        T0 = self.ReLU(T0)\n",
        "        # T0 = self.fc_bn4(T0)\n",
        "        T0 = T0.view(-1,64,14,14)\n",
        "\n",
        "\n",
        "        #print(T0.shape)\n",
        "        T1 = self.T1_(T0)\n",
        "        #print(T1.shape)\n",
        "        T2 = self.T2_(T1)\n",
        "        #print(T2.shape)\n",
        "        T3 = self.T3_(T2)\n",
        "        #print(T3.shape)\n",
        "        T4 = self.T4_(T3)\n",
        "        #print(T4.shape)\n",
        "\n",
        "        outT = self.ConvLast(T4)\n",
        "        #print(outT.shape)\n",
        "\n",
        "\n",
        "        return outT\n",
        "\n",
        "        #print(T1.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yorBDJ4MD7gt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa1e6c3-1254-487d-c883-f16078c474d7"
      },
      "source": [
        "decoder = Decoder()\n",
        "decoder.to(device)\n",
        "decoder.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Decoder(\n",
              "  (ReLU): ReLU()\n",
              "  (fc4): Linear(in_features=4096, out_features=12544, bias=True)\n",
              "  (fc_bn4): BatchNorm1d(12544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (T1_): Sequential(\n",
              "    (0): ConvTranspose2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (T2_): Sequential(\n",
              "    (0): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (T3_): Sequential(\n",
              "    (0): ConvTranspose2d(64, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (T4_): Sequential(\n",
              "    (0): ConvTranspose2d(32, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (ConvLast): Sequential(\n",
              "    (0): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cAMZX96D-pp"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXHgUBSdEBI8"
      },
      "source": [
        "#device = 'cpu'\n",
        "mse_loss = torch.nn.MSELoss(reduction='sum').to(device)\n",
        "#l1_loss = torch.nn.L1Loss(reduction='sum').to(device)\n",
        "optimizer = torch.optim.Adam(decoder.parameters(),lr=1e-5 , weight_decay=1e-5)\n",
        "cosine_similarity = torch.nn.CosineSimilarity().to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aeKfhryEDzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d1e5898-1831-4be5-f9ee-cc313f639966"
      },
      "source": [
        "epochs = 1000\n",
        "\n",
        "for x in range(27,40):\n",
        "\n",
        "  total_mse_loss = 0\n",
        "  total_l1_loss = 0\n",
        "  total_l2_distance = 0\n",
        "  total_l1_distance = 0\n",
        "  total_cosine_similarity = 0\n",
        "  batches = 0\n",
        "  total_examples = 0\n",
        "  n = 10*[1000]\n",
        "  decoder.train()\n",
        "\n",
        "  for i in range(1000):\n",
        "\n",
        "    try:\n",
        "      X = torch.load('/content/drive/MyDrive/vgg/vgg_image_features_'+str(i))\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "    f = open('/content/drive/MyDrive/spectrogram/spectrograms_'+str(i)+'.pk','rb')\n",
        "    spec_dict = pickle.load(f)\n",
        "    image_path_list = ['/content/drive/MyDrive/reference/'+str(i)+'.jpg'] \n",
        "\n",
        "    y = extract_faces_features_decoder(image_path_list).to(device)\n",
        "    X = extract_vgg_features_decoder(image_path_list).to(device)\n",
        "    \n",
        "    y_pred = decoder.forward(X)\n",
        "    print(y.shape , y_pred.shape)\n",
        "  \n",
        "    assert(y.shape == y_pred.shape)\n",
        "  \n",
        "    loss = Loss2(y, y_pred,device)\n",
        "\n",
        "    print(loss)\n",
        "    \n",
        "\n",
        "    optimizer.zero_grad()\n",
        "   # print(loss.device)\n",
        "    loss.backward()\n",
        "    #total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    batches += 1\n",
        "    total_mse_loss += loss.item()\n",
        "    #total_mse_loss += total_loss.item()\n",
        "    \n",
        "    total_examples += X.shape[0]\n",
        "    print('batch is {} loss is {}'.format(batches,total_mse_loss/batches))\n",
        "  \n",
        "\n",
        "  print(\"Training EPOCH : \",x)\n",
        "  print('total batches processed : {}'.format(batches))\n",
        "  print('total examples processed : {}'.format(total_examples))\n",
        "  print('Total loss is : {}'.format(total_mse_loss/batches))\n",
        "  print('L2 distance is : {}'.format(total_l2_distance/batches))\n",
        "  print('L1 distance is : {}'.format(total_l1_distance/batches))\n",
        "  print('Cosine Similarity is : {}'.format(total_cosine_similarity/batches))\n",
        "\n",
        "  model_weights_path = '/content/drive/MyDrive/decoder_0718.pt'\n",
        "  torch.save(decoder.state_dict(),model_weights_path)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56345.7734, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 1 loss is 56345.7734375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56362.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 2 loss is 56354.35546875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56335.7812, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 3 loss is 56348.1640625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56397.9102, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 4 loss is 56360.6005859375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56340.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 5 loss is 56356.53046875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56307.5156, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 6 loss is 56348.361328125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56330.8359, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 7 loss is 56345.857700892855\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56320.0820, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 8 loss is 56342.6357421875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56332.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 9 loss is 56341.55121527778\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56315.2344, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 10 loss is 56338.91953125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56327.2109, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 11 loss is 56337.85511363636\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56312.5312, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 12 loss is 56335.744791666664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56336.4141, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 13 loss is 56335.79627403846\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56296.6094, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 14 loss is 56332.99720982143\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56344.0703, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 15 loss is 56333.73541666667\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56305.9492, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 16 loss is 56331.998779296875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56290.7305, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 17 loss is 56329.57123161765\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56296.4492, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 18 loss is 56327.731119791664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56294.6016, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 19 loss is 56325.98745888158\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56234.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 20 loss is 56321.4318359375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56286.2695, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 21 loss is 56319.75744047619\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56274.2305, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 22 loss is 56317.688032670456\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56269.2461, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 23 loss is 56315.58186141304\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56316.5078, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 24 loss is 56315.620442708336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56253.7266, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 25 loss is 56313.1446875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56298.8164, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 26 loss is 56312.59359975962\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56216.4844, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 27 loss is 56309.03399884259\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56275.9727, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 28 loss is 56307.853236607145\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56218.4688, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 29 loss is 56304.771012931036\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56233.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 30 loss is 56302.40052083333\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56271.1875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 31 loss is 56301.393649193546\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56219.9297, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 32 loss is 56298.847900390625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56199.8984, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 33 loss is 56295.849431818184\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56217.3281, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 34 loss is 56293.53998161765\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56171.2773, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 35 loss is 56290.04676339286\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56195.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 36 loss is 56287.427408854164\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56209.3984, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 37 loss is 56285.31851773649\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56200.6758, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 38 loss is 56283.09107730263\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56171.5742, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 39 loss is 56280.23167067308\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56157.8047, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 40 loss is 56277.17099609375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56179.1992, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 41 loss is 56274.78144054878\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56167.4766, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 42 loss is 56272.2265625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56177.8828, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 43 loss is 56270.03252180233\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56150.5273, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 44 loss is 56267.31649502841\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56134.3438, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 45 loss is 56264.36154513889\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56134.7109, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 46 loss is 56261.54305366848\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56136.4023, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 47 loss is 56258.88048537234\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56133.2656, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 48 loss is 56256.263509114586\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56098.5938, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 49 loss is 56253.04575892857\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56088.0547, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 50 loss is 56249.7459375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56104.5703, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 51 loss is 56246.89935661765\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56084.4453, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 52 loss is 56243.77524038462\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56091.7852, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 53 loss is 56240.90750294811\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56069.0859, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 54 loss is 56237.72562210648\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56074.0195, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 55 loss is 56234.74914772727\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56055.8984, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 56 loss is 56231.555385044645\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56046.9453, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 57 loss is 56228.31661184211\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56055.3672, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 58 loss is 56225.334725215514\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56046.0430, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 59 loss is 56222.29588188559\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56000.3594, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 60 loss is 56218.596940104166\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55988.1836, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 61 loss is 56214.81967213115\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56053.4609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 62 loss is 56212.21711189516\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56008.4688, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 63 loss is 56208.9830109127\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55962.2891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 64 loss is 56205.12841796875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(56009.7891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 65 loss is 56202.12319711538\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55960.4414, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 66 loss is 56198.46135179924\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55938.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 67 loss is 56194.58506296642\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55971.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 68 loss is 56191.31083409926\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55933.4453, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 69 loss is 56187.57365262681\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55929.1719, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 70 loss is 56183.882198660714\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55924.4375, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 71 loss is 56180.22804797535\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55905.7578, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 72 loss is 56176.41596137153\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55900.2891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 73 loss is 56172.63340111302\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55878.8281, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 74 loss is 56168.66305954392\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55879.3984, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 75 loss is 56164.80619791667\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55877.0938, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 76 loss is 56161.0205078125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55853.5938, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 77 loss is 56157.02795251623\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55846.3398, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 78 loss is 56153.04477163462\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55836.7617, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 79 loss is 56149.04118868671\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55828.3672, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 80 loss is 56145.03276367187\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55850.0312, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 81 loss is 56141.39076967593\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55814.7266, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 82 loss is 56137.407059832316\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55851.0859, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 83 loss is 56133.957407756025\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55776.6445, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 84 loss is 56129.70368303572\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55766.5039, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 85 loss is 56125.4307444853\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55768.0039, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 86 loss is 56121.274618459305\n",
            "Training EPOCH :  27\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 56121.274618459305\n",
            "L2 distance is : 0.0\n",
            "L1 distance is : 0.0\n",
            "Cosine Similarity is : 0.0\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55723.9297, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 1 loss is 55723.9296875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55692.8438, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 2 loss is 55708.38671875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55693.1328, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 3 loss is 55703.302083333336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55708.5781, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 4 loss is 55704.62109375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55682.3242, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 5 loss is 55700.16171875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55676.1367, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 6 loss is 55696.157552083336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55666.0859, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 7 loss is 55691.861607142855\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55652.7578, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 8 loss is 55686.9736328125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55620.2344, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 9 loss is 55679.55815972222\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55648.6094, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 10 loss is 55676.46328125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55643.3711, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 11 loss is 55673.454900568184\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55617.8086, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 12 loss is 55668.817708333336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55578.2109, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 13 loss is 55661.847956730766\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55609.8906, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 14 loss is 55658.13671875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55617.6953, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 15 loss is 55655.440625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55596.3516, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 16 loss is 55651.74755859375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55600.7461, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 17 loss is 55648.74747242647\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55572.9297, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 18 loss is 55644.53537326389\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55577.9102, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 19 loss is 55641.02878289474\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55502.5312, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 20 loss is 55634.10390625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55567.5664, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 21 loss is 55630.935453869046\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55554.6055, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 22 loss is 55627.46590909091\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55533.0820, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 23 loss is 55623.362262228264\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55532.9141, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 24 loss is 55619.593587239586\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55521.3359, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 25 loss is 55615.66328125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55555.1562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 26 loss is 55613.33608774038\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55489.1289, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 27 loss is 55608.73582175926\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55529.0156, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 28 loss is 55605.888671875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55445.4922, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 29 loss is 55600.35775862069\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55474.5117, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 30 loss is 55596.162890625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55491.2031, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 31 loss is 55592.77709173387\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55456.7305, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 32 loss is 55588.525634765625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55462.9688, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 33 loss is 55584.720880681816\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55436.5977, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 34 loss is 55580.36431525735\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55400.1289, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 35 loss is 55575.21473214286\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55452.2969, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 36 loss is 55571.80034722222\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55427.7266, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 37 loss is 55567.90646114865\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55445.0742, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 38 loss is 55564.67403371711\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55419.6250, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 39 loss is 55560.95482772436\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55414.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 40 loss is 55557.28251953125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55410.1953, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 41 loss is 55553.69502667683\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55443.8516, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 42 loss is 55551.07970610119\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55403.4922, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 43 loss is 55547.64743822674\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55394.5703, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 44 loss is 55544.168412642044\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55396.3867, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 45 loss is 55540.884375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55396.1328, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 46 loss is 55537.737601902176\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55400.9922, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 47 loss is 55534.828125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55382.8359, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 48 loss is 55531.66162109375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55358.2578, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 49 loss is 55528.122767857145\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55333.6719, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 50 loss is 55524.23375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55378.4062, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 51 loss is 55521.3743872549\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55354.1562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 52 loss is 55518.158653846156\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55390.2578, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 53 loss is 55515.745430424526\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55351.0938, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 54 loss is 55512.69632523148\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55340.5391, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 55 loss is 55509.56619318182\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55344.5547, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 56 loss is 55506.61955915178\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55348.0234, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 57 loss is 55503.83717105263\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55359.7695, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 58 loss is 55501.35324622845\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55341.9766, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 59 loss is 55498.65194650424\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55351.1953, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 60 loss is 55496.1943359375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55300.6094, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 61 loss is 55492.98802510246\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55385.3828, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 62 loss is 55491.25245715726\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55347.4922, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 63 loss is 55488.97054811508\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55317.1562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 64 loss is 55486.28594970703\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55332.0312, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 65 loss is 55483.91280048077\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55308.1328, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 66 loss is 55481.249467329544\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55299.5391, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 67 loss is 55478.537371735074\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55337.3672, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 68 loss is 55476.46133961397\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55291.8633, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 69 loss is 55473.786005434784\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55284.8945, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 70 loss is 55471.08755580357\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55263.5938, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 71 loss is 55468.16510783451\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55282.5938, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 72 loss is 55465.587727864586\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55311.5078, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 73 loss is 55463.47704409246\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55259.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 74 loss is 55460.72482052365\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55295.3203, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 75 loss is 55458.51942708333\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55282.5820, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 76 loss is 55456.20446134869\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55287.3203, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 77 loss is 55454.01116071428\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55278.4766, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 78 loss is 55451.76071714744\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55270.7070, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 79 loss is 55449.46889833861\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55282.3945, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 80 loss is 55447.38046875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55321.9883, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 81 loss is 55445.83241705247\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55274.3828, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 82 loss is 55443.741568216465\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55302.3672, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 83 loss is 55442.0382624247\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55258.5156, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 84 loss is 55439.85346912203\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55276.1484, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 85 loss is 55437.92752757353\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55275.7422, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 86 loss is 55436.04165152616\n",
            "Training EPOCH :  28\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 55436.04165152616\n",
            "L2 distance is : 0.0\n",
            "L1 distance is : 0.0\n",
            "Cosine Similarity is : 0.0\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55249.1914, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 1 loss is 55249.19140625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55226.6172, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 2 loss is 55237.904296875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55254.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 3 loss is 55243.311197916664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55263.6719, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 4 loss is 55248.4013671875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55224.4453, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 5 loss is 55243.61015625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55241.8203, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 6 loss is 55243.311848958336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55240.8242, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 7 loss is 55242.95647321428\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55235.6875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 8 loss is 55242.0478515625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55200.4141, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 9 loss is 55237.421875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55251.8164, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 10 loss is 55238.861328125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55234., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 11 loss is 55238.419389204544\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55221.3828, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 12 loss is 55236.999674479164\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55195.0898, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 13 loss is 55233.775841346156\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55244.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 14 loss is 55234.532924107145\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55240.0117, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 15 loss is 55234.898177083334\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55229.0234, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 16 loss is 55234.531005859375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55257.1875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 17 loss is 55235.863740808825\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55228.4922, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 18 loss is 55235.454210069445\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55235.0039, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 19 loss is 55235.43050986842\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55173.8711, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 20 loss is 55232.3525390625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55234.1211, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 21 loss is 55232.43675595238\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55226.9414, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 22 loss is 55232.186967329544\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55217.3281, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 23 loss is 55231.54093070652\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55200.5078, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 24 loss is 55230.247884114586\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55225.5234, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 25 loss is 55230.05890625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55252.9844, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 26 loss is 55230.94065504808\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55201.1680, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 27 loss is 55229.83796296296\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55239.1914, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 28 loss is 55230.17201450893\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55162.0547, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 29 loss is 55227.82314116379\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55202.0781, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 30 loss is 55226.96497395833\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55197.4180, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 31 loss is 55226.01184475807\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55191.3867, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 32 loss is 55224.92980957031\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55205.2461, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 33 loss is 55224.333333333336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55178.2969, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 34 loss is 55222.979319852944\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55161.7578, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 35 loss is 55221.23013392857\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55215.0898, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 36 loss is 55221.0595703125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55179.6250, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 37 loss is 55219.93971706081\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55210.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 38 loss is 55219.68801398026\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55192.7578, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 39 loss is 55218.997495993586\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55191.8047, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 40 loss is 55218.31767578125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55192.9297, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 41 loss is 55217.69845655488\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55228.0391, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 42 loss is 55217.944661458336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55183.2188, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 43 loss is 55217.13708212209\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55191.6875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 44 loss is 55216.55868252841\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55183.6992, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 45 loss is 55215.82847222222\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55205.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 46 loss is 55215.61345108696\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55202.8555, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 47 loss is 55215.34200465425\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55192.5781, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 48 loss is 55214.86775716146\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55179.6172, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 49 loss is 55214.148357780614\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55156.5156, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 50 loss is 55212.995703125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55197.6367, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 51 loss is 55212.69454656863\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55184.8711, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 52 loss is 55212.159480168266\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55216.5273, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 53 loss is 55212.24189268868\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55177.2812, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 54 loss is 55211.59447337963\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55173.6523, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 55 loss is 55210.90461647727\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55186.1406, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 56 loss is 55210.46240234375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55192.1875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 57 loss is 55210.14179002193\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55200.4141, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 58 loss is 55209.9740705819\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55185.7812, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 59 loss is 55209.56402277543\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55206.8203, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 60 loss is 55209.518294270834\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55164.6445, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 61 loss is 55208.78265881148\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55223.7031, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 62 loss is 55209.02331149193\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55203.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 63 loss is 55208.93365575397\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55182.4570, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 64 loss is 55208.519958496094\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55189.2812, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 65 loss is 55208.223978365386\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55177.9648, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 66 loss is 55207.765506628784\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55173.1172, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 67 loss is 55207.248367537315\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55207.6094, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 68 loss is 55207.25367647059\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55159.6094, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 69 loss is 55206.563179347824\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55152.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 70 loss is 55205.78549107143\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55145.2383, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 71 loss is 55204.93271346831\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55162.9297, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 72 loss is 55204.34933810764\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55200.3672, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 73 loss is 55204.294788099316\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55148.5469, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 74 loss is 55203.5414379223\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55186.5195, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 75 loss is 55203.314479166664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55169.2031, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 76 loss is 55202.86564555921\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55179.5547, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 77 loss is 55202.562905844155\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55174.5234, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 78 loss is 55202.203425480766\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55165.4531, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 79 loss is 55201.7382318038\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55176.8477, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 80 loss is 55201.42709960938\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55208.7188, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 81 loss is 55201.517119984564\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55172.5391, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 82 loss is 55201.16372903963\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55171.4727, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 83 loss is 55200.806005271086\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55162.0195, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 84 loss is 55200.34426153274\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55191.1094, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 85 loss is 55200.23561580882\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55180.8438, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 86 loss is 55200.01012899709\n",
            "Training EPOCH :  29\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 55200.01012899709\n",
            "L2 distance is : 0.0\n",
            "L1 distance is : 0.0\n",
            "Cosine Similarity is : 0.0\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55160.8203, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 1 loss is 55160.8203125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55141.3828, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 2 loss is 55151.1015625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55173.6250, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 3 loss is 55158.609375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55157.8438, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 4 loss is 55158.41796875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55130.3789, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 5 loss is 55152.81015625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55159.8477, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 6 loss is 55153.983072916664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55164.1641, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 7 loss is 55155.4375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55161.9062, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 8 loss is 55156.24609375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55121.6875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 9 loss is 55152.40625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55174.9922, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 10 loss is 55154.66484375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55160.0703, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 11 loss is 55155.15625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55151.6484, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 12 loss is 55154.863932291664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55118.9062, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 13 loss is 55152.097956730766\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55182.1406, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 14 loss is 55154.243861607145\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55159.8359, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 15 loss is 55154.61666666667\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55162., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 16 loss is 55155.078125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55202.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 17 loss is 55157.876838235294\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55161.2461, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 18 loss is 55158.06401909722\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55169.8516, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 19 loss is 55158.68441611842\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55103.0312, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 20 loss is 55155.9017578125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55167.3594, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 21 loss is 55156.447358630954\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55163.9414, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 22 loss is 55156.78799715909\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55159.5234, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 23 loss is 55156.906929347824\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55110.6680, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 24 loss is 55154.980305989586\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55171.7578, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 25 loss is 55155.65140625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55184.6016, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 26 loss is 55156.76487379808\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55144.0078, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 27 loss is 55156.2923900463\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55174.9414, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 28 loss is 55156.95842633928\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55088.3945, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 29 loss is 55154.594154094826\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55145.0469, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 30 loss is 55154.27591145833\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55126.5625, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 31 loss is 55153.381930443546\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55136.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 32 loss is 55152.84069824219\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55153.5781, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 33 loss is 55152.863044507576\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55121.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 34 loss is 55151.94795496324\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55113.2031, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 35 loss is 55150.84095982143\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55164.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 36 loss is 55151.22905815972\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55117.3203, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 37 loss is 55150.31260557433\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55156.4141, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 38 loss is 55150.47317023026\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55145.0703, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 39 loss is 55150.334635416664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55143.3477, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 40 loss is 55150.1599609375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55147.4609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 41 loss is 55150.09413109756\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55178.9766, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 42 loss is 55150.78180803572\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55126.0781, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 43 loss is 55150.20730377907\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55149.5469, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 44 loss is 55150.19229403409\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55126.8359, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 45 loss is 55149.673263888886\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55168.4219, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 46 loss is 55150.080842391304\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55156.8633, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 47 loss is 55150.225149601065\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55151.3125, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 48 loss is 55150.247802734375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55140.5078, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 49 loss is 55150.04902742347\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55117.1836, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 50 loss is 55149.39171875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55154.9336, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 51 loss is 55149.500382965685\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55145.4531, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 52 loss is 55149.422551081734\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55173.9023, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 53 loss is 55149.88443396227\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55132.2852, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 54 loss is 55149.55852141204\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55130.2266, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 55 loss is 55149.20703125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55147.0078, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 56 loss is 55149.167759486605\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55152.9609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 57 loss is 55149.2343064693\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55158.7188, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 58 loss is 55149.39783135776\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55143.6367, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 59 loss is 55149.300185381355\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55170.6133, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 60 loss is 55149.65540364583\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55134.6719, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 61 loss is 55149.40977202869\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55173.1562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 62 loss is 55149.7927797379\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55165.3594, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 63 loss is 55150.03986855159\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55145.0859, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 64 loss is 55149.962463378906\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55149.9805, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 65 loss is 55149.96274038462\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55144.0703, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 66 loss is 55149.87346117424\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55138.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 67 loss is 55149.709305037315\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55173.2617, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 68 loss is 55150.0556640625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55116.6094, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 69 loss is 55149.570935235504\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55102.8516, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 70 loss is 55148.903515625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55110.9844, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 71 loss is 55148.36944322183\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55127.0312, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 72 loss is 55148.073079427086\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55171.5625, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 73 loss is 55148.39485231164\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55118.8633, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 74 loss is 55147.99577702703\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55158.1953, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 75 loss is 55148.13177083333\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55134.8398, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 76 loss is 55147.95687705592\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55149.5312, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 77 loss is 55147.977323457795\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55145.9492, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 78 loss is 55147.95132211538\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55133.5195, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 79 loss is 55147.768641218354\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55143.8438, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 80 loss is 55147.71958007813\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55170.5430, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 81 loss is 55148.001350308645\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55141.4414, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 82 loss is 55147.92135099085\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55116.1445, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 83 loss is 55147.53849774096\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55132.4219, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 84 loss is 55147.35853794643\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55167.8984, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 85 loss is 55147.60018382353\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55149.8086, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 86 loss is 55147.62586300872\n",
            "Training EPOCH :  30\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 55147.62586300872\n",
            "L2 distance is : 0.0\n",
            "L1 distance is : 0.0\n",
            "Cosine Similarity is : 0.0\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55131.7969, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 1 loss is 55131.796875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55111.3594, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 2 loss is 55121.578125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55151.2891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 3 loss is 55131.481770833336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55110.1641, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 4 loss is 55126.15234375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55090.8438, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 5 loss is 55119.090625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55132.7109, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 6 loss is 55121.360677083336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55140.8008, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 7 loss is 55124.13783482143\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55140.4570, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 8 loss is 55126.177734375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55090.2070, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 9 loss is 55122.180989583336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55149.4023, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 10 loss is 55124.903125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55137.2891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 11 loss is 55126.029119318184\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55129.3047, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 12 loss is 55126.302083333336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55084.2969, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 13 loss is 55123.07091346154\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55162.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 14 loss is 55125.9140625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55126.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 15 loss is 55125.973958333336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55140.7148, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 16 loss is 55126.895263671875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55191.8164, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 17 loss is 55130.71415441176\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55136.0078, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 18 loss is 55131.00824652778\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55148.7266, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 19 loss is 55131.94078947369\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55068.4219, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 20 loss is 55128.76484375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55142.2539, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 21 loss is 55129.40718005953\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55142.6914, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 22 loss is 55130.01100852273\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55141.6094, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 23 loss is 55130.51528532609\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55047.1172, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 24 loss is 55127.040364583336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55155.9141, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 25 loss is 55128.1953125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55154.9453, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 26 loss is 55129.224158653844\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55123.1875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 27 loss is 55129.0005787037\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55147.3359, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 28 loss is 55129.65541294643\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55026.9688, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 29 loss is 55126.114493534486\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55123.0977, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 30 loss is 55126.013932291666\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55084.7344, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 31 loss is 55124.682333669356\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55114.9141, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 32 loss is 55124.37707519531\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55133.8281, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 33 loss is 55124.663470643936\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55095.9062, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 34 loss is 55123.81767003676\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55090.2305, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 35 loss is 55122.858035714286\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55144.1836, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 36 loss is 55123.45041232639\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55079.8555, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 37 loss is 55122.27217060811\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55133.0898, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 38 loss is 55122.55684621711\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55127.1680, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 39 loss is 55122.6750801282\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55122.9688, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 40 loss is 55122.682421875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55130.9180, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 41 loss is 55122.88328887195\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55158.3438, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 42 loss is 55123.72758556547\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55091.2656, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 43 loss is 55122.97265625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55134.6250, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 44 loss is 55123.237482244316\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55093.7070, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 45 loss is 55122.58125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55157.2578, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 46 loss is 55123.335088315216\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55138.2656, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 47 loss is 55123.65275930851\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55135.8906, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 48 loss is 55123.90771484375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55123.3789, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 49 loss is 55123.896922831635\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55097.6250, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 50 loss is 55123.371484375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55137.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 51 loss is 55123.64361213235\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55130.3438, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 52 loss is 55123.7724609375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55155.3047, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 53 loss is 55124.367408608494\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55110.9141, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 54 loss is 55124.118272569445\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55106.3242, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 55 loss is 55123.794744318184\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55129.3359, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 56 loss is 55123.89369419643\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55135.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 57 loss is 55124.100054824565\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55138.7656, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 58 loss is 55124.35290948276\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55120.7070, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 59 loss is 55124.29111493644\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55154.7617, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 60 loss is 55124.79895833333\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55123.3164, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 61 loss is 55124.77465420082\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55145.7109, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 62 loss is 55125.112336189515\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55148.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 63 loss is 55125.489521329364\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55125.2188, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 64 loss is 55125.485290527344\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55129.6641, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 65 loss is 55125.54957932692\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55128.9180, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 66 loss is 55125.600615530304\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55122.0547, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 67 loss is 55125.547691231346\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55159.7148, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 68 loss is 55126.05014935662\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55088., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 69 loss is 55125.498697916664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55066.1562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 70 loss is 55124.65094866072\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55091.6875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 71 loss is 55124.186674735916\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55103.7188, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 72 loss is 55123.90239800347\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55161.3711, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 73 loss is 55124.41566780822\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55103.5977, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 74 loss is 55124.1343433277\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55147.8516, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 75 loss is 55124.45057291666\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55115.7188, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 76 loss is 55124.33568050987\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55136.6328, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 77 loss is 55124.49538352273\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55134.1641, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 78 loss is 55124.619340945515\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55115.1406, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 79 loss is 55124.49935719937\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55125.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 80 loss is 55124.51186523437\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55148.4180, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 81 loss is 55124.80700231482\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55124.6250, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 82 loss is 55124.80478277439\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55073.7891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 83 loss is 55124.190135542165\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55117.6484, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 84 loss is 55124.11225818453\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55156.2969, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 85 loss is 55124.49090073529\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55129.9531, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 86 loss is 55124.55441497093\n",
            "Training EPOCH :  31\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 55124.55441497093\n",
            "L2 distance is : 0.0\n",
            "L1 distance is : 0.0\n",
            "Cosine Similarity is : 0.0\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55113.9531, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 1 loss is 55113.953125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55087.8086, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 2 loss is 55100.880859375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55141.9961, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 3 loss is 55114.5859375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55074.3516, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 4 loss is 55104.52734375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55057.7695, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 5 loss is 55095.17578125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55117.1797, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 6 loss is 55098.843098958336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55129.4141, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 7 loss is 55103.21037946428\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55131.5781, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 8 loss is 55106.75634765625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55063.1953, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 9 loss is 55101.91623263889\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55136.6875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 10 loss is 55105.393359375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55125.6406, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 11 loss is 55107.23401988636\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55116.6914, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 12 loss is 55108.022135416664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55052.9219, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 13 loss is 55103.783653846156\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55151.6172, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 14 loss is 55107.20033482143\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55101.8242, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 15 loss is 55106.84192708333\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55130.8594, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 16 loss is 55108.343017578125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55191.1211, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 17 loss is 55113.21231617647\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55119.5078, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 18 loss is 55113.56206597222\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55139.3828, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 19 loss is 55114.92105263158\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55034.4375, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 20 loss is 55110.896875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55126.3672, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 21 loss is 55111.63355654762\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55132.4531, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 22 loss is 55112.579900568184\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55133.2227, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 23 loss is 55113.477411684784\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54965.4570, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 24 loss is 55107.309895833336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55149.0156, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 25 loss is 55108.978125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55132.5469, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 26 loss is 55109.88461538462\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55111.2188, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 27 loss is 55109.93402777778\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55126.9531, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 28 loss is 55110.54185267857\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54941.7578, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 29 loss is 55104.72171336207\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55109.6172, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 30 loss is 55104.88489583333\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55038.0430, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 31 loss is 55102.7287046371\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55100.2422, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 32 loss is 55102.65100097656\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55120.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 33 loss is 55103.18430397727\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55074.2422, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 34 loss is 55102.33306525735\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55069.4609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 35 loss is 55101.39386160715\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55128.6641, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 36 loss is 55102.1513671875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55039.2891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 37 loss is 55100.45238597973\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55117.2617, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 38 loss is 55100.89473684211\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55117.2227, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 39 loss is 55101.313401442305\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55108.8281, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 40 loss is 55101.50126953125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55122.3125, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 41 loss is 55102.00886051829\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55144.7344, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 42 loss is 55103.02613467262\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55054.3281, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 43 loss is 55101.89362281977\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55127.4336, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 44 loss is 55102.474076704544\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55061.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 45 loss is 55101.56076388889\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55154.0781, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 46 loss is 55102.702445652176\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55127.4961, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 47 loss is 55103.22997007979\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55127.5352, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 48 loss is 55103.736328125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55109.7422, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 49 loss is 55103.858896683676\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55079.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 50 loss is 55103.36296875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55126.9141, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 51 loss is 55103.82475490196\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55122.0781, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 52 loss is 55104.17578125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55141.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 53 loss is 55104.884728773584\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55096.0898, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 54 loss is 55104.72186053241\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55084.2578, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 55 loss is 55104.349786931816\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55116.6484, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 56 loss is 55104.56940569197\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55124.5781, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 57 loss is 55104.92043585526\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55124.2148, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 58 loss is 55105.25309806035\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55100.2344, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 59 loss is 55105.16803495763\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55144.4375, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 60 loss is 55105.822526041666\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55116.4766, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 61 loss is 55105.99718237705\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55123.1211, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 62 loss is 55106.27337449597\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55139.5234, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 63 loss is 55106.80115327381\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55108.2891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 64 loss is 55106.82440185547\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55113.2617, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 65 loss is 55106.9234375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55117.6250, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 66 loss is 55107.08558238636\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55109.6367, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 67 loss is 55107.123659048506\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55153., device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 68 loss is 55107.798311121325\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55056.4844, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 69 loss is 55107.05463088768\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55027.7734, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 70 loss is 55105.92204241071\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55073.1836, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 71 loss is 55105.4609375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55080.2617, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 72 loss is 55105.110948350695\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55158.2578, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 73 loss is 55105.838987585616\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55089.5820, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 74 loss is 55105.61929898649\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55143.0352, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 75 loss is 55106.118177083335\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55098.6133, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 76 loss is 55106.01942845395\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55129.3828, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 77 loss is 55106.32284902597\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55128.4062, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 78 loss is 55106.60596955128\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55096.6133, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 79 loss is 55106.479479825946\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55111.4336, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 80 loss is 55106.54140625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55129.3242, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 81 loss is 55106.82267554013\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55110.3828, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 82 loss is 55106.86609184451\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55029.2891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 83 loss is 55105.93142884036\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55107.3281, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 84 loss is 55105.94805617559\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55142.4297, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 85 loss is 55106.37725183823\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55109.6055, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 86 loss is 55106.41478924418\n",
            "Training EPOCH :  32\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 55106.41478924418\n",
            "L2 distance is : 0.0\n",
            "L1 distance is : 0.0\n",
            "Cosine Similarity is : 0.0\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55097.0195, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 1 loss is 55097.01953125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55056.3164, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 2 loss is 55076.66796875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55138.4531, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 3 loss is 55097.263020833336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55038.1797, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 4 loss is 55082.4921875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55016.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 5 loss is 55069.325\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55103.5039, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 6 loss is 55075.021484375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55121.8984, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 7 loss is 55081.71819196428\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55127.7266, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 8 loss is 55087.46923828125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55028.3125, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 9 loss is 55080.89626736111\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55128.7891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 10 loss is 55085.685546875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55116.4609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 11 loss is 55088.48330965909\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55104.7969, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 12 loss is 55089.8427734375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55015.7422, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 13 loss is 55084.14272836538\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55138.9219, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 14 loss is 55088.05552455357\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55074.1875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 15 loss is 55087.13098958333\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55125.1172, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 16 loss is 55089.505126953125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55193.6094, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 17 loss is 55095.62890625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55103.1211, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 18 loss is 55096.04513888889\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55134.7031, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 19 loss is 55098.07976973684\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54988.8867, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 20 loss is 55092.6201171875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55109.9727, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 21 loss is 55093.44642857143\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55126.0469, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 22 loss is 55094.928267045456\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55127.7422, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 23 loss is 55096.35495923913\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54849.6406, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 24 loss is 55086.0751953125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55142.9922, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 25 loss is 55088.351875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55107.9766, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 26 loss is 55089.10667067308\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55102.4609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 27 loss is 55089.601273148146\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55104.9531, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 28 loss is 55090.14955357143\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54823.4766, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 29 loss is 55080.95393318965\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55097.8281, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 30 loss is 55081.51640625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54974.9766, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 31 loss is 55078.07963709677\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55080.4609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 32 loss is 55078.154052734375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55105.6094, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 33 loss is 55078.98603219697\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55047.0508, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 34 loss is 55078.046760110294\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55047.8828, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 35 loss is 55077.184933035714\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55111.1133, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 36 loss is 55078.12738715278\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54986.4922, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 37 loss is 55075.65076013513\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55102.6914, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 38 loss is 55076.36235608553\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55109.3555, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 39 loss is 55077.208333333336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55094.4219, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 40 loss is 55077.638671875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55116.4727, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 41 loss is 55078.58584222561\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55131.1641, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 42 loss is 55079.83770461309\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55007.6094, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 43 loss is 55078.15797601744\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55122.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 44 loss is 55079.16930042614\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55021.7344, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 45 loss is 55077.89296875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55153.9219, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 46 loss is 55079.545771059784\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55119.7031, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 47 loss is 55080.40018284575\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55120.0938, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 48 loss is 55081.22713216146\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55093.8047, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 49 loss is 55081.48381696428\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55054.5469, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 50 loss is 55080.945078125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55118.8594, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 51 loss is 55081.68849571078\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55115.2266, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 52 loss is 55082.333458533656\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55126.9570, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 53 loss is 55083.17541273585\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55082.8984, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 54 loss is 55083.17028356482\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55059.4805, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 55 loss is 55082.739559659094\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55104.2422, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 56 loss is 55083.12353515625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55114.2188, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 57 loss is 55083.66906524123\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55110.9531, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 58 loss is 55084.13948006465\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55077.9258, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 59 loss is 55084.03416313559\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55135.0156, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 60 loss is 55084.88385416667\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55108.9766, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 61 loss is 55085.27881659836\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55099.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 62 loss is 55085.5021421371\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55132.8008, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 63 loss is 55086.25291418651\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55089.1133, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 64 loss is 55086.297607421875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55095.2656, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 65 loss is 55086.435576923075\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55105.2969, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 66 loss is 55086.721354166664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55097.4922, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 67 loss is 55086.882112873136\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55147.1719, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 68 loss is 55087.768727022056\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55012.2891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 69 loss is 55086.674818840576\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54986.2422, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 70 loss is 55085.24006696429\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55048.7031, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 71 loss is 55084.725462147886\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55054.2969, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 72 loss is 55084.302842881945\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55158.6484, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 73 loss is 55085.32127568493\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55072.3203, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 74 loss is 55085.14558699324\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55138.9766, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 75 loss is 55085.863333333335\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55078.9688, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 76 loss is 55085.77261513158\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55123.9609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 77 loss is 55086.26856737013\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55125.8164, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 78 loss is 55086.775590945515\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55072.7109, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 79 loss is 55086.59755735759\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55098.7891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 80 loss is 55086.74995117188\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55106.5312, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 81 loss is 55086.994164737655\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55092.1836, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 82 loss is 55087.057450457316\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54980.5156, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 83 loss is 55085.773814006025\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55098.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 84 loss is 55085.92234002976\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55118.9844, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 85 loss is 55086.31130514706\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55085.4609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 86 loss is 55086.30141715116\n",
            "Training EPOCH :  33\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 55086.30141715116\n",
            "L2 distance is : 0.0\n",
            "L1 distance is : 0.0\n",
            "Cosine Similarity is : 0.0\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55078.7188, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 1 loss is 55078.71875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55012.3945, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 2 loss is 55045.556640625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55138.9570, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 3 loss is 55076.690104166664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54997.8828, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 4 loss is 55056.98828125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54964.7070, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 5 loss is 55038.53203125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55088.0547, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 6 loss is 55046.785807291664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55115.1562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 7 loss is 55056.553013392855\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55127.2344, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 8 loss is 55065.38818359375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54978.9492, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 9 loss is 55055.783854166664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55122.8672, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 10 loss is 55062.4921875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55106.8281, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 11 loss is 55066.52272727273\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55089.1719, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 12 loss is 55068.41015625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54973.4375, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 13 loss is 55061.104567307695\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55121.9141, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 14 loss is 55065.44810267857\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55040.1953, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 15 loss is 55063.76458333333\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55120.7188, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 16 loss is 55067.32421875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55195.9297, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 17 loss is 55074.88924632353\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55083.0078, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 18 loss is 55075.34027777778\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55131.2461, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 19 loss is 55078.28268914474\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54928.1641, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 20 loss is 55070.7767578125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55089.1484, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 21 loss is 55071.65159970238\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55120.6172, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 22 loss is 55073.87730823864\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55123.8984, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 23 loss is 55076.052139945656\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54717.9414, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 24 loss is 55061.130859375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55133.9727, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 25 loss is 55064.04453125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55078.7031, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 26 loss is 55064.608323317305\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55096.0234, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 27 loss is 55065.77184606482\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55079.2109, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 28 loss is 55066.25181361607\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54686.2070, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 29 loss is 55053.14682112069\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55085.6875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 30 loss is 55054.23151041667\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54897.1172, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 31 loss is 55049.16330645161\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55048.5391, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 32 loss is 55049.143798828125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55089.2969, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 33 loss is 55050.36055871212\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55009.0078, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 34 loss is 55049.14430147059\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55028.4922, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 35 loss is 55048.554241071426\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55089.4375, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 36 loss is 55049.68988715278\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54927.4531, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 37 loss is 55046.38619087838\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55086.5117, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 38 loss is 55047.44212582237\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55100.7266, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 39 loss is 55048.808393429485\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55077.7734, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 40 loss is 55049.53251953125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55111.6406, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 41 loss is 55051.04735137195\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55114.6445, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 42 loss is 55052.56156994047\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54954.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 43 loss is 55050.27234738372\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55118.3203, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 44 loss is 55051.818892045456\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54976.0820, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 45 loss is 55050.135850694445\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55153.6328, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 46 loss is 55052.385784646736\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55113.1641, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 47 loss is 55053.67893949468\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55109.2148, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 48 loss is 55054.8359375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55073.0664, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 49 loss is 55055.207987882655\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55023.5547, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 50 loss is 55054.574921875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55110.5625, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 51 loss is 55055.67271752451\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55108.0703, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 52 loss is 55056.680363581734\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55109.9258, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 53 loss is 55057.68499410377\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55069.7852, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 54 loss is 55057.909071180555\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55034.5352, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 55 loss is 55057.48409090909\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55091.1797, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 56 loss is 55058.08579799107\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55102.4102, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 57 loss is 55058.863418311405\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55096.7969, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 58 loss is 55059.517443426725\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55053.1562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 59 loss is 55059.40962658898\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55123.1914, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 60 loss is 55060.47265625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55097.7812, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 61 loss is 55061.08427254098\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55073.8438, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 62 loss is 55061.290070564515\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55126.9141, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 63 loss is 55062.331721230155\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55066.7461, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 64 loss is 55062.40069580078\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55075.3672, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 65 loss is 55062.600180288464\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55090.7656, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 66 loss is 55063.02692945076\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55085.2070, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 67 loss is 55063.35797574627\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55138.2891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 68 loss is 55064.45990349265\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54954.4141, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 69 loss is 55062.86503623189\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54945.1836, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 70 loss is 55061.183872767855\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55016.8555, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 71 loss is 55060.55952904929\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55027.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 72 loss is 55060.1025390625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55159.4531, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 73 loss is 55061.46350599315\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55053.0234, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 74 loss is 55061.34945101351\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55133.5547, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 75 loss is 55062.3121875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55053.8906, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 76 loss is 55062.20137746711\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55119.6016, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 77 loss is 55062.94683441558\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55125.5547, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 78 loss is 55063.74949919872\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55048.0820, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 79 loss is 55063.55117681962\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55085.8828, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 80 loss is 55063.830322265625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55077.2227, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 81 loss is 55063.99565972222\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55066.8281, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 82 loss is 55064.03020198171\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54929.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 83 loss is 55062.4093561747\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55089.4922, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 84 loss is 55062.731770833336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55083.1562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 85 loss is 55062.97205882353\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55060.2891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 86 loss is 55062.94086119186\n",
            "Training EPOCH :  34\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 55062.94086119186\n",
            "L2 distance is : 0.0\n",
            "L1 distance is : 0.0\n",
            "Cosine Similarity is : 0.0\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55060.9609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 1 loss is 55060.9609375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54966.8789, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 2 loss is 55013.919921875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55139.9805, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 3 loss is 55055.940104166664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54954.1328, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 4 loss is 55030.48828125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54915.3203, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 5 loss is 55007.4546875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55070.1719, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 6 loss is 55017.907552083336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55108.5352, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 7 loss is 55030.85435267857\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55128.4570, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 8 loss is 55043.0546875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54916.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 9 loss is 55028.979166666664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55117.5078, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 10 loss is 55037.83203125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55098.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 11 loss is 55043.31321022727\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55071.0039, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 12 loss is 55045.620768229164\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54932.4922, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 13 loss is 55036.91856971154\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55101.6484, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 14 loss is 55041.54213169643\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55003.1641, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 15 loss is 55038.98359375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55115.6641, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 16 loss is 55043.776123046875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55195.2969, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 17 loss is 55052.68910845588\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55060.2891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 18 loss is 55053.111328125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55125.4531, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 19 loss is 55056.91879111842\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54858.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 20 loss is 55047.0197265625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55065.9062, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 21 loss is 55047.91908482143\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55115.1875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 22 loss is 55050.976740056816\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55121.4062, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 23 loss is 55054.03889266304\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54601.3594, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 24 loss is 55035.17724609375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55122.7266, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 25 loss is 55038.67921875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55049.5703, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 26 loss is 55039.098106971156\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55088.8359, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 27 loss is 55040.94024884259\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55051.8516, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 28 loss is 55041.32993861607\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54561.6328, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 29 loss is 55024.788658405174\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55075.0898, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 30 loss is 55026.46536458333\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54817.5078, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 31 loss is 55019.7247983871\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55009.6016, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 32 loss is 55019.408447265625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55075.2031, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 33 loss is 55021.09919507576\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54966.7812, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 34 loss is 55019.50160845588\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55013.6875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 35 loss is 55019.335491071426\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55065.4062, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 36 loss is 55020.615234375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54877.5820, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 37 loss is 55016.74947212838\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55065.9766, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 38 loss is 55018.044921875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55091.7539, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 39 loss is 55019.934895833336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55061.7617, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 40 loss is 55020.98056640625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55106.1953, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 41 loss is 55023.05897484756\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55097.3711, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 42 loss is 55024.82831101191\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54903.2695, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 43 loss is 55022.00136264535\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55113.7578, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 44 loss is 55024.086736505684\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54932.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 45 loss is 55022.054947916666\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55151.5391, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 46 loss is 55024.869819972824\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55106.1836, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 47 loss is 55026.59990026596\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55092.5352, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 48 loss is 55027.97355143229\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55051.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 49 loss is 55028.45878507653\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54993.8320, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 50 loss is 55027.76625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55101.7539, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 51 loss is 55029.216988357846\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55100.4727, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 52 loss is 55030.58728966346\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55095.4688, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 53 loss is 55031.81146816038\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55056.9648, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 54 loss is 55032.27727141204\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55013.2891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 55 loss is 55031.93203125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55078.2539, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 56 loss is 55032.75920758928\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55091.1875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 57 loss is 55033.78426535088\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55082.1797, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 58 loss is 55034.618669181036\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55029.3164, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 59 loss is 55034.5288003178\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55108.2734, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 60 loss is 55035.75787760417\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55080.8438, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 61 loss is 55036.496990266394\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55050.2734, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 62 loss is 55036.71919102823\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55118.7344, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 63 loss is 55038.02101934524\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55042.9688, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 64 loss is 55038.09832763672\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55054.4844, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 65 loss is 55038.35042067308\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55074.6328, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 66 loss is 55038.900153882576\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55072.7383, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 67 loss is 55039.405200559704\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55127.0156, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 68 loss is 55040.69358915441\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54898.6445, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 69 loss is 55038.6349071558\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54904.5391, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 70 loss is 55036.71925223214\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54984.3086, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 71 loss is 55035.981073943665\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55004.0469, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 72 loss is 55035.53754340278\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55157.7773, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 73 loss is 55037.21206121575\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55035.3281, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 74 loss is 55037.18660261824\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55126.9141, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 75 loss is 55038.38296875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55026.7617, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 76 loss is 55038.23005756579\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55116.4883, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 77 loss is 55039.24639813312\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55124.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 78 loss is 55040.333784054485\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55030.8789, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 79 loss is 55040.21410205696\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55072.4922, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 80 loss is 55040.617578125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55045.1562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 81 loss is 55040.67361111111\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55043.0469, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 82 loss is 55040.70255335366\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54874.8281, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 83 loss is 55038.70406626506\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55080.6953, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 84 loss is 55039.20396205357\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55044.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 85 loss is 55039.268106617645\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55036.6406, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 86 loss is 55039.23755450582\n",
            "Training EPOCH :  35\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 55039.23755450582\n",
            "L2 distance is : 0.0\n",
            "L1 distance is : 0.0\n",
            "Cosine Similarity is : 0.0\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55045.3398, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 1 loss is 55045.33984375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54928.9688, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 2 loss is 54987.154296875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55138.3594, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 3 loss is 55037.555989583336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54909.3633, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 4 loss is 55005.5078125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54875.5391, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 5 loss is 54979.5140625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55051.8008, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 6 loss is 54991.561848958336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55101.5078, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 7 loss is 55007.26841517857\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55128.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 8 loss is 55022.40673828125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54855.4570, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 9 loss is 55003.856770833336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55110.6250, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 10 loss is 55014.53359375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55092.0859, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 11 loss is 55021.583806818184\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55057.1484, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 12 loss is 55024.547526041664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54896.0195, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 13 loss is 55014.66075721154\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55079.7188, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 14 loss is 55019.30775669643\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54967.9102, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 15 loss is 55015.88125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55109.3828, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 16 loss is 55021.72509765625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55192.6055, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 17 loss is 55031.776884191175\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55038.8047, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 18 loss is 55032.167317708336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55117.3164, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 19 loss is 55036.64884868421\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54791.9453, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 20 loss is 55024.413671875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55044.7695, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 21 loss is 55025.38299851191\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55110.4844, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 22 loss is 55029.25124289773\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55120.2109, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 23 loss is 55033.206012228264\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54505.6953, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 24 loss is 55011.226399739586\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55112.4375, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 25 loss is 55015.27484375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55023.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 26 loss is 55015.57436899038\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55079.7969, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 27 loss is 55017.95298032407\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55024.4648, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 28 loss is 55018.185546875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54458.5156, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 29 loss is 54998.886584051725\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55067.4609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 30 loss is 55001.17239583333\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54743.9062, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 31 loss is 54992.87348790323\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54977.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 32 loss is 54992.39306640625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55063.1055, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 33 loss is 54994.53586647727\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54933.5078, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 34 loss is 54992.74092371324\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55001.4922, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 35 loss is 54992.99095982143\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55041.1562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 36 loss is 54994.32888454861\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54836.8203, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 37 loss is 54990.07189611487\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55041.9688, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 38 loss is 54991.43760279605\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55084.4219, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 39 loss is 54993.821814903844\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55048.6406, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 40 loss is 54995.19228515625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55101.2656, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 41 loss is 54997.77943978659\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55081.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 42 loss is 54999.772786458336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54856.0469, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 43 loss is 54996.43032340116\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55109.7734, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 44 loss is 54999.006303267044\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54893.0312, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 45 loss is 54996.65130208333\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55148.9609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 46 loss is 54999.96238111413\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55098.9180, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 47 loss is 55002.067819148935\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55075.5156, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 48 loss is 55003.597981770836\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55031.9609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 49 loss is 55004.17681760204\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54971.4609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 50 loss is 55003.5225\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55093.1992, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 51 loss is 55005.280867034315\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55093.6406, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 52 loss is 55006.98009314904\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55081.8945, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 53 loss is 55008.39357311321\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55045.3594, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 54 loss is 55009.078125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54994.2422, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 55 loss is 55008.80838068182\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55065.3398, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 56 loss is 55009.81787109375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55081.4219, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 57 loss is 55011.074081688595\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55067.3516, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 58 loss is 55012.0443830819\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55008.8906, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 59 loss is 55011.99092955508\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55092.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 60 loss is 55013.325455729166\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55063.0234, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 61 loss is 55014.14017674181\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55025.8867, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 62 loss is 55014.32963709677\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55106.4453, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 63 loss is 55015.7917906746\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55017.7148, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 64 loss is 55015.821838378906\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55034.8203, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 65 loss is 55016.114122596155\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55057.0547, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 66 loss is 55016.73443418561\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55060.0547, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 67 loss is 55017.3810051306\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55115.8867, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 68 loss is 55018.829618566175\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54853.0234, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 69 loss is 55016.426630434784\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54863.2070, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 70 loss is 55014.23777901786\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54958.1953, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 71 loss is 55013.44844850352\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54985.0234, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 72 loss is 55013.05365668403\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55154.4219, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 73 loss is 55014.99020761986\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55022.5703, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 74 loss is 55015.09264146959\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55119.7383, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 75 loss is 55016.487916666665\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55003.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 76 loss is 55016.32277960526\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55113.1641, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 77 loss is 55017.580458603894\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55120.0469, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 78 loss is 55018.89413060898\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55017.3086, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 79 loss is 55018.874060522154\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55059.9688, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 80 loss is 55019.38774414062\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55013.0898, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 81 loss is 55019.309992283954\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55025.4609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 82 loss is 55019.385003810974\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54815.5820, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 83 loss is 55016.92954631024\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55071.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 84 loss is 55017.58440290178\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55011.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 85 loss is 55017.50840992647\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55013.9219, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 86 loss is 55017.46670603198\n",
            "Training EPOCH :  36\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 55017.46670603198\n",
            "L2 distance is : 0.0\n",
            "L1 distance is : 0.0\n",
            "Cosine Similarity is : 0.0\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55031.2109, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 1 loss is 55031.2109375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54897.9141, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 2 loss is 54964.5625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55134.0703, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 3 loss is 55021.065104166664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54864.2656, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 4 loss is 54981.865234375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54840.4688, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 5 loss is 54953.5859375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55034.9180, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 6 loss is 54967.141276041664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55094.0703, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 7 loss is 54985.27399553572\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55127.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 8 loss is 55002.99755859375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54807.3633, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 9 loss is 54981.260416666664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55101.7578, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 10 loss is 54993.31015625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55087.1406, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 11 loss is 55001.84019886364\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55048.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 12 loss is 55005.707682291664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54861.6328, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 13 loss is 54994.625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55057.5391, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 14 loss is 54999.118861607145\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54935.3516, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 15 loss is 54994.86770833333\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55103.6328, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 16 loss is 55001.66552734375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55190.0469, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 17 loss is 55012.74678308824\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55020.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 18 loss is 55013.19487847222\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55108.2422, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 19 loss is 55018.19736842105\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54732.5547, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 20 loss is 55003.915234375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55026.9062, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 21 loss is 55005.010044642855\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55106.4883, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 22 loss is 55009.62269176136\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55119.4102, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 23 loss is 55014.39605978261\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54420.5820, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 24 loss is 54989.65380859375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55103.6328, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 25 loss is 54994.21296875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54997.9766, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 26 loss is 54994.357722355766\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55071.4219, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 27 loss is 54997.21195023148\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54997.9062, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 28 loss is 54997.23674665178\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54371.4336, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 29 loss is 54975.65732758621\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55061.6172, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 30 loss is 54978.52265625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54677.1641, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 31 loss is 54968.801411290326\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54952.6328, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 32 loss is 54968.296142578125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55052.2617, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 33 loss is 54970.84055397727\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54907.8672, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 34 loss is 54968.988396139706\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54990.6055, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 35 loss is 54969.60602678572\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55019.4844, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 36 loss is 54970.991536458336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54800.7891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 37 loss is 54966.39146959459\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55017.4180, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 38 loss is 54967.73427220395\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55077.0664, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 39 loss is 54970.537660256414\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55037.4648, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 40 loss is 54972.21083984375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55096.7656, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 41 loss is 54975.24876143293\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55067.3164, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 42 loss is 54977.44084821428\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54813.5195, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 43 loss is 54973.628724563954\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55106.2070, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 44 loss is 54976.64186789773\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54858.2734, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 45 loss is 54974.011458333334\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55146.3438, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 46 loss is 54977.7578125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55091.8594, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 47 loss is 54980.18550531915\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55061.8008, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 48 loss is 54981.88582356771\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55014.1875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 49 loss is 54982.54504145408\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54955.6992, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 50 loss is 54982.008125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55085.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 51 loss is 54984.04350490196\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55087.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 52 loss is 54986.03786057692\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55068.6914, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 53 loss is 54987.59736143868\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55034.3945, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 54 loss is 54988.463975694445\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54976.1094, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 55 loss is 54988.23934659091\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55053.2969, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 56 loss is 54989.401088169645\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55072.4766, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 57 loss is 54990.85855263158\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55053.1172, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 58 loss is 54991.93197737069\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54991.3398, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 59 loss is 54991.92194120763\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55075.3867, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 60 loss is 54993.31302083333\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55049.5781, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 61 loss is 54994.235399590165\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55001.1719, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 62 loss is 54994.3472782258\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55092.7461, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 63 loss is 54995.90916418651\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54991.7734, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 64 loss is 54995.84454345703\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55016.9609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 65 loss is 54996.169411057694\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55039.2695, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 66 loss is 54996.822443181816\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55048.3984, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 67 loss is 54997.59223414179\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55105.5391, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 68 loss is 54999.1796875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54814.4258, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 69 loss is 54996.5020946558\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54823.6016, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 70 loss is 54994.03208705357\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54938.0273, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 71 loss is 54993.243287852114\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54970.8164, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 72 loss is 54992.931803385414\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55150.9219, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 73 loss is 54995.09605094178\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55014.4414, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 74 loss is 54995.35747466216\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55113.1875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 75 loss is 54996.92854166667\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54986.8047, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 76 loss is 54996.79533305921\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55109.3594, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 77 loss is 54998.25720373377\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55116.2656, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 78 loss is 54999.77013221154\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55005.0547, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 79 loss is 54999.837025316454\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55048.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 80 loss is 55000.440625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54984.8828, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 81 loss is 55000.24855324074\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55010.9648, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 82 loss is 55000.37923971037\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54753.6875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 83 loss is 54997.4070500753\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55064.2969, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 84 loss is 54998.20335751488\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54983.1016, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 85 loss is 54998.02568933823\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54993.6719, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 86 loss is 54997.975063590115\n",
            "Training EPOCH :  37\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 54997.975063590115\n",
            "L2 distance is : 0.0\n",
            "L1 distance is : 0.0\n",
            "Cosine Similarity is : 0.0\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55018.2227, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 1 loss is 55018.22265625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54873.5625, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 2 loss is 54945.892578125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55127.5742, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 3 loss is 55006.453125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54819.8750, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 4 loss is 54959.80859375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54807.8438, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 5 loss is 54929.415625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55020.2578, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 6 loss is 54944.555989583336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55086.0469, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 7 loss is 54964.76897321428\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55125.0547, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 8 loss is 54984.8046875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54768.9609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 9 loss is 54960.82204861111\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55092.4336, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 10 loss is 54973.983203125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55082.8086, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 11 loss is 54983.876420454544\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55042.1484, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 12 loss is 54988.732421875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54828.8359, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 13 loss is 54976.432692307695\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55036.1328, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 14 loss is 54980.696986607145\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54907.1172, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 15 loss is 54975.791666666664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55098.5078, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 16 loss is 54983.46142578125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55186.8242, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 17 loss is 54995.423943014706\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55005.6875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 18 loss is 54995.994140625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55100.1328, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 19 loss is 55001.47512335526\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54679.4258, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 20 loss is 54985.37265625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55011.1250, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 21 loss is 54986.598958333336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55103.3164, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 22 loss is 54991.904296875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55118.5117, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 23 loss is 54997.408967391304\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54342.5156, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 24 loss is 54970.121744791664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55096.3672, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 25 loss is 54975.1715625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54975.7305, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 26 loss is 54975.193058894234\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55064.8086, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 27 loss is 54978.51215277778\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54973.6641, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 28 loss is 54978.33900669643\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54296.0391, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 29 loss is 54954.81142241379\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55056.5195, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 30 loss is 54958.20169270833\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54614.9688, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 31 loss is 54947.12966229839\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54930.2891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 32 loss is 54946.60339355469\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55042.2188, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 33 loss is 54949.50082859849\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54884.7969, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 34 loss is 54947.597771139706\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54980.2422, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 35 loss is 54948.53046875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55002.7266, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 36 loss is 54950.03591579861\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54767.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 37 loss is 54945.10926942567\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54994.0312, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 38 loss is 54946.39668996711\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55069.3438, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 39 loss is 54949.5491786859\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55027.7656, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 40 loss is 54951.50458984375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55092.1484, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 41 loss is 54954.934927591465\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55056.2734, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 42 loss is 54957.347749255954\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54775.2148, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 43 loss is 54953.112100290695\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55103.2695, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 44 loss is 54956.52476917614\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54826.9531, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 45 loss is 54953.645399305555\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55143.8828, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 46 loss is 54957.78099524457\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55085.1953, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 47 loss is 54960.491938164894\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55050.2188, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 48 loss is 54962.36124674479\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54997.5977, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 49 loss is 54963.080357142855\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54943.9375, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 50 loss is 54962.6975\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55079.5312, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 51 loss is 54964.98835784314\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55082.6914, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 52 loss is 54967.251878004805\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55056.1641, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 53 loss is 54968.929466391506\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55024.9258, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 54 loss is 54969.96643518518\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54959.6875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 55 loss is 54969.77954545455\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55042.0234, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 56 loss is 54971.069614955355\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55064.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 57 loss is 54972.71148574561\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55039.2148, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 58 loss is 54973.85809536638\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54976.2812, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 59 loss is 54973.8991657839\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55059.1016, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 60 loss is 54975.31920572917\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55041.6797, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 61 loss is 54976.407082479505\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54975.8711, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 62 loss is 54976.3984375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55079.7383, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 63 loss is 54978.038752480155\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54963.9102, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 64 loss is 54977.81799316406\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54998.8164, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 65 loss is 54978.141045673074\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55021.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 66 loss is 54978.802734375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55037.2344, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 67 loss is 54979.67484841418\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55095.9766, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 68 loss is 54981.38516773897\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54778.9102, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 69 loss is 54978.45074728261\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54783.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 70 loss is 54975.66216517857\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54920.3203, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 71 loss is 54974.88270246479\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54960.1445, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 72 loss is 54974.67800564236\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55147.4805, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 73 loss is 54977.04516267123\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55008.0898, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 74 loss is 54977.46468538851\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55107.5000, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 75 loss is 54979.19848958333\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54972.9062, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 76 loss is 54979.11569695724\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55105.9453, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 77 loss is 54980.76283482143\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55113.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 78 loss is 54982.46299078526\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54993.6875, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 79 loss is 54982.60507318038\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55036.8438, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 80 loss is 54983.28305664063\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54961.1367, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 81 loss is 54983.00964506173\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54996.7656, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 82 loss is 54983.17740091463\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54685.0820, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 83 loss is 54979.58589043675\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55057.7383, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 84 loss is 54980.516276041664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54958.5781, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 85 loss is 54980.25818014706\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54974.8398, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 86 loss is 54980.195176235466\n",
            "Training EPOCH :  38\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 54980.195176235466\n",
            "L2 distance is : 0.0\n",
            "L1 distance is : 0.0\n",
            "Cosine Similarity is : 0.0\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55005.4922, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 1 loss is 55005.4921875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54851.4883, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 2 loss is 54928.490234375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55120.5312, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 3 loss is 54992.50390625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54771.7695, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 4 loss is 54937.3203125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54773.2695, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 5 loss is 54904.51015625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55006.7617, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 6 loss is 54921.552083333336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55077.2422, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 7 loss is 54943.79352678572\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55123.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 8 loss is 54966.2255859375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54731.5469, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 9 loss is 54940.15017361111\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55082.9219, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 10 loss is 54954.42734375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55078.3438, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 11 loss is 54965.69247159091\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55036.1953, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 12 loss is 54971.567708333336\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54795.6406, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 13 loss is 54958.034855769234\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55016.1445, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 14 loss is 54962.185546875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54880.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 15 loss is 54956.756510416664\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55093.4648, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 16 loss is 54965.30078125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55183.9141, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 17 loss is 54978.16038602941\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54990.6797, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 18 loss is 54978.85590277778\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55093.0508, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 19 loss is 54984.86615953947\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54622.3242, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 20 loss is 54966.7390625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54995.5391, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 21 loss is 54968.11049107143\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55100.8320, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 22 loss is 54974.14328835227\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55117.0938, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 23 loss is 54980.358525815216\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54263.7500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 24 loss is 54950.499837239586\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55089.9141, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 25 loss is 54956.07640625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54955.5469, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 26 loss is 54956.05603966346\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55059.1641, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 27 loss is 54959.87485532407\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54949.7891, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 28 loss is 54959.5146484375\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54223.7148, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 29 loss is 54934.14224137931\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55051.1133, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 30 loss is 54938.041276041666\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54551.9336, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 31 loss is 54925.58618951613\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54908.6172, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 32 loss is 54925.055908203125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55032.1094, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 33 loss is 54928.29995265151\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54862.1094, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 34 loss is 54926.35317095588\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54969.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 35 loss is 54927.59040178572\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54989.5703, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 36 loss is 54929.31206597222\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54734.6328, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 37 loss is 54924.05046452703\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54968.2109, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 38 loss is 54925.21258223684\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55062.2500, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 39 loss is 54928.726362179485\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55018.0938, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 40 loss is 54930.960546875\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55086.8242, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 41 loss is 54934.76209984756\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55048.8125, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 42 loss is 54937.47758556547\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54736.6484, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 43 loss is 54932.807140261626\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55100.3281, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 44 loss is 54936.614435369316\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54794.1016, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 45 loss is 54933.44748263889\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55141.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 46 loss is 54937.973760190216\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55079.6055, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 47 loss is 54940.98720079787\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55039.9062, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 48 loss is 54943.048014322914\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54980.0938, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 49 loss is 54943.8040497449\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54934.3906, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 50 loss is 54943.61578125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55074.2734, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 51 loss is 54946.177696078434\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55077.2617, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 52 loss is 54948.698542668266\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55044.6094, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 53 loss is 54950.50818101415\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55017.0156, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 54 loss is 54951.73980034722\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54944.6484, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 55 loss is 54951.61086647727\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55030.7188, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 56 loss is 54953.02350725447\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55057.9844, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 57 loss is 54954.86492598684\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55025.1719, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 58 loss is 54956.07711476293\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54962.9844, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 59 loss is 54956.19418697034\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55043.3945, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 60 loss is 54957.64752604167\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55035.7109, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 61 loss is 54958.92725409836\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54947.0625, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 62 loss is 54958.73588709677\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55067.7734, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 63 loss is 54960.46664186508\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54930.4648, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 64 loss is 54959.99786376953\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54977.9766, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 65 loss is 54960.27445913461\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55003.3125, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 66 loss is 54960.92655066288\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55024.8672, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 67 loss is 54961.88088852612\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55087.7734, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 68 loss is 54963.732249540444\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54746.0977, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 69 loss is 54960.578125\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54736.3750, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 70 loss is 54957.37522321429\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54903.3438, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 71 loss is 54956.61421654929\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54951.3125, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 72 loss is 54956.54058159722\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55145.2266, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 73 loss is 54959.12532106164\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55001.6641, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 74 loss is 54959.70016891892\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55103.2422, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 75 loss is 54961.6140625\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54960.2109, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 76 loss is 54961.59560032895\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55103.1953, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 77 loss is 54963.43455762987\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55111.4492, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 78 loss is 54965.33218149038\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54983.0859, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 79 loss is 54965.556912579115\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55025.5312, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 80 loss is 54966.30659179688\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54937.4766, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 81 loss is 54965.95066550926\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54982.5898, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 82 loss is 54966.15358231707\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54594.5703, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 83 loss is 54961.67667545181\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(55051.4375, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 84 loss is 54962.74525669643\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54933.4922, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 85 loss is 54962.40110294118\n",
            "torch.Size([1, 3, 224, 224]) torch.Size([1, 3, 224, 224])\n",
            "tensor(54954.9609, device='cuda:0', grad_fn=<SumBackward0>)\n",
            "batch is 86 loss is 54962.314589389534\n",
            "Training EPOCH :  39\n",
            "total batches processed : 86\n",
            "total examples processed : 86\n",
            "Total loss is : 54962.314589389534\n",
            "L2 distance is : 0.0\n",
            "L1 distance is : 0.0\n",
            "Cosine Similarity is : 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfgOngBiEPw-"
      },
      "source": [
        "model_weights_path = '/content/drive/MyDrive/S2FD/Model/decoder_weights_epoch_13_l1_loss.pt'\n",
        "torch.save(decoder.state_dict(),model_weights_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4srPRpzdEVJC"
      },
      "source": [
        "model_weights_path = '/content/drive/MyDrive/Decoder/decoder_weights_epoch_7_l1_loss.pt'\n",
        "decoder.load_state_dict(torch.load(model_weights_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT8PKG7vEXyp"
      },
      "source": [
        "def decoder_eval(image_path_list,spec_dict):\n",
        "  decoder.eval()\n",
        "  audio_encoder.eval()\n",
        "\n",
        "  y = extract_faces_features(image_path_list).to(device) #real image\n",
        "  X_d = extract_image_features(image_path_list).to(device) #image->vgg\n",
        "\n",
        "  y_vgg = decoder.forward(X_d) # predicted image from vgg features\n",
        "\n",
        "\n",
        "  X_spec = torch.tensor([np.transpose(spec_dict,(2,1,0)) ]).to(device) # spectrogram \n",
        "  y_vgg_pred = audio_encoder.forward(X_spec) # predicted vgg_features\n",
        "  y_pred = decoder.forward(y_vgg_pred) # predicted image from raw waveform\n",
        "\n",
        "  cosine_pred_image = cosine_similarity(y_vgg , y_pred).mean().item()\n",
        "  #cosine_actual_image = cosine_similarity(y,y_pred).item()\n",
        "\n",
        "  y = y.permute(0,2,3,1)\n",
        "  y = y.cpu().detach().numpy()\n",
        "\n",
        "  y_pred = y_pred.permute(0,2,3,1)\n",
        "  y_pred = y_pred.cpu().detach().numpy()\n",
        "\n",
        "  y_vgg = y_vgg.permute(0,2,3,1)\n",
        "  y_vgg = y_vgg.cpu().detach().numpy()\n",
        "\n",
        "  #print(y_pred.shape)\n",
        "  #y_pred = y_pred.reshape(-1,224,224,3)*255)\n",
        "  std = np.array([ 0.224, 0.225, 0.229 ]).reshape(1,1,3)\n",
        "  mean = np.array([ 0.456, 0.406, 0.485 ]).reshape(1,1,3)\n",
        "  for i in range(y_vgg.shape[0]):\n",
        "    y_vgg[i] = np.multiply(y_vgg[i],std) + mean\n",
        "    y[i] = np.multiply(y[i],std) + mean\n",
        "    y_pred[i] = np.multiply(y_pred[i],std) + mean\n",
        "  #y_pred.shape\n",
        "\n",
        "  w=3\n",
        "  h=y.shape[0]\n",
        "  \n",
        "  no=1\n",
        "  \n",
        "  for i in range(h):\n",
        "\n",
        "    fig=plt.figure(figsize=(9,9))\n",
        "\n",
        "    fig.add_subplot(1,w,1)\n",
        "    plt.imshow(y[i])\n",
        "    no+=1\n",
        "    fig.add_subplot(1,w,2)\n",
        "    #print(y_vgg[i].shape)\n",
        "    plt.imshow(y_vgg[i])\n",
        "    no+=1\n",
        "    fig.add_subplot(1,w,3)\n",
        "    #print(y_pred[i].shape)\n",
        "    plt.imshow(y_pred[i])\n",
        "    no+=1\n",
        "  \n",
        "  dist_vgg_l1 = l1_dist(X_d , y_vgg_pred).item()\n",
        "  dist_vgg_l2 = l2_dist(X_d , y_vgg_pred).item()\n",
        "  cosine_similarity_vgg = cosine_similarity(X_d , y_vgg_pred).mean().item()\n",
        "\n",
        "\n",
        "  print('L1 distance between actual and predicted VGG features is : {}'.format(dist_vgg_l1))\n",
        "  print('L2 distance between actual and predicted VGG features is : {}'.format(dist_vgg_l2))\n",
        "  print('Cosine Similarity between actual and predicted VGG features is : {}'.format(cosine_similarity_vgg))\n",
        "  print('Cosine Similarity between actual vgg image and predicted image : {}'.format(cosine_pred_image))\n",
        "  #print('Cosine Similarity between actual actual image and predicted image : {}'.format(cosine_actual_image))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gugH9SwhEoFX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "195f5637-f798-4cf2-d643-0278c5e36d35"
      },
      "source": [
        "i = 73\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    try:\n",
        "      X = torch.load('/content/drive/MyDrive/vgg/vgg_image_features_'+str(i))\n",
        "    except:\n",
        "      print('vgg file missing')\n",
        "      \n",
        "\n",
        "    f = open('/content/drive/MyDrive/spectrogram/spectrograms_'+str(i)+'.pk','rb')\n",
        "    spec_dict = pickle.load(f)\n",
        "    image_path_list = ['/content/drive/MyDrive/reference/'+str(i)+'.jpg' for key in spec_dict] \n",
        "\n",
        "    print(i)\n",
        "    decoder_eval(image_path_list , spec_dict)\n",
        "    print('****************************************************************')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "L1 distance between actual and predicted VGG features is : 26.242128372192383\n",
            "L2 distance between actual and predicted VGG features is : 0.7332481741905212\n",
            "Cosine Similarity between actual and predicted VGG features is : 0.7311735153198242\n",
            "Cosine Similarity between actual vgg image and predicted image : 0.557323694229126\n",
            "****************************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh4AAAC2CAYAAACWE4TgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9SawtSZrn9TMzn8587rnjm8eYMjKzMnJqugGxAdQ7kLoEzQZoFV2bYo1YgBASvWcH1VKzYQFCtJAQaoFEIxZdVNM5dGZVjjG8eBFvuPO9Z/TZ7GNhfob7IjKysisjI0rc78mf+znHj7mZuR/7/vb//vZdJSJc27Vd27Vd27Vd27X9Lkx/0RW4tmu7tmu7tmu7tv//2DXwuLZru7Zru7Zru7bfmV0Dj2u7tmu7tmu7tmv7ndk18Li2a7u2a7u2a7u235ldA49ru7Zru7Zru7Zr+53ZNfC4tmu7tmu7tmu7tt+ZfW7AQyn1N5VSv1RKva+U+k8/r+tc27V9Xnb9DF/bX3W7foav7cto6vPI46GUMsC7wL8BPAe+B/x7IvKz3/rFru3aPge7foav7a+6XT/D1/Zltc+L8fgu8L6IPBGREvgfgX/rc7rWtV3b52HXz/C1/VW362f42r6UFnxO5d4Cnm28fg78tc0TlFJ/CPwhQBiE39oe7jSfeAZGAUprtFLojb1Syn+G8iex2n3i2JM54re/DLMjIGx8/1eUJVf/e+X7n/L+p5W9cQ21edInd942G8yv++DqdUQ+4/tytVaybkTTRPn041fr+WrTrlxPrr5Uy//kE2V94vubt+OVU15enp+JyC5/OfuNn+HRcBuFIggMzlqsCFrrVR+J4F83fWuURhtNXVeICCYIcM75/lSglcFaiwICY3AiWGfRSoFSTZmC0goRBeLQSmG0xjqHFcEYgzi3WWes8/0eaoVDYZ31vyul1ucq//sSJ+jm+tZaLE0bmt+UAFpprPjXRmv/2lpENec6h4iAUv4zZzf6yWHFobUGBOUEB02b/M01yo8F1joEQS/bJOKvoTTOORSK0GicE6w4aNqECE4ErRWuGQq0gkAbrLPNZwaRZT2bNjX9FDT3cNVPG21Szb1wzmEAExhc7bDI6l5fqacIWgStlB+Zmj5USiEbv6Ojs6PfyTP86nMcBeG3dobbKEAr5e/rsn6AEn9/tFr/vpdj8rItKIVatmX5qLpmlqvUaixRCn+vm6Fls0ya66/L5Mq4ohU42SyT1TWd+mSZzW39RJnL91dlNvVB+YFGNefKRpnNR1fKdEuf0FzvU9ukGr/1Sj3XN6J5NptrOOEzy1xf/5VzN9qkNl6rVyr+aX3/qW3asFWZgN70H82pbn3IeDYhzdNP9TCfF/D4tSYifx/4+wA39m7J3/lbf4g4h0LQyhFoTSuO/ZYktJKEdpIQBSGmGVx1c+MUCq18ZylocIbzg4OrwNaI1J9SiWa/0TVXHoQGFEgzwItzuOZ4+fCo5qnwg5bfOxFkOcKxPn8JhFbl/YoNEbSzaHHNj2n53VeqfwVxNW1vfoQb/fzK+b5ubgNYLMtZ/xjX9XAiuGW7m70T599rtuV54sA5EOcHeN/m9aPY+B5k2ckKlFoObE1vqqbPV9+RldNaDvLLsjYBimxc4z//n/77jz7ZW79923yGb+3flv/w3/m7vPX4Kzw/ec7l5SVvvvkVPnzyAeIsSkeUZU2cxFhbcv/hXaYXGYsix9Ulu3v7nJ8dkWUZiVKkInTbHWazKd/+xjd57913mWUL7t++xeHpKViHdpa6rpEwQCvDqNchDkImiznTNOPWzjZnswU292UuxJEkCYu84Dtf+QrvPvmAReXYGbZZZCWmdlRlDgK1UYRBAMqwPxhyPp8yXqQ8vnWTF2cXUJVECDMntOKYtKr46muP+PjFMZkt6IQxxhiyoqTKMkKEhYJO0iEvc772+mM+fPaS8WzG/Tt3eHl8jLGWyDlScYRRQOXg7s0DFtM58yLH2pphJ2GaWyTLaCu4QBjEMZOi4p2Hj/jw5Qsmec6dvS1Ox3O0CMrWVFaQMECUZtDtkpiQcTpjkeXc293mZDLH5jmBggWObtJilhd87fGbfPjsI7K6ZKfXIS1KnBOkKDAi5IEmDEKUMdzb2eZofMnFZM5r9w54fnhBWFUgQo4QxiF55bg7GnIxmVI7hzHNs1QJ2jlK/OD9X/7x3/udPMOvPse3d2/I3/39P2A3gEw0ee3ohzC3yjsaPBCNAxg7xdB4gFYCtXX0NMyVRteOUIEFVAizCu4lMKkUhRU6CvLGyVq8I+oomCiIgAQoUFRW6AFjDZHHkoQCEsJlDTcDmDTjTYigBfIG6MQKEgVzDc7CQMFCKawVOhqmQCxQAomADuDSwX4AC6uoAe2ESMECUA4i5etaGsisv/7UKWortBWkTVscEAKJhguBbgMOBA/828CkaZNp2lQFsLCwp2AGWIFIoGocfSW+PVHTT6FAG8gUVBaGGi4VxJaVb9QBXG7UE4HACVpBqkFZX14MTIzvtx0NKYqybvpJoC1QKDACkYGxg10DpfX3cAl8LFDh++GP/+E/+JXP3OcFPF4AdzZe327e+7WmmlmRNgZjDCYIMEFAYAzGBBht0NrPHjzzAWoJn9mApesS14ef4rzXZ6lXz/YOcgM9+rPWs5Irl1hB4uacV1DxJvr8VbYGKLJCn7+WqVki8xVbsFne8mADQK0+WML3jcZsHjdAaen43Wp/FXSsgIfz56+AhwPErUGELMHBsv+kuWWymkH4WXeDvDeAxHJ6pJRG6Q3kvmrer+mjfzH7jZ5hpaAVB8zzGUKLRw+2OXz6jCzPMUHEw1t3CUJDURSI1hwfX7B/Ywe5MGjT56OPP8K5iu3hDtvbWyincGVNK2pxdHpGtxOztT1kcn5OmqWA4v7eHlEU4MoMgojZxYxkN8HMhTvbWxyenpE7RzuO2d3qsW8C0jxlK2lx8uKQVitmbxAwnS+YLXIEYbfXZZgYtFOUUjNf1JTiQc6DvRHHR8cs6pooCNjf6rMfJdTlHGe6XJye0u13aFURylmOzi+pRNjp9NgedlEocmrqhWE8nhPgeHjrJofHJ2RFjtGGg91tDgJNUeQYHbI4uyQZDQisJWgnPD8fU4kwCEMGg5ChDrG2oBN1OB2PiQLD6zsjLidT0rz0N26rQyuKcdYiYch0XhBsd4nzBaP9bV6eXJDVNa24xc6wzYEy5FVOP2lzdnpMuxuzpVtUWcY8zXAi3Bx2GLRa1OKocaSTgrISwsrx8OYepy9OyauaWitudQ0m6ZAWOaN2l3yWEyURcVURKThJfT0NfkAuvqBnGLzDGhqwTmOV40YEC/EThBzYDSDQkDnYbwfY1JE7oRMKsYaTEmrlSAwM21DlHkAcJJqigsJZdgLIa++kagWjwDuvooZhpKAWFjWEodB1MFagtB9bRjEUJeQWbrWhLqBGGIbgKpgpsNqDjCSArIJuANpAWoLSwraBiQM0lALbMdgKMoGbLYXLhVKEnvGO/8KBaO/0uwmUBcRa0QsgKwSnha0AFs4DjmU/KQepwE4MUsO4hnbgQccUUMazBr0WlDkgsJNAUXiwMdRQOcjwr7eVBym5hVEIWEgthM09u3RgtO/XYQJ5AYXzbaoLoUQYGl/HGeA0DPAgMq+gayAMICvBGWGgIVVglS9nEPs+njs4SKCuPRhpaTC1B3C1gdpC+9eIOD4vjcf3gNeUUg+UUhHwt4H/9S/yxSUlpPUafATa+GOtm7CLXlHDfhK8nO1vFLI8VJ629eU13282pZX/TK2P2djUxix7eS1eee8vYvLK/spnm0zHyjVvMiBc3X5FOciSeWG9b5iSJX+wBBJOPEJ1bAKKhglxDbPhGqajec855+l767C1vbLVtcXamrr2W1VXzVZTVRV11byu/FZWJVVVUpbl6r26rqkqv9V1vS7fWn9N63ANFe4B1AaM2eif36L9Rs+wW9apdgy7A2ytqeqae7fugRjee/ouF7MZF7MxL148J4liAtPi5t27LMqC/d19kqTL5XjC049eMstznp8ekc9nGBFGW7v02gmLNOPhjbvESvHs+ITL6Zx5XnNyeILSjlYQsjcc4aqanW6X/W6Xuix5dnLBvKzIFyXT+RgRy263zfb2gGye8/rePh2lOJvOOZoWTCrL+WWKthWRVGwP+hjr6AUhNwZDtLV8dHrJuCiZpjXH5xdYcWxFEfujbcaTGfd3b9Ayhst0zsn5mFlVMT65oKxztFh2toYEcQDWcnd3n1iE58cnXKY589Jycn5GoC39OGRne0SxyLndHzAII9Kq5vAyZ1pZJjPLIp3RcjU7gy6tdgdX1Dzc2aevFC8uF1wsChal48XJJUpbWqFie2sXm1WMkoTtdhtX5rw8vWRe1SwWBePZBBHHTq/D3nBIsUh5eLBDXymOxwuOJwvy0nJ2OkVhadmS4WiIA5wJ2BkOUU54NqsZlxZXweV4jMXRdcJoq0de1NwYdGhrRYEfvH+Lg/JvPA4L3hlrESLxs25nNXvdNgMHRyWc1dASuJxX1OIZiTjUWAfbvRaDwJBZeDmHQiCshcvMYhAGBrSGWmDUDek5OCs9YAk0LAohr6FtwDTgIAwVQ60IgKPcA7PEwPnCO/eu+L110O8Y+rWf5Z8UfvzPSlgU0FLeSVsF2iiGoSESOMy9024puEjFl9PUMxfodDR98SDiJPOOHSvMcyHSnjHwZIJi1DZ0HByXcN6wCZc5VLV3xqbp4zhS9J3v38PUgwsDjDMIxDMQiO+nfgJ96/v9rPKM0KLwQK3VsBBOII40fa0JgMPMsw6R8W0SgS5NSMXBVjdkq4Jx009aQVlDVniWJsC30yrYCj0AO8k9YEsC3yZbQ6Q9eFIKggjaTaQ2d3ymfS6Mh4jUSqn/GPg/mv7870Tkp7/mO6xmthvgwLMepmE6TAM82GA7mnDLBgBZxmk9MNAorRsiZJMNETYVBkvGYx2zEkQpaGLHDgdKo/A9qpvrrOfvVyHB0gluvnuF0ViBjQ1WwW187pbhGscKVa2YlU/We9PprgIVK+akcYorELJx7c17wJo9cE0M27mrLIe1FutsA07cBjixiAjWquY1PvzE1TaDa+rqmng5DYjD36dNENkcyPJeru6pZ5dWoONXhKL+MvabPsNaGxaZxdopOrxA6RAzGPLs8JDdvX0WacbZ5YK93R5GaS4vLzi/nNAablGmU1Tcw9U1uzsjFqXm5dElX339MT//xU+pz045OnlBK+nSjhMOjw/pdHqIE2ZFRttEbA8GvJhNST9+TtJKKKuaWAmXRcVWr4eqS07Ozrm/f8Dp+JizLGWWz9EXXcIg5OzsHIxiGBicWKaZ486oy5PzKYvTC1rtBGshCEMup1O2ui2ktlyeX3Jzbw81n3A+SUnHC0y7S6wV08kZShuGrR7O1ZyeXfL45gEfHh1SFiegBBO06cYJp2entNsdQqmYTmcM+n1anZiTtGby5BkmjFGuRpylqGv6UQAinI9TXr+xw9OzE14uxsSpBpOgOx2OLs8Io5BthDrPsUmbO6MRTy8uWCyeE0YROEuoNbO8YLvXo7QFJ+cXPDrY4cXpOdM0ZTEdY7o9nDGcnF5QRQF9rbB1wfnccnc04snFBfnFKaJiYqUIneJ8MqEbKhIdcDldcG+4RS01l0VGmkNQVogTLqYpqQgt/Iy1+DWD9uf1DIP/yS0cWBFiBVmoMJXjfJbhNPTx9DyBp+SfWscIULVCi0LNc8ZKSICOhtLBjoKFgvPa0QGqjiIohXxRkRvvSGPxY+ou8ESgU4MJoQ4gKISJ8cNep0FlLQvWwLH1s/a6pYisYOeWeQCBha4GY2C/hifKswfLNkWFkIrFGu+QER+6GCl46aBXgbQUkRZU6pgYHxbpKM8YbAEvNVxY7/zzNoSZsMgslfbvBeI7fVfDMwtdCzpShEYwhTD3jzAD76boWc8YXFjfvqwLYQo2h8L4cFAs/k7uW3jioG1Bh+AMqMIxadidIR449Brwdu58O+sEogqqWcW8AXcD7RmlHQsf4QFIYIBYEeVCrjwz1dUe4LScB3CXQGKhSiCowNX+fknlQeRn2eem8RCRfwT8o9/sS1cZD2M82FiDDs9KLMMrHnB8NuvgAYlGf8JBfcYUeSPc4F9+krNYv9M41tUerjAYK70EV/ZrsOFW+pH1uX52z0rjsQzxqDX+uFqdV4DEuh7LzzZDLSKC+5QAxSaQWuo6VoBjBTxqzz44u/pMnDRgBKzzM4Y1iHLr67sl8PB9swQefq/WwKNhqZY3UOAKy6V1c2t+TejqL2u/6TMcRyFf/dpX+PmTpxgN2WKGmJjxNEVLjlSGSkJUGHL37gOS/oCPPn5JoNtMFz58Mp3McEFIEMSkZUESh3z969/kw4+fUKYp8yJHiWa6WBAGgX9ugIUt6Q9G3NoZ8eLlxyTGkS4qFDBfpGAUiUBZZ1QlPHh0h/PjY6QsWdQlSvyImmsf+jII87wkilu8ceMO7z5/SqIhm80J0MzSHIwhQZCsIitL7ty9R5XOmE/mZFWFcgqlhIwMhWCARZqiNbz5+BFPnj1F1zXzPCcQWGQLgiBAO9AWykqxt7NDF8XZxRkWx6JwhMCstgRKkaBIi4yyhNdff8TJxy/RtmacFhiB1DmCQBMgxHXFonAMhwP2tkd8/PRjcEJal2hg0vRTBBR5iXJw694dppNTVF0xcZa6Fpx15EYTAZGypDYlSmIe3r7Fhx9/jDGK2aIgEbBWM0UIgYWU2Aru7B8wmebU5YwggqLwjnqpdfgt4Y5/oWfYayVg1FLkuQcflxraIlT4mfkA78Qrga0kIKgdxoEEnrHo4cMNpUDiYGo887HXDUnnFW0HZxo6zrc3w2sVbO21FEnoXyvxrMMEP+MuxV+zK54ZqgR2Yz9L7zqYGQgaNmaGHxtc6csMNQwDr0kIFZwDPQAHpfIOutS+zGEMtvSz9zwAV3iNQyrNPXIeSAGMIigqD0ougEHjwxYCQ/HaiwroRGCsd9SF8m0Jne+XGoibsIVzsBX7cEurCTO1nL8nc6CtfFhooaAdQIulzhHG+DqXzus+uuLDRxU+hJPn0LFeLxM7D2IW4MfRpsxAQTv0oaFYwRnQFz/fzcUfl84zIa3Qf880oSgsIA2oED7hXzbtCxOXvmorxoN1iMM7mcYhabWe7W4CCLkaYVnOjJFmpoz2KmFPUTTi0asz5JUAc0MDsdI3bAADt/HaNezFcn8FYGyAiHXIYwOYbAoyN8HHRlnarV8jsmY5lsdXANcGm7G83ka73EYYhya8sikuXdWLNTCy0gAKsQ3g2GA8rMU5uwIj4twaeFgPPMRtMjuN1qNZMbG82ibw0E04zIMPUE6t27kkOVyz8kJgkxH5Mpi1ju3dPd795c+YLRYkcUxlhcFgiIoCLo9ytBEuz07Z6ieYTsAvn7yP1hZrCxQBt27f4eToBUWWEkYxz599yP1Hd3j/44+5uDgnjAyCxrQS9vp9Do8P0UZRugJXG24ejPjwo2c4sWgRUJrtnW3S+ZxJltIxhvPLGTu7u0wnc+bpAhPE1BqMMvRGW5yfX1DampGGRQk3bx3w8ZHXn5TK4JTQ6bSoESbzBaLhYn5BZ9CnrAqOLs5pGS/iFAWj/QPOz8/J65KOgePphDu3bvLk2UsWeUkSxtQCvV6Hjgk5GV9iAoVbzGi3YqIo5OXhS5Tys3BR0B9tIbMF87KgreF8POfurV2OT06YlRmxCaiBMA4ZRDHn8wVaCabMKSTh5v6Qw8MXOCcYo6CGre0RaZYxTVO6IZzNZoz2tknTBZeTKUkQU9cQhgHtdofJbMZMHEMNk3nJjTu3efLxCyprsaJQAp1uh8rBLF0QG8V8ntLutqjrkjybEIQhWe28wDIAVXsqO/4Cn2MHRCEsKsEKUHpeOFPeuUjt9Qahwv8XCa50VPgZOco7a20VmRMS451fp2NYFDUKyAshUV6LYZUHmZXys+wSCIyiLgVcA0CUd54oH07RBuYCJvKUvgaqXAgDDyJc46itgiDw54aRd+bWQVQKofIiVDRY6/UOFUDo6xUAdSnExotTa7y+ogDiyItAgxBKrx3GlP6aufiwCw2QMarxaso76NIKceCFnTRktsWzO4saVNyUiWc6Anw54jz4qhWYwAMbbbzjt84DElEe8CkNtQMCSB2oBnAFLPUpvp9sAxJK8WBv4SAMPehyDpJSfJsblyNuHX5SIYj1oKcqfEinEKD2bZrJZ4/MX5qU6cvwAnAFeKhmpquXr1mzDCumgc1Qy6YGg6vlrACMXpW7/OfrwCdWbthNMeXK+TqctdTWYusNTYK1DSOwdsrOLR31mjVwIli5umLkitZik6HYeN9tgB7Z0Du4K9tGfaW55nKljXh9x3JVy6p+y7pZDyxq59tQ2/qKhmOp4/iknqNuNn9cr/Qd9XrfaDmquqKuK2pb+63e6LON/qsbMLPZlvU92GRb3NW++KIeYIS8yBnPJvR6Hd565x12trZ5/fVbPLp3B6IO4ixiHa4WJufn1IsJX//6G4xu3KXf7/Hdf+UbtEf7KB1ixS/HLQrHeHxOFAZ856//S7S297l19yZvfvUNQhOhnFA7/zxO53MWRc6d+/fZv3WPZDTinW+8QzeOiZrfTSVCVdWczaY4HfCNd75Bp91ltLPNN77yFpFSq8Goso5FWnCWFwxHOzy+94Buf4u3X3vMTrfnB3eB3AmuqhlPpiineO3Ntxh0uvSHQ777zu/RCjQhzczMOcosZzJf0Eo6fPXBY0adHg8ePuDmwS5RQ+dZcUhtmcznLKzj4cNHDPsDWoMB3/nOdwgDQwhoUZQCdVlzPk/RYcTX3n6brU6Pg5s3ePsrr5M0iuVCQJxlOlswmefcvnWb27sHDLZGfOvrX6cXRST42XzphLqsOZuMcSbg6998h3anx/b2Dt/+5u8RmwCDn/2V1pGmGfMsYzgccf/2PdrtPm999THDbms1e6+cUFaW86zAKsW91+4ThTEqinhj/4AQ6NBoCL4gUwDOO8E4DOhuD4iA+9shNxJDFy+MXOAdXloKuSh2toa4MCRUim/daNEVIQKmys/UtRXmNRijGe0PcAJbLcX9rqYnHkBUxjt/qb3j7PVipBUSCjwa+VBBC5hqDwCU9SJVoxWDvRbKQS+AR9t+tl+Ld8R1c27poBsbVC8kELg3hKHyDM5Me+ZFKahL3w+9rYgKz4C9uetZFaM8CCsB7aCw0AoUemAIBPb7sBf7UEdt/O/Iac/m1AK9YYALFW2BR/u+nhEenJV4VqRw0NKKZDtECwwiOOj69hfNtUV5x1846HYCXBzQEnh9x9ez09ynTDzgyaxnkQe7LRAvJH20BR3xAC1vGCWWZSYBuh8SCdzZhp72dV3o5vrW338UbA01Vnk9y97Q990g5DORx5eG8VibBwyr/B1L0ecnVjIsz2bjaMl2SBOcaEYx1eyXeIXGcV8JB8ByKSyyXKXhVnuxm0tKXeO83Ssz+4ZTaJgPNl+/sv9Vy2iXoRbVaCeUuHU4aRVjafZKEFFX9RsbwAXW7d3styUL4TbrsyxD1sDLbjj6JXiqrfU5Klwj+nS2EaU237OsNR5uGWJxQLMCRjW1WILCJl/DKr+BNOBQpBH4SpNDYF1XLXpJb3nQ2JTzRbIfIoo4DlHEPHjjdf7sez/g7v2HzCYLLianUKcgOVHUJs1Ltnb2aLUz0lnB9PiQr3/rHf6v//0fgx4gNiMIE1wFAQnahDx4fI8fff/P6XW6GJPw4x//lFoLUjuSICSrHHtxG6Vj2v0Bf/ajn/DG48f8vz/8IRIaP1DjnQHG0DERnb0d3nv/fbQJ2Nre5v/55z+mDDSqhlApKudoq4BQYG+0zU8+eI/7t+7w5MULUuep9wQvTLNOGJiQut/n/PSEytbcu3eXf/xP/oS6WXIeOrAIxgqJUtw/uMUP3/sl+7u7XF6MmcwWVKIwVogRMnHsa00dJ1R1zWWa8vrDh/zff/qnEIarnAFGCZEJSZTi3q1b/Oj9D2i3YwId8GfvfkSGZyAivODubtDm0gT0e21+8u67vPnoMf/sxz+ixgs8W6IIFSgT0jOW9miLd99/jyDSjEZD/skPfkyq1ssbxQodIgxwc2ePn3zwLrduHvCLJy+xtaVQntaONRg029owb3W4OL6gqCu2Bx0+PD7FGb8s84sclBXQrv2MtN1LeDaeMugYzlKBWlNpSycASkiMsF3CaWiw2jKpK/a6hp8cFsSBIRLrGQyBQeX8Usxem+eTOXEEhRMWqSLTnplwlRdgdmvhRCtcqDmbF2y14MUlRIGiFs/EhA76CnoCaTvkaFahA9/HL8eKWgsqgLryIYN+5ZegqlhznFVsJXA6gdBoLM4zEw7iCgYOZpFmWtZUSugn8NGZ11Fo7UMrofjwTKFAJ5rjuaUbwzT1ug5raKgYz2CNHFwaRVY7ZrUwaPsyw8ADk9z6fuo3ISxpGY6nNXHkHfwiV5SB+FUrlReA9i2carCBcJ5attvw9ML303Jsjx30lA9r5e2Ao0WJCT27dDiFSnsQYxuh6rD22g3igJeznEELDsdeRCrNihjjPAAMHMyMYpz59xMDs4kHZ4uKz4y1fC4p039Tu7F3U/79f/s/AhHiKCCOQpI4otNq0Wm1ff6OMCAOIoxSiFhUk9xHN2yIVhqj1+LS5WxYOYufQ7gV2FjR/6vwyQaDsPH5pmjSWXcFiKwAyWcBj2WgqwllLN3iZhhkWdZmuEbh1/RrEe+AlytqNsJQbJbVIKpV2GcDiLD8fMnqqIbVaTQXKyDCVWbFNfXyrMMGa1NvgA5rG/DlQYo0gMM51fTPK+EWafiIVe6OJtSim3to/Iql9YoiLzgFVmEYvQzF+BjNWh/SMFgozX/1v/wPPxCRb//2n9RfbTf2bsp/8O/+Eb12B1TI1t4NJhdHlGlO0o64WCy4/9oDpmeO6cVLnAo4uHMbDUznl7g0I253SLMcbM79R6/z5N0PsC4nNG3iOGR3+4CT02dki4xuJ2Yyn3N3b0QpiovTE6xohsM+4nzMPROLykokVhR5wVt37vPk8DnaWixCd9imo3uczi4oqppB0mJRLBi0OuGhJCsAACAASURBVLTCkKOLcyIVEiWKUgzdpM28yqnznFYcM5mn3L+xy+XlGFv7RGdxt00QBcynGXMRuqJwzqIizV6rzfPLsWdVwgCtFO3+gMs0I1+k9JOESZZysDciW1TM8pRACb1uBy2arCzIUSS1RZuA3FbcGQ348PySlhWqQJEEhn6nz0WWsshytuKERZ7T3xths4pxmtJFiIYdQqcoRchqQcqCllJMy5JHNw74+OwM4zzzkrQidtsdPprOKKqafpwwrzJ6nTYdHXJ4OabtIBnE2EqIkoRZVWKziiQOSbOMO3vbXEymqLxCxGFaGmO6ZOmcmQixeA1M6oQY+M/++O/9zp9hgFt7N+Q/+f0/IMHPbAeR4lwUaem4ERkuK8te7BkRK4rECZX2tL92cCgwEEVLKybiuB3CswIGSqERSge9xOfgmNewHSqy2odk2sbn+QjxIXGroK/hY/HahUGoOK+F2wEc1tBVilCEufOi00z5UNV+6JmQWnth58vKg5QGB9DR8BLQNewniuNS2DV+magWHzIqBWLjWYpTYMv41SNzgRshvCi8Qzf4c/sGTvBhm/0ujBd+9YdxfulxwjrkEuDXNPfwzMOFhTshPCt9mSGeSekYr2/JHOwlMG1W/rQVTGqvO3HKO/pY+UxxLed1JycV3DRwUvvzTcP4tbVngS4c7DUhGKu9UPhF5cW1Ri1ZF3ipPAuz24LTzPft3Pl2BcYvw40aBmosXnxsxbNc/+3//A94cXr4qbPBLxXjsZyzLkMrK8ZDrcMhS5ONbyleWerarEShmSl7Or5+haVYr8iQKwxGo79Yreq4mrPiUwWhG3oMjzdkhTvUhspmCRg2od6nsR5NzMczN9LM+JWf/S9XtayJjyXD8UpZrOuy7FxpKGcvXN3YNyDE8SmrWBrg4ZmOVzQedtknyz0r4OGPPSxaCmXdEngsq6RBiUI58fFj53BKUOI1Hyi1Al5OHMqttT7LfC/LVVBKy0of8kWYVorAWB/OKGfMJyHpYkEYt5jOczqtAc9++T5BkDDYHXJ+ckI+O8VVQp7OIWgT1Ia6zEhaCT/7s+8z2NqjKgrQNXVdkuZT8nxG0m6RlRWddosXp2eIKIajPS4uT7AIZVWiRLBWSLohk+mcQdziR08/oB/HqDjGlQXztKCMNHlVEoYRmXLgYJqmnFjLoNumXOQ4G1C5CslTbJ3TChTjxYJ+GPL08JTAONpxhzzPqcscVwSosiA2GmM086KioyOenI/pdwKqCpwVSnHUszlFVTIMDdM8pRVFPD8bEwO9dotFmpFVJaVTuKpCG4OKNJfzBd0o4udHZ/S7LR/TdpaFCFKWPhGbiVjYChWFnJxPUM4yGg6ZTCYop7hMC2KECvEOIM3pRAl//vwF/ThAxQkuL0lr4WVWUBYlSRRRlxmRQDbPmVYz+sM+6WyBspBWjq5YXFXSiwLO04xOGPLh4RlhILRaCfk8w5YQtnLEOVpOcMY7rWipZ/iCTONXKeSFonaCWCF0wg0DF7UlVHBcNbkaEsNULGklqBq2xW9BKExKoRXC0woSpShamip3ZEqoaogsHGgPtJx40DCtIAk1hXZklU90ZRxsCcQxjDOhHXgHGwjkiaIohTk+TNOvfPKvHB9WiUN4UfsMvYtIKPJGm6KgV0M7grNcaGkv4qwtRInPjTFzHgh1K9hvNB5ZBZ0EDi1EWlEnkGVedzTW0Km8/uMy9f2YNUxCknhwkloPKloWDhS4CCaZF2m+dE0SsQTKzIMuG0BSQj+AaQ3KgQvgvPSsRrpkXxofswNEMZxn0ArgED/HKxOFFEKKT3zWLuGG8WyNdV4r87KGxCjmIdSF13agYGAhif0y3xZewFrW0GorbC3kBjCgS796qTJeoxIbria4/JTn7Etjm5qO1QqHK8LSV85nQ9uh9FoH0syWl07YuibfhK29JmNDo7DSI9TVKofEWptQUVbr/BN1VV/ZV1VNVVarrXxl779fb2gg6kYDsVGflbZh6dibfBmb4QtxG+BouSJl498nAJJd78XrVFZalVfCRKv8HRufLwGHdU1YZbkt31vpVTY0GBt5P9bgbJ17w21En9aRqA1tits4XoV57JX+sc39s42m5kr/NXV19ouJkItoqqJCBZp3vvUd8myBMZZev027E/l8CA6CuM3l8SGREYKozf03XsO5CkPK/u1tlLJkpUXrCO0ci9kEow2PX/8aZZmhcERRyHDYwznx1HzQYja5AATrAt56622KskBrYXu4TWQCSiskWtHutBjPZyRRyO29myRxjEERKMVed4DWAc46erGhFp/iu2UC3npwH1uWOBXQ72/TDSMshlBBr9PmMstoRyH7nR6j0bCZBGi2+tskSlGWFXGjoqyqilYU8tb9u5R1hdaaqN2jFbd9PgIROq2QyzQjDgP6Ycy9e3fACQ7FaLhLYgKs9atvtA6YLBYEUcQb9x9jxaJMQBwl9NpDRDTOWlpRh/Eix4YQOMdbr79GWVU4UQy29jHaYK2jq6EdtxnP5iRxyP3dA1pxjNGaSBuGW/uIKFxtCU1AltcUzqFRvP34EXmZI9rQ72/TNgGutEQIg16XaVbQSxJ2Ol0GSQ+rFJUxtDtdoKHZv0ASWgBVeAd9f6vHwiqmorE6IFaG2vqVI70IpmVNUMFQB+z1OkxFsVAarRPAO8XYQpgI6cJigDv9NrloxihyMSgJqMWvPukaSJ2FXIgc7PRazC1MRVFVPsVrXkNcQqsFs9RPdraTCEXABEXmFNoZrz3KfcbQMhDIfMhjp5eQlk2ZVhOiyC3YAtoxzArAwtAEhCZiKoq5VWB93yxySGpwgZAt/EC21YqoSpiIIiv9Ut7KArlfITIufftaTtEKQ3LxzEzdZIrLKwhL0DGkqX+v3w6pK8VUFKn17EzhoM6hE8ICQSqhJTDstFjUPoNrXSoPyioveG0nMFt4Bmk3jnASMEWxcApXawrxQKeDX9FmMyEQGHYTFpVvU1n5rLWp8+3oJDBJBVVBojUKQyGKVDw9oPEgTn3Gc/zlAB6yuaRSrZfQGuOzmG4spfQyjqXmQa3AySbo2DRrHXVtKRtAUVZ2tS+bhFVVuU5eVTbb5rnVat8kuGo2f071ia361G0DrGwAkLreAB2f5sQ3BKVuCTle1YdceW9zGaysy7Qb+yXoaL5n2RTU2iuizmXSsCvi2g2R7Eq4iqz2VnxNlwnKXBP28UnLrmpR2Kz3SozrVgLT2toNkNhsjfC1tpa6qe9S3OvcFyMvNUbR7rS5c2+PP/mnf0Jdlbz95jscPX/KfHzBwWiPJOmixbF/6z43b+2RzS754fd/wPbuHrfu7fPzH/5TorDNrVt3wFYEQcBgMOLRawf88Pt/wuVkzFff+j0mk0tevHzG1mCbQb+LMXCwf8Du7ohWR/je9/8p3U6XB/fu8/6T90EJO7sDaie40jIcDrn15kN+8eGHHB6f8PjRA1yg+eDFM6LEsN2PqYuadmxI+j26N/b50bvvQhjw+t19Pjg5JqsqBp2YrlJIWrDX63H77m2eTmacvDxkZ3tE3Ep4//gQF2tu9hMiJ/RjRavd5uDubX703gc4Ed56cJOj6TmTbEG3ZXwa7qxmp99leOMGF0745c9/yXB7yN7+iPeefQSBZtRvo1D0lGPU7/LwtQf885/9jGma8frDO1wUc44uTuh3W4w6HWxdstftMdzaxnVa/Ognf0671ebhvXu8++wpTsPOsI1xflnpoN/nzmsP+cnHTzg7PeXh7TuUCj46ek4UG3Y6LT977iaMBn22Dvb5wc9/BqHm8e1bvPfyGZmt2Rq0CJUiT0uGvT67t25wskg5Pj1nOBwStmIm0zkWGhHwF2cGhWjFTifgw8mMRMPDTsJFXZNZSyvwGTWlht0kot8OmWvhbLYgiRU7ScBRnVPjl3BGAmGuaIWGvX7A01mKcY6DJCDDMXE1sYFB4B3lTWNohQoTwuEsIwrgVmy4VBYHDCMfCjGZYisybLfhRVZSVTXD2LuzsbMYBXuhz1kxcgoTKNqJ4uUsJzBwO1KMlaNEaEc+FGNy2As1/Rgu65osL2kbRdsozsQH7Pcir5sYVD6UMkzgKC0JFNwMNQXNypfAh2eCEg4CaEWQI0yyiiSAkVFcegKardCzCf0CuiFef5JWKBH2QoMTRYrXr2wZMAXso2gFIIFwOs9QAexrwxlCDWxHXgxqch8u2+7AUVEidc0oUD7EK45IwU7o83BsOYgCz3AczZt+CjQTJxRAP/QAxeSwHXqglltHVlnaWvkkeI0+KPw1zPOXJtTyifCK3ny9zu+wFJBeyVq6ivOvN2G5QsU7saqqN0ICjWbjlRDK5pLZ1d6tz2PJFAir95bOblPjcWXKsgGU1CvgaKXbYKWJRZAmR4kXlqIAt9E27fwCYU/pXAmxrNiFZX3YEJY256M29SVrELAOr2yyJxuMxsZqEnGbfbcWkIp4kaFIo/HglWttjqhq2VUrCbDX7SgFyouDWfWpbLRf+75Z7pe6mCa9/Rc1W6ydJQoiBv0dXntNcTDa53vf/zFB1KIqLCcnH/Kt736H8/MZL54/pX3jJn/9X3ubFx9fcHJ5zofvHaKDmLwoKWan/Ot/89/kez/8c8I4JjY9vvZ7b7M9GPGn/+wHvvMEzi6OeOutt3Fi+eD99xl1urz5zbdpRU/AwS/e/QXKGIq65mI641/9G/8yv/jle5RVhswc3/kb38ItSn7x819SiUNQzLKC0c19Xjs44OcfvWBkDI+2din3F3SjgF88eUGgA3JrOVrM+caD+xyPzxkvCtLTCV9/9ICiWHD48oy0tohSpLUj7cW88ZUDfvrhczoCQwIe3LpJN9A8ff9jBE2N5SwtePvuAbO05GQ8pT+d8tfe/Covjo+4nI45fH4MSvu07U747jd/j5++9x6BBZXWfOVrb9ESx89+8T5Ka2qE89mMNx7cRYct3nvylCFt3v72V3k/eIKyjnc/eA9tDKV1nKUF3/nut/nZkyeUaYk9X/Dtb7yDK3I+ePc9CoXvp6Ji79YON/p9/vz9DxmGMfd3blCkOd3A8NMPP0SbgMI5TrKCd956g+dnZ1xOZixOF3z14WscX5yQT2cUtkbwqyq+yKW04NOPGwuklgTYieBZmoExpLWlcBCGIWEkTHOLQtjTmjxWmNrxsqpxoqgQDq3iZkdxWAiBddg5dFFsRcJlXmG1RqxQNKtF4jaclEJH/N89sU3CsmeV/+N8FcK59U51KoKqHUXtHWw3gmlpqbTyKy7wWTnbsdeTxCKE4jUZfeB5JQTaizBz24hGFVCL//slDkLjJ64zrYjE57i4tD4F+6nzIRPE37OOwFFlCZtMnuK8kNkFPrFWojxgqpQHbceqSRiH10y0NZyJZ4gqPGBLgNOqRmuFaVzBAghjuKg9CEjwS2z7Ai/EEjXygrH1IZqJAmOFMvX5Tdoa5rWjMgpl/UTw0vqw06X15yz7aaDghbWEyofDC+t1H3mTsyNq9DCepXPU+i+e8v9LIS492L0pf+dv/SFGK5I48n8YrhXTabVoJy2SKCJsUqf7RREWmj90E+gAo/X6j8bBemZcVVRFTllmVHW5BhIN8NhckvmJFSvLUMEKoPinaSWa3NBArPN2AKz3nsmB5UodNoDHctnvJvgAVp7TIATikznppXhyM737Ui8iazHtMiSz+qNu8kq+jg0UutR/ONgALHYd6tnQcSxDLHKF8bCfIiAVnCi/uaYvXmmXAJt/GG6dir55f1VHtf5+A5jWCcbWS6Y9KG2WXDfp9P/r//N/+50L827fvCd/+Lf/CFdXdEY7pFlFt9tGabi4GFMWKTjL3sE+pY3IixlaRYyGAy4mc/a22hyfnIITsqqEMuXhg8ecnF5SVwXdbh9UjWhotbqcnZxQFQsAOp027VafRZpRW8tWu80snTAajRhPpjhnKcqMsnbcv32L0/MJui7pxC10GFLnMwZbI05OL8htjXKWMIrYH/Y4mSxIpKCTDCiqkiRSOBUwn05InR9kXuu1mec5ee1IdEDYiimLjO3dbQ6Pz5k7ryUSrXh9p8OLy4zAOjpJh8I6WoHDBSHz+YxxMxge9Ls4qamKCmM1UadHWSzY3RpxcnFOjqWuLJnAa3dvcfTygoCSVtTGKk/4dnoJxxcX5JX/67+tTod2GJOVJUFd0+1us0jP6Q/6TOcpVV3iipIF8NqtfQ4vxoTW0goTjAmpy4z+9pCjoxOyRhAeRBG3h11Oxwu0VGwNR4xnM9qdNlVpmcyn1OKdyf3RkMliQV1bEgdJu800XTDstzmfpZRuvaLlv/iCxKX39m7IH/3+H/ikVUaRWyHRmrCXkE5SLvHO83Holx2f19BXilr7iUO7HTMvKrLa+dwXBh4Cz8QLEhOtyJUQWYh7MdmsYILvn9uBd1zHtReVijSZMmNDLlCVlgxAw0MNx84vu+0aRer830AJ2yHzRcVceZHjduDZjJeNGNNoLxhNjParvbKKRaOruWf8EtSybv5InfKOOkoM89SS4svsGp+59Mh5Rx1or+FoKVCRosyFmfLP8c3ALxVe2HVukQgIYoVUkIlQuSbDKnAsfrVIqDwQ7SgIY02eOab439sN44HBhfXgw2k/VsahoRYomn4SDQ8NHFkPhFrNkuEWEHVC5rPKtwkvSO06f24sXixcW0gChQo0eW7Jmz55YLyQtLYeMDp8fxFCVflEayXw3/zDvxLiUkGx1HVs5t54JS8HrFQrzduNE5bVbFfcWgS50gHU9ScFo/ZV4OE1Ec5uaCDs5qoWaaj89aqZZebONePR1KM5XoEOlllXG+Hkxn6VJvxKdzSrWxSARmtphKWsc5X4Yn0iGq1RrmEwUGtdxSocw5plWF+CT1s+u9JMuPWxvdJXr2g5msI29Rurpa7Lq+m1QHh531CfPF62aQlTlsAKxSqcxrK/liLbpq+d+2xB0+dpzlnSIqXd6jCbXjLoDRlfjCnyOWEcs31wi/H5jMIFVNnY/0KDmvlM4coFL44y6jxj0O7Q2R5xcVIzX8zJ8imdTofp/IJOe5vFfMr4fALKMRgdkM8niDUU+YKizImjmGmRok3I0ekpdVnRbrUZDba4uBiTLTLKMieKE8ZFRl8bsqqmODojxbIVdQikYu4qFlnuQVAckxcZgyjiZL6gto5AwU4UklY1s6omc0IehOS2ZitQlDm8ODpj6oStKKClFPOq5mxRM60dSRgyz1N2ui1O0grSnAo/qFoHZVVRO8tCNKGGti2oxfHi/JxFXZEEMVtRC1VkzOYpC1fQbrXI84y9YZ+z6Zzx8RSrFbu9IbMixThLWeVkVUUchsyLKQSG0/GEqqhJWiGjrQEynjKep9RFiYsT8iLjxlbAJK0YH575P3yXBAQ6YJKXzLOSWV2RhCFH0yntwPx/zL3XsiRXdqb5beEqdBwtUkIXSpPT1dN90WYzF3M78zbTjzCv0c8x1mZzMWZtY+whwSpWAagEkMjMk+qIOKHD1d67L5aHOAkQbLJJAg5zhDgRLnZ4+lr7X///L8bTOVVVo4xmmEQUecmyKlnVjqAtBY66qggKRpMFNRKQIv0P97n4l1wC4v2Qa5nNHvQt17MaNVuyUDKLTp3M0vEw04oiBA5SRVXCzaJgaSUgHViZ3d8qUVRUWkzFjoaKm3GgWhTMrexnP0giAxLcrgLsp3JPuF06iCXh6RhBBcaNh8RciynX4T5MxhCvKlaRkFe7VhqZ5UjAzpWoT7IMbqceqz2FFvVIXDemYEaIpssgnhSLORQrR5UCTYkh1I1zqRLpaQvoDWT/rRBYWkEDusCysR/PrTw/aAv5sioDIZEmet1YOBzz0BieId8f7MH4FtLKk0eSuJ0iyZZScj5L4CCR++N45dDNOLUtRLWgPSjxPsk9nOzL2EeLijwBU8F+4zOSIwnYSok9etaC+SwQGUeuhWw7aMbJNGOvAgx7sJyLERwp1CvIzA9fZz+dxENiNFvJ6N3Z7da1lK38ZftkR00Smhn72thrbXq1YzoVwva1cxu0w/m75ZdNoHW7pZhdVcw60u7O+iWYb1CPncRDN8F3jVz4sLUv2yYS69KLmIyxLj2Etevq+pz1+uNNaaLx+wj6bvLh2SYebJMOef4umXM30dhNPNbj9E4pasPTkK0Jl2ObTK2ThTvntSmRfQ/igZxLQBKIXbVOc2XsJJo7CRTrMktAqR/nrq1RxDbm8ePHPP32OTc3NzgToU2MjlOuL16AydB6QBS3GR7uESWWb776Em0MXim0iSl8ze3rV2gVYeMWJprz6c9/zRdffsl0fE0IgdRE1CYwunlNCJpeu0satYjijOOjE548+ZOMiQOrNZrA65sbEqUxVmOV5v2H7/H64oLlbCTa/ODoxhG31YLgPIPIEmtFFid8cnLEk+cvWFWFtPEGWnHMi6JkqCBW4sXwYG9AvRgznc6pGglhS2vmzjN1nqFSaGWxuuSj/QEvLq/JZwsUcqPN4piLsiQDug1adzwc0HGBNzc3OAVRUKRa4XC8LHIGWpFoTWQ1H91/xMWzp4xHI4LS2BBomYjXszE6BHqtjCSKsGmLk36fr59+A8agvSfSoILj+e1Emp4pzzLAo7N7jN68ZHozRiuRj8bWcl04nK8YRBaMbcbpkD+/uKAopdtsqsEmCa+XOS0kwFoFp70eq8WCUb7CWIHR1w25av/jGoj5pnSwn8JiGVjNanSQ2bo2cFOJeiJTopDYM4p2DeUioLSocnDijDmqxJwrGCFWP0wUk1WgGot02Abx4bh28m9/vc0oyD7KlXAOCgW6ApTISPfYOmgeWXHadCNEJYckERNAVY0Vu5EAeaYb0mWQz5rG42NUw6ESOXDpxVo91FDfNjJhgJXM4mdV0/OkWU8MrGpQUzk+Vcp5TZExi5QgLBkyNmouio8iQFjJNqZlI0NVgrYcx9JZ1o/EI8d42eZtkO1lzb6thn2gWklZyCL79womze8UtCQix1acW/NRIDagnBBab5HnnSAOqUqJiqesBHlRGqJK7se3lShXoJHmGkk2iokkTNTgV40c1/0wV+mnQS5lE7s2i9pd/95Z7Fo0ugP1ux01RENEdI0cdPt8q2yp3FrZ0nRRfWctG7fNsiplLdfPq01Cs3b+dBs1yPcpMnYIkO++3wR+16hA/E65ZI2obFQhsEV/7iRoO26s6p0RasZmd/vr49ygGWujsN0E5B01i9tJRLYE1NAc/xZxUkoJMXizWoyx2CjCRvIYxTFRkhAnCXGSEsfp9nmSEMcxcbx+jImjmCiy0svDmHe4P6phxqzt4f/1F+89H374iC++/BNVWXJ27yEmBB59/HOOjw9AGzIbMx5d0+9n7J8kPPnqCUdHh2TtLqpe8bt/+5c477E2JrOW68uX/M///rd8/uRzxpMJDx8/JstSOnt7PH7/MUor2klMXtUUVc57H7/Pn776nH5/j05nAEbxy9/+BqfAKEWWRFzfjvnko/e4vr1iMhtxfnqEMYaQZTx88Ig4NFJBVzNaLvnk8TlfXLwgsZZ+v09pDKf3z/HW0mrO/TIv6PVbzFVgUVbsdTtEkWFqDPfunwjEDbgoMC7mfPT4nC+vbvAhcDhogdZkwyE2E5fPoGBZ16QtS7vd4fntiL1hj04WszCa9z7+RG7qgLea1+Mxv/nkZ3x98YJpnnN8cgTa0DrY5/DBAxLAWEPlawrneHj/nC++fcr+sE+v16HWmg8//giDEfKcUdzMV3zw+D5XtzfMyxX7x6c4NCHLePDoPVIgNoraO6bLBZ989JjPLi4w2tDvdKmN4ejhQ4KNSABlFePVioPDPQpreJuvOOh1CEGxUopOS9w0K/XjzgY9EGfSfdQoRWyNJEKJTJiGyIx4pqR0RmyY1QEdGVKjmAXotBXtIOdRWWlQNmxr3pRytzapEU6FEfvvIYCCKhbPiiyRWbU2Ch2JqVsaSQmgDbhIAmY7EetwABfrjZ9EYiUgawMqkYDda0tbepQiREoQplhQpr6WAD23oK1wJlSAEGlaVtCPTizbTAyQCDrQScQRNFJALC06aiMljQMt2yojQRFM0xCuavaxCqJOGSKIi0lkXFuxyHY1EBKFNpLEpUaCvtHgYimZrPevjJBnV4ghWRrknFwkHI9WBPMmuXOR3qAlmYUTBGULiSAu7VQ8WrQGY8UVOFhJ1vpKzM4WRkpDBklUrZXny+Y8MyT5+SHw+SeSeNxVZ6yRi3WQ/ftOYV3SuMNzWCcAtdvae+8Ez00CsrE8v6ua+I4apZT27WW5TjyKzeuqrr5r693wQu5apm/VIruOn3eUJuvHdQv4HeXIbhlHhqQpN9zpb3K3brEpP21QjZ3W9t9DGt0mIG6TXKzHyrudv/ntse/Ka9doCFpvEg6zTjqs2SQcNo6JElk3iUaakmQpcZqRpKmsSUqSJqRJQpqkJElCFMVYG2HXCc06+WjO9zsE1n/FxQfP69dvcVXFR5+8h4mh3+5xfphJIIkzVvUEQuBqdM3V1ZQ0cvz8F4/RvubDD97HRCVJq4MHnCqpXcXLp69YzeZ8+P4Zw/02Ko549NFDjAkYFbGsCly5ZLKY8vrVa/Cej372IVlkuXd2TruTkMYxOgSWeYGqa15djsiXK47PTumd3kebmIf3zvFK4ZSi8AHloao8l9c3hDpw7+FDvI4YtNscD/tNByQhu2UaZuOcejQhRC36J6fUyvDg5JC2jfBKbr6Vl1nU27c3aOc5PD0jtHvESczZ4ZDMSkDIA5jaM53VjK9v0FHMyeP3WemYh2enZFmMspYAlKVD145v37yhKHPOHz8kHRxio4T37t9DK1Fp1LWDqmK5WDG6ucUozcOPPkBrw9nBAd12FxVZSqAMAes9r69uKZdLBv1D9g6PUFHEew8eoAl4JS6jwQV87Xj19obgPO998D623WbQ73F4cEAcRQCUdUC7wOh2ymI+o91uMzw946VDBwAAIABJREFUIShR5wySNgqRf/ofqVwIzURvKbP/3qDFIo0xKO53YwZaYVhbz0NdBeysQhnN4KDHDZqDWHHWMkQNSjJ3TQ+Xhce6QKed4lsppYOzlqIfiUX/SonLqAnSkRWl6O2ljNHsaTjsNqgLMHHiXKoKQS2i1BD1YuYVHCSiNCEI6XFZC4Kj53Jug0HEShu6wEFHUJbIwTSIDHaNBBiraPct00qxl0C/RcOHk6QoVqLCIUCrpcljTeQFKUqsjM9UCRqjESUKWjEYWKZesWeh35ZtOt+cUxCUJnhIU4XLFHUl6qBeJMnQCijKZv9LuVZ6PcNEKYZaSjkRoLyYhEWNBDaqIUkscS9i2Wyzn8r5lDQW+Qr0Sq6DQT9hbBUdBUcdIceqIEiScUKgpQZrFa2uZulEcdNNhQeTGX4w8/jplFqaZaNc2Xm4u+xM/dXdEktoAv3Gn6NqeoesA+i6ZLCjRlkjEN65bRB27yYN8nxDOm3KNcYYsBal9HekocFvEwU5lS3HI+iARppoabV9Xz4V1rQNpGiidyiaagMBvet5stnXZlzullfWSZFURprSBI1/RkMUvYNwbHge7yZW234y622sf6pNw7cmMdhVHK2TBG1EtWTWScPGJG77+wd2ks9mXNfqpPWxrC3lfdOAjqbPz49FllYolvMVsUl483pGUeY8ePyYv/2b33N8/hDtKrJWC+weq/kt1/UbtE74w+fPCFGCjQ1/99kX9AdD5tNL0u4e9XTG25sx3nuur5eMJo7T40d89cUTBv0+WmtSG5MlKePZgtH1FZ1Yyjd5vuDgcJ///68+42C4z+1kzF63y3S1YjmfEYLHhpqL1TOOBwNubicEFYjjmE5didNiXVPNlqRacfPqFfMq5/T0jL/+4gknvT6zxZzTxLAoPZnxUIs0++2rFwyyiLqueHoxJopijmxBAtyWgU5eEggsRzd4Kk739/ny2QXH7S4axXFmKEtPpoB8RaIUr7/6mnbwJNby+Z//TLvTpSoLWq2Y+bKiWIgZ1/R2wjxMOD4+5stvvmXQ6aK0IbURUZRQLZaMb65JjObZk69wec7w/D6f/fHvOBjus5ovGGQRi7wilDmRC1SLGS9ezDntd7i6uQYHaRSRaUVkFLO8op5N6RrN25cX5GXBvQcP+ewPf+Tk4BjNiGESUzhHXNWYymG04vLlSxIriqjrxQqsJm+axv1Yi0JQAK9gvsgxkaM90HwxKjlKI5wpOUtglkspKXMwJzCdTekYR20VT0aObmYIyrHvpZTQ1hJYV0WJJtBrw4tloBtpnA3sR9JsTBnhkKAC41lBEjxlDN/cwl4iQfIQGDfNzqIAK+fRi4JuC64q8csggk4kUXWFkECVhttljVIen8LTkSQK3gnPYV5ImSBSsCQwnVUkcWAaYLEQczBtIW06uWZBZv6TMqCcRydwsYC9FHwCXSMcE60kUchVYDx3pCYwCzCdQbclZahOQ0BNkfOa1QEWgSSFixz2E1CxoCQulx8qaZLU8cKRqkAew4upJEm1hyNgnAvXRClYOYeeO1qJOJu2vXiHtK34mJRIyQUFt4sKqz0hha9u4ail8FVgqKUMZJtxmvnAYibo0dxDsZDvL2t+sNby00g8wjpgSKAyxmCNqFUUDZrhHLWSf5QqNHbpa4aEgrD2fqgqyrKkKAqKoqCqC+q6xLlqR4UStjP1tUx0XW7YBLfdRm9rCelW7SKxThAErXYVLTskU8KuXkXEGSqgUZvn73yCbYFpPR6g1BpF0OJv0gRtkI9u+CU+7BBd2ahatqZgWx8Q1uP6buKxg2KwIaU2CIvSKB/Q7zrDqK2TqLYRxlq0sXdUOOtEY2N5rtVWrfOusmUzFlu+jA7iRuuU2+H9hGZ6KB4nuiGY/hiLEIUdSbtPPr8h6/f56k+fEXTCt18/pd07pt/TrEpHp9VnOp7Q7XZwZaDIl3zx+Z+I44zr12/oD4/IsgQbd6mKKVFbFB5p1uXi+ec4F1jOZrSjNnEvRjnPkYlY5QuStMV8VaCC5vMnfyZRius3r9jr9sg6HbyWqUioKyo8wde8Hd2Sh0DXKFLnSTodEu+JvaYsIU5jRmVBx0RcvHxBEmB6c01mNa04wlESBY1TnlXw4BRuuWQxW9BriHDEmtRAJ1IYA5m23BYFvTjh4vUlOsDo9oa+tWRxilEFsYlYFTlElmntUHXFk5fPaUWwGhWkcUorSTBBU4ZAK4qYrXL22m0uXr2QRoOLOR1tSLo9XO3o7w2Zzaak7RaLVQko/vTNt7QMXL++IE0SsiTFOU9iE7wvmIWalm5zeXXNIih6ShFrsP0euqoYWkMdPFEcMytKWnHM1998jQ6Ky5fP6cUR3SxB5ysyE1EuC1ZaoHlfOoq8JjbN7FT94P36X35REoyMU4wqx16A2UqSwFCUxEir+2DARBbtpZi/LB29GkZFYJhCKB21UfRNwGmFSzSq8uTO06uR60qDCZ7IC8LS1lBoBVHAV6CcJ/EwCdCLxdk1ILPpSoNKFKYO1LUYaZFLeSW1gTIHGtvxuiE9qgq886QKZiX00qbRmZdgXxtQFjAigc10IBRS6uhkYvilGkfT0oNugc/BhIAJsCyl/OMBUwsSWGvhmIQIqJvPVlKW6KeCRijVHKcGkwKVjEdiYJVDGstnjBfUIbOCOvkYQgHaSw+mRQXdTJKd4KTEUmkp42gHvhY7fl/K+WZGeB9KCZl04UFlgiJVzpMi49RPBN1a/0ZKSwkLJ+cZWRknb0DH0mQv0vz0EQ+pmEiw1kpjrMFYs6nhb3uIiMrDKAlkW6WLfKau603Skec5xSqnqgucq6h9/b1yWbfuwbJb3thdG1XLOvHYEEebQO+VIyi9IalskY/1uYVmFr/+HdROWQkU68+uA/EW+1CEjUzUaI0xFt2MDc24bGWsYVvqaVAXMQiT17sllk1oX5en1jLZsOPVEbYJyjpRALVJsrYcEyXlFSXGb9pEKCucDqUlUdpNPO54mOygHHcVSjIe0gRP0JzgmyvZK5TzQiJVvhmpJhHUgg/9GIsPsCpLTFIyONinnWTcXL7h5MFDJrfXFMsRL8cLoqSDoqSsPEetI7rdFvk3I0zU4vj+Oc+efIGbG8a3t6RJSpmviLMO/eNDWknEZbHi6OCMqi6YzeZM344xRkijRVnQ72b0sgGjyQQKODk+5NuXr7CrnBezmWyzLjFKcf/kmDSK+Wo2oZdmRMYzXhQU0wWlChhrqauKnlLstdroqmLm4H4r5ttVRezh6TTHWI0LHuUDJ7EhGM/KB/EZiCyv65q09IwQ/sR17WhrOGun1KpiUsD9VsSrwrNyjtF0gY40oSpxdeC826LVanN9dY2pA4NuxvPVgrQoGK1WJElMWRVkseZk0CdKDW9va066bSo8s0XBfDTCRykGR12VnMUdWmmP2XSGAobDDi8uJ6iq5vl4QhwZblcrLHBvOIAk5XY0Zj+1mMRyPSvgdobHY6OIqqzYa2fs9brkZUW5VDwatnk+XqBqx4vxHBsZbusKFWBPRaSR4RYpBQRlyIOjsYb40ZaAoAYmBPYii3Y1BBgqzbUXkvtFCTqCupSeWW0Ug9gQgpMEoDaMnCMKgW+DzPbHucf4wMAafCX3l25QzErp2jurhFeAC/i64XNYjfFe5KeVlCOUgotGbjrNpXTXNhpdCRm/5yVYF64pi+jmsWiUJlYRapEtR5WUgjxw2dzT/DroK0Vdi217S0G+km1qJ2UhkN4lqYe2ETQgCmKbPvZC/lw2CErVzP5jwKIwIdBBEoBFg4i8rSWgz3PxEMmMoi4DOkC7FrKoD+AL+VzwkoglHhKroA7SsLGAWS3n8gbhhCwKGafUaFwt8ann5fiK5oJbNDFqWsj+u1bjK49FEJ5xM6F745umkLmgTXY9TiHQclLeMkHO/4fA558UxwO2sLxpavhsSINbbsHGVGpH0eIbJUtZllQbHkbzWFVUVSl252tOR9OSfcNfuBO412WJLdy/LlE0OYIgDWotarmr8Lgz4OvS0bvZX/N+2C0tbf62KyFuSjGbUoVBGSPllUZOuj7GtcR1t0zhA9sSifd3ybfvWqG7LWF0K8FtMoKdJm3ayO9jjJA9IxuJqVCzWhthrDzaKCKKYiGTxjFRLARTY23DAdmWXJQ2m0d5v/mMtlvEZ/0dY9Cbz0u5RpKfH6dArrQkhQ/fv08Up3zxzVN+/ptPmI3f4uqcVivGxinGKOqq5NGjE/KyZrqY43Gc3h+ynE3RxpC1smabEc5VfPzpxwRv+PrJN7z30Ycsizl1VRInbeIkJrFydz0+PkRnKQ6YzGZ88MH7TBYlsVLESYtUKRITUTvHp7/+GYuy5tvLS06PT9BRDKRY5AbdM/I79FopxycnkKQ8W+Q8PD9nQkKGJlKKPop9owk+8MtH55Q2ZRIsvpWRdDvMbUyMeCjsKeiogFGKB8d71GmLb2eOe/eOGPkYowwxgT2gHUWEEPjgvYdgIsZlTaE0xyenrIqYWCkSnZIoRdtavPd8+stPQSc8fXnD48ePmKHwTpNaI23GcegQOD05JEoziCzzPOfB+QnTQtQxqdV0UXQji3OOX376KbmDV6Mxp6cHkGZ4nxBrTVsFekZjjaHbaXNweoKKE96Mxnz06DGjQpMGjQmiWmhHEc4HfvbonCqJGJUBE8foVgYmElUCP+5NWSHKobO2xSUxF16RZSlTpTAo8cbwoiwhBO51LDYx3FrLW6VJ0pilMmikYdlhDV0l/JbHg4g6srxFESLDAkVQmhrpCHuMBOqegSRWLCLDJRBZIa1aJKgdORg2viEnHSis5hZFbTWlUrigcEhSsO9l9p0oaMcwt5qRAhtpJg2C4IJ0et1XMpfZz2T2vkSRG+mTtZY4xx4OgqAZsYdeAqVVLJSoTOZBiJZ1kP33myp434DVipVWTLQgpHmgQfBhEAT1wAlPpbaKOYpgFfMgQd4H6Do4apRlXSWqn5VVzLQo2KZexkkHGNayf+/gsAWV0cyVoo6EXFo3CULiYS8ICpIC3QSKSHOrINKaCbLNEKQktG8AD4NECMYrpamNximNas7Jhx8ml/4kEI91qeWO+yfsBHMJ6HdjtGqIk0DDSah3iKJbRctaQruzP6WEY6FD0zhNkAGZwUvpxGsJwNrrbfmiIXuueSZrt9U1sXG9k91zUDv/U5vH73qU3FnZaQPPdga0QYbCVmb6Het0GqvyzXfD+ot3E6nv+f7a4jzsDPa26LMdOwUb9ELKJ2aTFIn+TIy8tpyOJjkwmjWPZX1GG9KsChv06q4sR5APSd508znd/E6aoOS7oXnvx1qUVnS7PSbTGTe3Oaf3T7kYOSbjMTbKePzBhyzm17hoQJbF3Fx8SZrGjK5KBkf3uXhzxWo8Zu/olIOzM7qdDr1en9G0xe3VBbc3S/b3h0xvF8ymE0KAe/ceoUJGVXi67TZXk2viOOH66oZ75/d4/fwlo8WETqvD4OiQdBERmYS9XovJxVsqV9KLIqgd48Wcuq45GfTox4b5qqSbRVTznOWqYDGb8v7hHrc3t1wtl2gtKIXxESvteNzvMbka4wjs+RqTWt7OV5SlI4thkFgKZyAOpCXM5xXT1YrH/RZ+NuN6tUIpxf1+RoJhoTR7/S7z6xtCnFLNpww7Xa6vLlkVBVm3wzDLyMqYuBURpQk3r66ZLGec7u2xmi+ZzebgA/ePDwUX84FOu83l6BplYpbXN5yd7HN9ecVklROnEcO9Ni6Xqz476nH5+g3L2tGPLNo5bmcLXO3Y77cZRBGLqmbYbjGfLVksC+bjWx6dHvH68i2T2RxtDGf7A2zlKIJncNDm9mpCsAqbl7SyhJvpQhBVZFac/2hXsXDOuhGsCs+KJY9SjaPixjtCgOMEDJolgQfdhHJRUgRI65r9VDEpahYIStFpiXxVGc1xqlgsHKtQcc9AUIqb5j41MJIYLDzsJYq6CszrgPUVfSON5MqmFDVMoSqlq+p5qqjzQOFqhojh2bTplttB+BDLCrpaUI1lDQHHoYKVC7iGI9GPIVTy9+NULHYqF2irQBLEV8MZyGpRfawaEuxeLP1oKjzdBuWotMihh1YC8KKGw0RKNzMfyIKUhZbIOcVOSi7SOFH2n9dQN9vUSsoyRXNOkYV5CcNEeBzzGiLvaTXb9FreH6ZScikrOEmFl7HyNUMlidg8wFLJ2LQjOadWgw7lNXhqjrUYnBVKzuUgBVfJmB4n8jvUeDIkWS2DSJ9LhP/zg9fZv9QF/I9Z7gTUsOUe7AZToAl6u66dW0LpnUZim6Zrbts5dv39TdA3d9QXxsgsXGbp61m8xUZxIwPdWe12NU1ZwWy2c3ddz8zvBOgmELMrgW26sYZm3T7fJhDfl2TcQWPuJG67ScZ2FNf50XfLNDsJiaI5BhrexdZLZUMS3ZzPDhKh1+Wxpgym7yI2P7iq7fdY73t9LM1x7xBB7hzTd/1e/vUX7yq0j+hkfR6cnLF3cML87VtOzx9T24w//uGvyLKEcjni6y//jnb/lJMPfsYnv/gl89LTarVJsgGj8ZyLp085OOrz1VdfslxBpzfk0Ucf8P5HH3NzdcnR8SkqWF68+pagFcoq/vzsKVm7x+nJPd5//AiNkHz7vR6rxZJvn33NYDjkZnzD9XhKbBIenZ9x795Drm+uONnbJwXejKeMC0+SplxcjqmCYy9LGPT6ZFZRuprjQQ/r4Zt5RZUm2KC5uJoQvOes02Yw7DOZrBi2O2RaMynhTaWxrZibSUWRV/RsxF6/Ry82TGYFJ8M+cQg8G68oohgd4OL1NQbNw70B985OyFdLup0uSZwwn815O53SGfR5eXnLYrEisQn3Do853d/n6uqas9MzIPDs7SW1UqhI88WzZ/RUxMPDQw6OTqhWEIwha7eo8opnb6fE/Q7jVc71aEyqFI9PTnjv7JzrqzGn+wfEwOVkwajypFnG81eXxATOWh32ekPiAHVZszcY4p3j2fWI0G5Ta3h9dQtecdTtcrS3x2K2ZNiOSZSipJFe/ihXcHMdh0BRBiIPUdAE75nngYNuizjARQG3SF+Oi3FO8LCvFUmkKYqATiMyJRLcb1eAVbjSc5U7tA9kXhMZWJSBvXZMx0m546qWgDhaiYV6p5lveg+l1vSQ/iJvcuFcoOByJfe+XuPfkVeBNNV0apHlvimkfHNbQVGLp4f2ss0cKSekAUaFyHKNhetc/t5S8lg0BMxOM3+7ygUhmfmmLEEjfQ2SILQiIW3Oa/EcMRpui62Xh/Oi7nKJpusVUbPNMsi+bnP5/U1z05t76bLbclIWuWpKLTeFlHBSZNvOQ2GkvBkDl7lIbZ2CUS78kLYMG6sK0k5Ez4up2O44VY2nh0Z4IksF/UiTBdnm1Ms4XRVyzrGXsk/tA9pKUqWR8f+h5aeBeMAmQG5m5mGHZ9AEVukKvyVS+uY5PmyksPU7hmGhISQodFPx+G5gukMIbUzB/MYkbNftdHtchG2pR93Zxl3EY839gC1/4V3b743zzSaxkuNclw601k2pQ21KLGseyJ3AjBSgtq93iBTrwwhbFOR7EZMm+VijM80B71SMVAM+7KAaO8lUUHpTlpEEb/s51Uhft4ck47k9gzW2EghrpGMzlDvcj01GtO7tolHN811g619zMVHMdDVn8eQFupUQfEl/MOTm6oq94QGzqeKLzy84f/+Idq/DyxdPuXj1mnYWUfuKrDMkMGfY7zAr4bO/+YLf/eo3fPb7v+Gb1QKvIhJTMjjc53Y8pttr46qKy1evaQ8H3H9wxttXL5lcviQ2KU4HBmmbt5Mlg14fly/54xd/5ucff8Cz5y94eXlBdGkhTui2M1aLGWjoGMNyPmOqDe/v9fnmdkrx/BXWWG6Mou1rJjNHaqVu/HI04bwbM4wVL5ZL+sWKEFssgbCYUwUvgaEseXVT8VE34sm85M+jG1KtGRlNx2omsznWQBfF6+tb9vf22BtkvBpPmc9m0Grhy5JIG0pX0U4ssfN8+exbfv7oIV8/f8mL1y/RtcOlMXutNvPRiE4nwxc1N5eXtDpdPjw54vnVFZd//D1GR2LzncXM50t6qSW4wJ+fvuDj8xMury+5GF0RT27QUUIry5jN5mij6CpFMZ3xKi/48MEpX7++ZPL8G3QwOBy9LONmNqOVaILTfPv6NR+dnbNY5rxdTbEXM2wsJaJiWbIM0rtDqY1A60dZLFLv984TK8VEK1res1jkaCTQlaVDxXAewzelZ+ghBOmKGq0qJgSsEjXFpAw8ULDS8KYO9AjcWJFnlquKQjdlCaTMcm7hy1q+qzUsLLQqz9IIapFoQRYOAhA16gwFq1i6xqoiyGe9bFNrOAO+9SKbTTTMI2iV0nvEKVFooBr78wjeVtJ7xSUS8KNSnFzL5jiVgWMPr60Ef6NhlkJWCLJR6SZwI0hOZqTtfeaFZGoDpEUg14FayVigpSx0bcRvxCiYJdLCPtTin+FCI//VcGDgpRNVkbewiKBVCTISdGOcpkTZMlqPE7BIpezplzWrxiW4UR9zDDyHTe+acQStKpA3yFCi5DfoBAG2r52Mk49kbINrSL+Ns+kPLT8JxAPCRhWxVmkIZ2NrZrWWvK5RjdptDb/KDX9ja+q17lGy6XZrDdaKp4SJrKAaDSdhbVIVRc1jHBMnO7yEaL2+w2No+AZbnsH60XwnIO+u2/4iu6Zf60AtyYUxtjmehChONo9rBMZYi7Z228VXmy1HQulmftCUbYJibbLqG4TkTiv65jH4NRqyqW5tyh53+8vI8aKVrEptn9953fA2NlyOXYRp1+vDbP6mtEEps0kotonGNgENBOHG7PBg2CQgP84lHZzDGvjk5x/TSmOSToebyYzSxNzeXGF0QEWK1cJjveLk5IwPP3iIilMMljc3E8piyXIxw7LC2JS38wUq7fGzTz+h207pdfYYT6eUBcynM5SxeB1RrXKKxZJOu8/9R+8TTCDyNTe3t+A98+UMZS1tpZheT6ic5+z+I1RkyRTM5kv8YoXzUkKLtMZ6xzIvMJFleHiEU5BpxbQKxM5RNDfcPSXQ7rSC/qBDrQwtoyg0jEsnDbOCQK894LoMFEGx3+8QgHakuS5rqB3Oyw2rBayWU6plwXA4oN/roF2N0Y7JdIpxXhqBWUsKTG6nOAXHp6foNCI1isliQpWXLBc5ymhSo/BFzmQ8JWl3OD48IQpyTjeTGco58tKjjKYHTOZzVnXg5PwesYlJNIyXS6rlCufkfmWVInE1k9sZaMvB8BAfHInWXE2mRK7GV2Je1gWu51OC8+wfHBJlXawSz4fSCVwdECLmj+lcWjczVpuAJ9CNYaTBOC/GWkr4CPNKZsitxFBrMe/SVjH3noSAQwJ624nZV+6hl1mWwCBWTHeIAAFJHvIKpnXjAWEkSUia/imRWt+PRG47c2Lz3YkkIRhEgoT4EIhMEyi1+GgUvmnSZiVoty2MAbtW0KlGzloLYbMfSdDuW9lmHuS6dEGOxzSISgTEjZHWMJKSzDreFkoQjrxu5LINgadnASslDNskE1aLDfzSSzIfN2Zj+5EgDhpJBKom+FeVOJxmRpKMjm4SqiBj7oKcf6tBk4wTAzSHdPedIAhFpAVRzhSoWlAfqwTRMEos56dAvL7fakk6prUkLK1I9pNZCEZ+H7tOEBU/OAn8ySAem86j7KpYHM6tu5B6lBf2wwZqD14MfJyjLAuqsqSuKlxTYtkEStvIHTdQvGoaym2DKjRBze8gKuEddcsO8fJOr5YdQuemz9kG/WDDadhFPDbnfCeYr3kjGmMlMYrtNkFaK3201vgQUK5ujlu6LG5s1Rvew/oWFpp/3YJosCmrCKeDzeP6eDf9TkKDqzRwx9oGfRPoWWur1uu7SceWNLouyeidEo6MmdqMHWHbsE4FIHiCEk7IJhHagXfWZaFmMJvj/HGmi957er0Br968YTwaoY3CEdFud4hUi/HoFmUs09sxWQqmfcSLVyPq5RXeOXTUZu/oiMVsSj5dodKENy+/ZTgY8vpqyng+x/ocSkecpHTTNjfjazQGpyy59wz3j3j75ppVkWO0witNq93Ch5rb+YxMad5OR3TbbepVTl3lLJShUhqjFP1ui+l8SekcB1oxqwr6/S7VfEZZO+llBBBHpNZwvczZU8CqwkYGHQIWR17Iv78YCFlMWTlGteOAQFXXdNoxoSxxPrAq5Rq21mCiiNFKZtaDsqYymm5kWU4XVJU4/FoFSadDUVWMVivaSjGZzxh2exTzhSRLSuNQxEYz6PUYjcdoPG08i2AYtros57cUdUWhglibt1q4uuYmL+kpWC6WtDstXFmwcAWmlgKI0tBpd5gullQh0AuBeZ6zP9wjX80pnHTkigCVpBhrGS3mpBrS5QITW6yr8dWCgKJumoeVBpQX9UD0o1zBsnhEsWKRgLtcBGlupsVUa1YE4nVQR2F0IAmeumjksUrQARNg6mBPi/QzSTS+csRAMZdtVMi/Vh8aIzojjp5KC3rhXBPolSALSksC0zESJIOVEkICsBDb8FrLZ32Q7acWZkiANE7KHHEzxrkDVKOAMRKwayUz9zhAvRBORaFE7RLRlGyMBHmvhHdSefALOc6yKQ9tbnNGEhLfGITlK9mma7apkHOKjSRIwYJtWsu7hSQClZJt0oxNaNxUabZZluJsihLpsApyTK2mQZ1rxskA1UySsKCFA+KR80sMm8ZyUS1jYfLGfdbJJGPVyJPXyivl5HcuV5IYlR502aA1/g7W/p3lJ4J4SFnBNOUE2PI8NghHQxytdtxFy7LauojuWJiHJooqrRr+gcVsOBq24W40r+MtdyOyu1wOQUWs3a5mjZhsZupyvOtMfFs+4Tuz8R/iJOwmHaA2x213HD9Ns3+9tgzfoAM7Af97y0iwJaNuk4/vrLCxZb9Tu9l5ui3fcDf4735lcyx3x2DD8zA7hNMGBbmraNmH3vMGAAAgAElEQVRxYf2+82F9Dpu60TtlpX8A4/sXXFrtNldv3mDjiF/929/Ra3X55IN7fPDpJ9A6RkUZPmii1hBd3bCcvuTTX37C3sk5ndjwv/5v/4Gs04c4QTmNc4HBYYfR22eEesm/+Q//jqy3x/n5Ab/83W9QNsUqQ4UXh9jYMprdcH7vnEf375F1O/z73/2OzMakSqE01M7Ra6VczaY4F/jVJx/Tb6W0+j3+4mef0mlGsCSwcoEoiXi1XNFqZbx3ckScxXzw+JxWZOgh0sIxgSTSTJ20KX94dkI3idBJxL/58B49H4RoZ2HsA7GxvFpVGGt4/9EZrSji3v0TTvYHDJHfcxECSity7xnlJQ8ennPQ6+KThH/3P/2WFJlRAqy8o9Nu8WY6IQB/+Yuf0W13OTg94dMPPtjA+FUtMzdlDNPFktOjI86PjrBZj9/95je0TSTIg4KFD3SSlLezOVUV+MXHH9NLU5J+n7/87a9pa03SJA41gTRJeDOd0mm3+fDeOWmnxa8+fo+9VkaXRm7tHElsmXhP5TyPHt0niizeaN472Mcis88fe4m1GHSljSOpUnA0SNiLDHtIIJ80844SRelh2G9jE4sDfnWa0GvMsGZNJ9PMKGZerBC6B1000rL+flsUMq5JWJyR/RcBWplBZwbl4Xwos+2BgmWTDMRNoI+AZF+UNBFwvwvDZgJVa5F4xkoCYzdWRF3x3T1oizJkqKSJW93MmTzCk2gPDVYLL+TeUFrPx0Zsz9f7rb1wTOxAMOZeAsMYBkDVICdKyfWngXZHYSKF9nDel142LQVVY42erEs6CrJ9hVWSVOxl8tk62jrbNk1paWdgMklcj7pyTl0FudlBSbxcW509g2mO535fSlZay/7rIPtfBWhFGtsTXOKgL6WvPlKGK4IkIiBJSK9ncE0YGnQlGVojPH/f8pNIPBQIsTMSkqZqzLFCWJuC1U2iUVIWBUVZUBT5Zi3LXNCOpgMtikaS2/QFiSIia5s1upNM2F1i6CapaIKjuhsI7/IyaI6xCYVhy1N59xG+E8vZ8hTWT7+boPCuwkN2uKP0uUsw3X0thNGd0sSGQPo93I7v43rs/he2ihff9GWR11tjta3PyRq+/K5iR20Mw5qyizKsib6qQUruPDbjsk1s1sezmzC9c+7/7Ffnf98SvMIoi1Kev/jdL/nibz6jP+ihXMWzb17C8ga/ugRlWU1u6fT36WRtbGSY3Fzy6c8+4v/9z/8PtVOEcopSOc6VaK/RAX718w/58q//lsQqTs5O+cNnf0tQjtwXRCjmywVZ0sKamPOzezy9eM3Z8SF/+OKPrLyj8AGcJ/KBVVnRQXN2fo/n11cUAY7OTvj/Pv+CqRI0MPiGkFYpYuDBg/t8fnlDmqa8uR4zK6VNtga6HvHbcIFOr8O0cty4wPHpEX/19Wsma9M4L3X0rhOG/nvnZ/zhxVtoZSyLmtfjGRMap0cvUHqvdLTSFGssbxcrHj64z3/5/R9ZNjJMQyAKYgjYVvDxBx/y5bMXBGvo99r83Z+fkNO08A5Q1p6WtmgiDg6GPL++5uCgz++/+ooFzSzcQ0KgqqCH5t75Gc+uLsm14d75Kf/lb/+OmYIqeCIVqGpHoh1pgI8e3OPzV69od3u8GE24zQvyJuhkHqpVTbesBDWZLSicozvIeHk7kWv9x7qAm0UDrUJQhN5hh+fTBT4xFJUYZBVKZuxRBcEF7pWeEBlUYrisHP2O5dlVjTcaY5syQ4BW7hj4QLuX8WqxkgTDwnQlvIS1aVfiYFCA0QqdRbzNPXEMk7nM9mvV9EdxkFSw74BMc7MM0iskgtuFNDyrlahOkgC9StADmwXerLwgGYWcs1eCfhgnZZw9DyFWLGrP1IuB12gqBmOFElVJHKBTS9JgW/C20dHmThKcXAsqU9Uiqx3UEIyi1opRFUgzuFkIklRqKV0lHpJSgnzc1rydi+zVA6vGyGxRSaklCtBveqooKwTVJIHxSn7ESotKxzjxQBl6UJniOvfkCuIIxgtYGSHa1k1DvUEpCZVtaS6WjiQS11aP8ExWQcY+quXfcRQpZnWgDoIErRbNxOUfMKT5H0o8lFLfKqX+oJT6TCn1X5v39pRS/7dS6knzOPzv2NAmEdDrIATCPXCu4W5svTjKQhKQbRKy9egQx01JPGzD67CNz8SuMsVYi4ma1Rq0Xatc7s6+9boE1PAXlN6iExLvdhQ4Yc2jaFaaMgZhJ3BuTnmznd3/2Ek41n9bJye7+9hNJDaGYXeOZU2O3Uk61slC2Anga8ggbFOk9fY3RN+dpGOzr3UTu7BTklqTRLhzGg3a8a7CZee5+u7jNgljm3w057r1WXnX1I1/UqXln+M6VniePfuaTv+EP/3xivN7nwKO3//xKcZ4VGR5+OlvGZ6ckq8qvvjDN7QP3uPllSLr9Pn6q68pvUGbmla7zQe/+C026vL5H54QdMSzl3OOjh9ho5i//q9/JI5bqCji/oNHHOwfowM8efKE/uCAP/3pGwZZj5vRhPn1mDSyxNby8bl8P7+dUOdLVtNbWihaRvPkq6/pB0dHaU67HQ47sVgiX18zTA1vv/mG8zTGO8fNeExfaVLgg15MMJBUFfkqR+czwnLCvtE8fXtFVlZ0tKIfa84ShQeqxYK2Cby6eMG9NCJSimevL+krRaIU7/UyssQSec98MacbeSbXN3STiIu3l5TTBX2j6cSW+0f7KGNYXF9h8VxfPGW/nRFbw5dPvibTmhTF6aBDt5ORhcCrl28YtA0vv/2WwzTmdjpjMRoJimE0j06HBGOYT0ZU+ZLZzQ2pVqTG8PlX39BRgbZSHPW7HA56JEoxe3PNoJ3y7bOnnLQy6qLk6vUbBlqTKMX7x0NsZIjrkrpYERU5fjkj03A9WeFqR0ASn/gffwn/s92L18hnT8H07ZSHNpBoxctpQaaUzJQjgfEtUPpAxzny0ZRjFbgua/LK044Etn8vlsDuESRjOVty5GoSAxdz4YUYJajBQdz09FGQqcBqlnNOEAVJJZbltYYHBmgSC28glJ5u7WkrUXtoK8hErMVmvUKQh8zAaimN0ZYIRyVJ5W+H0v1iI4nVLmCKQFfBdS2fSazM9E8b7kehhA+xLOA0yOx/VAhBVSuxYW9F8rnCQESAledASefewkuyEDScRnI+VbPNfOUZukCkYFSCjWWbHSUclIpmm1ra0J8qMVhbNOfkm+P0DecCC3Ue6NWBlobrQngZScOlOUxk3zL2sFzUnCHJ3KiCNJUk6dRI4hmUlHx0HYhzT6zgystxrYmwP7T8c3A8/pcQwvXO6/8I/OcQwv+llPqPzev/84c2oGAraTVNAAJoAp5a91hxToplDZ8heE9w61m332jhtWoUIWbHBdXelVreUVesSxHN9xUeFXbQh+bzwjb4HhTiO9EufOfthuq6ebZBO9Z1u52xAOEM1K5GqW1pYd3/RCvV/N1tykui4tnpq7Lmo7AjlQ3bZGMXlVknRhs0RTW8kHdPbectDahd5KV59EHe/26SJKY26/3cRTK2n9seI3ceN4eyO6Y7b2wTqX/y8j90HQvXVoHPKWZTbkLJdVnQjiJGr6/p7h/w9tk3KJuy//A+128uKOZvoPasllPmOiJNepTLOUna5uvf/xXdvRNKK864+eySS2om0zFGw/XliF6vy+3ollCXHBwecHU7xtdLqrKiUoA3aBuYTKbstVr86c1LWlYRZxlVUXNb1szqKa4oMFpxWyxRXjEvhLjdaacURY3zgaV39CpQvqKjYLRa0ootz+e1kN9aMXUZmLqaWe5pu5o0BKogNeI4iXhVVCSJpgBqNIvK41YVLizpac3VfE4njnmzrAjBMez1mM3mFCVUZUFS19S6ICEwXRW0kozn12OyVOGJcFXNog6UkylUK2zQzCe39GLLciVtE7q9LsvpglkeKL2TzrG6IAJGixn9NOPp5ZQ0DSS6Q16VzBX4xYqwmhFjyBclRkORV8zrkn4nZZHXGALzoqaoPcHNyazhzWxCN4l5eTMj4Ek7GcvZkpVzxEGjXKDlA03Xd5FH/kjXMDSlhjYsCsXcB3zhsd5zYmFRVbSaAFc6yFqW0jsmlfSVGjgYOLBxYFYEshje1JBqhWtp6pVn4mV2nFXSUr50ARskObmtII41TntmhSBUGhh4SNowXQj6cCvgAroFdd4gCxGkSzhqyht5LV1ux5UgKz6D5VKhgvh39J104R3nQu4sjHAlWi1BXqYN7yIt4FiJcmO+kqA+qYUsHTKYL+SeU8eQ5eKfsWw4GpWFcglJJmWMRSXJUFxLeSlOYbyUhnBjHzAKfAfyRZMsRZCuxKhr1TCObQrTpSAW3goSInwb2A8Qt+B2CVFDdjUeaCvKMjBTgi6lORxZSeLKErKsSZiMnEe5olGQQreErAW3K0GMllr8O1Rb0JxlaCzdc9gzkowscklowrthcvc6+yde4D+0/O/Af2qe/yfg//gHv6G2/hBrlcdugWgTkNb9UnaVLrsEzyZcKq2a0knjfGm/z1/jHdXJ9/AuUE1md/dwmmNer+puEN0tZ9wpcYRNAPabmftOYrDGRJoZfV3XG+v33bXIc/KmD03ROLMKqXYtI653OsaGnd4tYYsO+N3XO8jGOgH7nrKLkCnuroGtWZln/bbfOc+dxnI7ChoX1hbuu43nto+7+15nG3eTDHU3OdlNWv75tIj/qOs4BE1R5tQ4fv4X/0aS3nzMwfERnV5EsZxTLFf4oBm9+DPKBdrDAz781a/lcnIFD9+7B9pTVTXOacr5ivnkFlc6Pv7lr0lbA6p8RqfXYf9gQL6qKFc5cZxwO59Q1yUJil///Beo4MmXC+6dPkBrzTKvUcGTtTOuZgsKX/Ph6SmDXofKB1ITcdI/JChNWVYoY1h6LT1SQuA3jx8S/htzb/YrW3Kd+f0iYo85Z575nnurbt2aWEWRpZIoyd2wARvd9j/gtmHDD3oQug3DgB/8F/SL/wQbaAF+9YMBw3A/GW3AMAy3YVGkKJEUa75153vmk3PuKSL8sCKHW2SXpCJbxQ1snDx5MmPvHblPri++9a1vOc+k0Yw6I7SJqGox6MvaKS8XNfPacrfV4s5wwNKCdpphbw9roCwbaq1odMSkcODgg3unoBSzRtNrdUnTjFXdUDeWrJVztlxSeM8oSXnj5AiLBK39gyOsNwImnMVEOfPlCq3hvXt3SLViVUM3yem1uiyrhqKsUSbmZlVSeEeuDe8/uI8HVg0cDw6IlaYoKsBhTIezmYhF3z45YdTrsLKKSMf0BnsUNVRlhYoME6tY1g3KOT585008sHCaw+4IYyKKUhYHaafD2aKgVpqDdotR1qHyUClFp93GI23df4M2eH/n72KPCCCthXe6HSqrGHtFSoxShrmVYBencF00VAUM0By3cyonosLIp9IZthSA4hPPzdRSNJ7X2zlYzdiBdxplDUsHy0IC37hxLJYQOcV+K6VppHNsvZLKvFUpokiTwfVcPrthHGEqzdxLZUwTvDYWhXw9L4DZFGzt2csTXCVjlmGyi1qCbRLD5VL6k7TR5M5QOkkvVMGLY7EK3iJGmrw1Dnq5gVICfVNLinDRCICIE2FhikJMtjITUVkxS6tLmfDFSnrTuAjGE0nXdGKNL8SxdVWF6hwL85mwLuMwvrKQRQpVSaVPtZL4sqwEVOgUbuaeZQ17JiJpNEsfBLWF6HNmC1k4zYHVXFKNo1aEK6WqpVkBVq5puQpjLmT+Mm2IXETtBezZOjBhQeT6b9p+XeDhgX+llPqxUuqfheeOvPcvw+MzpDz4lzal1D9TSv1IKfWjVbF8BXToTYXC9iDbwL1teGZ32s97H9iKNYgxhmgXfJgolG9uDb90EGdueoisS1tf8Yz4N207aGSdCtlNqeyAj1cC+zoY86pPCX4bXL3z2KahLAtWqyWr1Wq7FysBIWVJWQTwUdfUzbYT77qjrl+nI3ZBhGer19ikUF5lQDZ+JFvI8cssxBoM7ER/vwYh3m8/I+c3n9H68a/ad5vx7TI2bidd5Hdu5FfPaXv8b6jy+Eb38Sv3cLmk1W7z/vtv8Zd/9kNur6/4d/69P+DZF3/N+OaSvdNT8v4Ib6Azep2339ynuLnmJ3/+/9EbjXj3/Qd8/JP/lzhK2LtzDDHErYRWt8eHP3ibn/34Jzx//gU/+Ac/YD654vzsGd1Oi7zbpSxLunmbe/eOyUZtfviXPwYT8bvf/4CPHn6G9Y7+fkdU9aWj3WrxwT/4kL9+8pQXF9e8/cYDbJLw8OoSFZvgZ+FoGU2/3+POgzf4q4dPWKL57puv8elkTO0seaLpekWzqulmGe+9dcrjsubL82sGewM6gy6PJrc0XjGMFZmVfhZpnvHgrbf5ydMX3DaO77/9gC8Wc6ZlRZ4lDIymXlV04pgHD+4zMYbPnj4jaXe5e3KXL84uULHmsC2mVqr2pFnG+x98yM8eP+NmseI77z7gpql4OZ+R5gn9RKOspZ+lHN85Jj3Y5+cPv8RHEe89uM/HVxc0StPttYkd+Lqh18758A8/5OePn/Lw5TkP3nyAz1KeXl+j04ReO8E2YZ6GA47eeosfffKQwsOH777LxzdXFM7S7iTkQL2q6OY57737FldVzYubW/aGPZJ2i9vlEggtzb/JHfwb+i5erpZ4ozgZpnw2X1Arz+vDlHPXsHSWzMC+gqiCXhSx109YRPByXuATzWEW87KpaIBRLFboeaXIIs39vYhHi4LCO45aMUvlmXmL1iEtUcORVuQZxKnnxaKiMXCSaG68fLd0IvGhyAupsDjswnllKayjn4qN/wxhbgaRlPOOnKRfujm8WNaSMghW5NrLOG3k+AMjHWvnzjGrLVkimovQdJWegZYTO/I0goMcLleWRsFRLEDBIozIQIsPx74S0alTnnFpMZHiwBjGYcxBFLRPtZSmHrbgonKUhK69SGon1uH6GzhQ0pAuiWBceGoDhwpmSgJ/N5Lzzkp5vN+Gs8qyDPNkUEyR3mc9I+c58oo4hn4OL5eWOobTyHCDpIFaRoS4WSnzNGxB6SzT2pIbQ8sIUDMEb5Sv2X7dVMu/671/rpQ6BP4PpdTHu3/03nulfjXu8d7/KfCnACcHdwID/+pLN2kOpYIl9lo4ADuZC9ED+LXmU+0YW5mtz0WYid358DvBfq1+8/jgPWAksDmN10h5rpb36835BbbkFYHBNmjj1SuBXIWTVsgNv9OuTc4bHx55gdXWhdWPXLMBnJPunhtTs53mdmvg8NVUz+aZr4CLLRvituDuK5+T+uqD3Sc2rA8BeAFr0zXlwCqUsgFEhqvfaGTYmRsPG83Glr1aly9vxvyqqdxuWiZcH/6rV/C32r7RffzKPXx8z7eyNnne5vTeffb2R/zZDx/jdA46p7g45/f+4D1e3KaMz79kpQd8//d7nL24ZVxW/PUvnuB9gvIpMQ3/wT/+D/no5x+TZDllE/PmO/cYdvf5ix/9Als1OJ9gm5q33nwDWzsuzp+hC8WDD95EWUUeZ/z0L38i94bRlLXjD/7hP+Dzzx/SlAvmz8Z873vfxS+XPHz8jHlVhkaB0N8fcafd4fHLc6LK045zDkYDBp0Wv/jiCQ7PCkiU4rsPXudscsuiqJmcz3jn9ARdLzm/nXO1Kmicx2uFy1Pe2Bvy8OKGrPFQO46GQ/baOV98+RiPp8RToHj3jdeYrlZcTebMr25567U73F5fs1yWPHn6JOSPNU0W8wf33+MXz87o1o7yaswbr71GW8FnXz6mqi3eOxqleOPe61hf8+x2CvMF999+C7dakumIj794uCm/rHTE73/wPT5//pKmLpg8u+J33n8XXTZ8+fQJ0yLME9Df3+duu8XD5y9Jqoa9uMvxaI9ht81PPvkY7z0Wxcor3vned7i6umE2W3Lz8op3Hjzg+uqSarVgvCgw3ovVNN8YePxGvovvHt7xuQM7q8nxHGdwPi1oUIRu7PTyGJTFWkU1bxgahU09xnmel2LsCDBTir224rz2JB5WU08LCey3ZU3hRfMTIToIFUsJb1zJcWLt6QEvQ7MyhwTATIsPR0tBuYTMezIFRe0oCK3tvbBHJpSexk5avxs8XS9mZkYFp9jAak9UcBcNglSDlLxeqSC4RNI4PpTTtpFVvkbcSi8D4+4QoeZas6EA34hHh8YTWThXltTImI0KbI8TP5NlISZjLS/PKR28VRBQU4UbJHbyRIwIWM+RgO+R1JXWwux0FFQFpN6L2VqYp3UVUIOUUC/COLaSb+uhhxfOBn1h+M7Wkm6JEEYl8tIgrnaWOoCeir+Z0VBfDfbfdFNK/XOErfmnwL/vvX+plDoB/i/v/btf997jgzv+v/ov/hvyLCNJIrIkFrZChQtwDtdYXF3jg5+GdxZC6mUdcFQI21FkiEIDM5NEmNigI8066Mv2Fb3DelVuLT6kcl7dm+2KPAT7XafU3XTQNsXhQoB060Ou52ojtBSQFBQkesu4KNegrJUbLo42hmXS6VU8BdwrbME6vbJlCjZlyLbZnGcT0lN2fS276Q0Idxhbh1QVKhLWqCsAjnVLex0M2tbuql4ZaRakxUY9ikS3szYK2xYE+VeBB+v52qZ/tkyR26ba/I6ANlTTOLtmSgSM/Pf/57/8sff+B3+f9/HpyWv+T/6z/xZnFP2TY8pJjXYNaTdlejtjuRwTxZ5et03hWyhrcT7i8OSA65fXDEYpV2fnWOdpnCei4ODgmMnMovySdn+EcRXzxYqjUZ+nT59SuxodGVpxTBrllI2YbA27B0wnV3TabSbzGVWxorE13kTsDwasZitiHHmekeQp4+trDk5OePHkiXxJK4WOIgZJRFGUxErTarXxTSUVLypispozaxzeGO62MpbVChxkJiZJMhaLGft7I66ub7h1Do2Snh15wm1RkihNnuWS48eSdLtcX14ycR6tDcMsw3lxKuoajen0WE7GdAZ7XI1vmdsaZT3eGE76bWazOc4r2mkbbTS2nNPrDbm+uebWOiKt5XtFg28sGYokb1MsV/T7bearkmmxorIWayL2u21WRQkoBq0WXiWU4wsOT0958vQpCy+anjiO6GQx5aohUZ5Wq0tRFZgoptKayWwMjcNGEfvtDlWxwjpLpiN67RaX4zG9dsrtvKDyfoPj//m/+O/+3u9hgNcPT/x//R//CYmHxBhwFqM0aS9nOl5wA3ileBB5Sbs4aGuFisWnI80zVmVN2UjVU6rhjhLnzhRItKJWHm2h1c9ZjleMkWB9HIyzpjaUFWtZoBFLmqWuPCUSUPcV3LrQOC54SGRA0tGUM8cSCYCDSEDI2AlQ8GGxarTCRDLmQp5i34hFuXLiCVI4ATc619QrR+lDqasRgDJ3687CYqgVaYgzsCsBJhVwFLxJGidzUSOgxmcKU3mKkMoxRhrfTWywIQ8CzRhpa+/XqRwvWgqrxEQsViL6jJH5Wnt4rJz8fhDmyfhtmXIORJ2IYtawJJTERjLG1G6dVJ0FjCKJFFXh5PgK7kUwceCDQ+l6Ma4SAS1zL5Uy/+J/+R95fvnyV+Lob5xqUUq1lVLd9WPgPwJ+DvxL4I/Dy/4Y+N/+NuNtqfYtpb5OmxhtpK36xu1yG8he7R0iZbAbJkJtm5ht0iubPdo4ZhoTiQ/CK/tXdCE6wugodEzd/v2VY79SfstXtB+72o51OmL3J1sH0Z2V/N/4Oaz3nfLVVyplNnqZXcjFJrWzZUn427EFO4zHpipnM3wwf7MhDRbEr3Ud9uC7UpayV2X1S7+Xm27C9dazZW2Dv6Pn+SUh6lcYp7/t9pu7jz1FNcHZituXT4hUiXURZ0+eoPySvdExyrUhzqGcs5pdUS8vub04x9Vzbq5nVMWSLE1p94+obRtjNMvpS5p6xdXZU6w3eO94/OUznILR4IhEx2hv0DQsFhNWxYKb8TWNt9zO5szmC6I4Zb83BNtgtGLZFExtzflkzLQUmvjp02fiKplmdJII4yxawa11TJzjajmjUZabqublbEZtFMd5RNsJK1c7uLFwUVUsdE2l4OnVNRfO0YnFrVJ5h0Uxs46J9Zwv5mjTMGssz88uWAJ38pgWbuM8PG4sF2XNqmywGC5ubphUFd0oYi+JSK2Ymk1ry9J5rpczKu+ZAc8uL5kB+5Fi4C2xcsRKcVM1XNYN1+WcwjguZwvOF0vQiv00xVjpv76sKpZNw/n4lqqpWKL48ulzFkDPxAyTGKxDac2kqZlYx8VsAs6zKlbc3t5gjGHY6aCdJ1aa2jcsrOO6KrlerLDeczNbUXkx6sq/AQf9m/wu9sjK91bB3DuirmHmHBeTBbdKuqzu41l6SWdcK7h0nlJ7rFZMFgXX3lIoaZSWQxATwxUwsZ60rSgUjKcrrkP1yX7wkYiQdMG1B5cofK4oKrEXr5BUQw8BGokSV9S5hXQgrMlq4ZinsuI/iELARQL1lRe/Ct2F0nmWeOZaQMZQC3iINdxquLWQDcULY1U4VolUu/QTeY3xQCzHL4F4JAZcqxqWRvQih2Zrcz5VQbDaBptAWXjmsbynE0M7BHoTydwXDvJhmDsrlvBGwV6ydQYtgtDWxdBkAkSq4ODaSaQyqQ6AY6IELGRDmCupWlmloIw4pK49J1fAlZMyXrqwajxz51hoaSa3r0TomoTPaQlEXRHnFg3UoTKp9Tfcx79OquUI+F9DpUgE/E/e+/9dKfXnwP+slPoT4DHwn/7NQ/mwIq+JjA4rX41AOBWMMSW4e+ekH0jIrSitf4nxEAaBTRWL2lm5byPnNvBKwFWvAAS9SbWAVx6n3CvBnVcC+nZM2EkBfEXMSTieWFVIaschtI5CB0MY6b+itSbSCrMpNX6V8fBItc9m9x7lrFQAKY/aSRtp7XYasW3DdDihnTNfZ7B+GaT63RexzWqsd2mrIlS9dSqwE+KwqpXCWrtpWb/WnmwYjTVgCI9fgUlrBkT5DVkT36kAACAASURBVJjazvGa9fCvANa/4/Ybuo8VWZry/d//Iz7+/FPG8wlOpZD3KXzD8uIxPu2j0gPaUcbRGw8YZH1+8fHP0NZSNh6imGI1pZlcEyV9svaAvDXj9/7hH/Lzn37EeHKNrcEnCdoWXF+/IEKRdwboJOHg4IS7x4f89K9/Kv8PThHhKJuS6WpB5hVpFJFGMe88eMDFy6dMbq+onZTDdXTEuCrx3tM1Go+jk6e8d7DPZ89eMFtU4MWR1Fh4UjWheZbCO3jjaI96MmcxW9Eoj3LQ0Zp5E5xdlcJ5i9GG79054tGLlyzmJXUIukoZnq+kGqanHLWH04MjWt5yeXkp9LH1tLWispab2tFRHu0UBvi9t97i4aMvaeYTrPeyAlZwYYXqHzglq+V+n9fabT578QJUsNlGVtVnZUXqPZHRaOV5/513uHz+iMXsFqcNkW9IdcSta6D09OKIWGnaWcZ79+7x6RdfUFYrnJPeK3h4sVzQ9h6HRZmIdw4PGI/njBcTEuOxjaw2XVjFfoOqlt/Yd7H1soo/binmC0+9sFgtFHxk4NrCAcJELIHDLKLVOKrCEYhYOk6M5WaN+LVUsQDTB23DdG6xc49TsrLvIgZjkRfGolBS9joCqsKjjDAHeSnMwrgRm37lJcAeRyIONZOQkrDihTH20vk199InRiMlq2Ut514CnVrAxgIJ5MqHPjAmuLnfSlrFOYhKSdmsvIxZI2mYo0g6wMZTeW8mRDxjJUDBhFDWj8Sng7n0OXEIi2G9iDb7StiIuobjWMShbiypmpaVVM2NF0+OxAugSJV0l6UUtmUORIWc+9QJQPNKWJrjJIhpx0i8sWAqsU+PXLB3D+e8H64p9fI5xiGdNK1F46GDydkgMBzVTPQujQVXyf9c3Xz9EvAbAw/v/UPgg1/x/DXwj/5uY7ExCrORwdoYH9rzKfSmeATWK3qh+9bpCu9cABkhaKkt67CtUmHDBshB5U5TXuGVRyu/abi2TgMo50ST4HYAB1sGw79yDbv6CQmuLoAO54XSWFdpKOUh9GXRTsuprMWaQW+itSHSikjrrXPqK8BjyxJJ6sTinMZuwIj0q9EajHZY7VHaoZxHMqvSw0W2nevaXJEKcyNztcFsa+FpYGq27xL44LzHOvl8vHfo8Nno4OOxTUe5VwDIq0dXO5/5es7YNJxb3zQ+WK3u+od8bQ3Xr7z3fjP3sXeed979Dj/9yQ9pnKHX6TGZjrl3/x2q1YSzZYmOIq6ffsHpnQNG3ZSf/PkntPo9Kj/HrxZ8+OEH/PwvfwKqg9aKxw8/5wd/8H1+8dOfMhvfcnxwzOXlCzqdHsP+EQ+/+ARtFLPllJZu8d333+OHP/pLkrRLksB8Ouftt97nyaMvqKmJk4wnZ+e8/85bXE2mnE+m7O3vc3N9QxPHHJ/cYfX4MdZLu4JZo3j7jQf89LMvSGJDJ84YL+YcHuwxmc5JG4tVcLucczDsUXrPvCrItMYpx0IrTg73uLy4Zgl447kpKt558z6ffPlMgEkWc1PUdHo9Gu/JptJ3ZVwUtFo5Scvw/PE5o36XybJg7mrevHPMi7MLIiRPfzmd8OYbr/HJ82c0dUUvyyirEpXmtPIW5fU1NTAvSzIdcffkNT797HNakTTaGFeWk+Njrq+ucTSoWHFxM+bB/fucXV8xWSzo9/pU8ykuyzjaP+DF8+fUyuNczXS54v133+VnH39EqiBNc25WK05ODhlP55iqxhrF7XzG3t6IwjbcLsYMe30mixmVcrQzjSscM4IF+LdwD4P8B0YpXBUCMGMlC8EqVVigY6VNeuUhihQ2VswKh1GKTEtr9naiSGopEa4joe+HbSNmYIh7qfZejMO0iCobFVbLNeQJrFagUUQaGivt3o2DXMsqfeqCR4YNpatKgu8ypD8GhLZRqRh+tRJYFRJYI6Vwym86AXeVgJYVwg5YJeCk0pIeubXB4VS+tokjKT/NM9FOOAQ0KiWAJFbCNmgtlSqNFbBhg0V5HozGOkrSQEqBSWBaybUvgsZlnUJZOkl/DBF2Rhup5kljqEPlThpSQ30FmRewE2thOfJgna7YilRXVgDC0Euax4fS3CyXuVfh/Bu3nY8MGXehZF42krrweBHYnQQBLF/3Tfxvo5z2G2yhu2xTBw2CDYFJ/roxnwpAYmsupXbSKVrSMWvTr1eqUwB2UhBf0VesfT9227N/1cyKAGx2af6QqGCzWt+svN3msXNWUg872pBX+sD4r4om5aLFAC3eNKiL4t1mdduGdRtTtGi7SyVP/Er1zrZ0eDf9sg714fdNabCAEgFYKrBAoSR2Z/ebx27zczfF0mzs7dcpFSkDLsqCopAqnWK3YmdVyHPFKrymoChC6XBZiT/FRlcTtDc73iU2pKq+jc15x4tnzygWU964P+L1N484OD7l/mnO/p1TSLu41S06jrm8HfPi0WNif84ffnBCr5vx4MHrHBy16B6d4vWKZjWhLlc8fvSC+e0Vd466vP7WEa28z/0373F4OERHGaW1WO8pyoKHD59AU/PB999l0Blx995dTt84pNPpoJSnqAq0s7y8uODq5obRcMQ7bz6glXW5f/cex4f7xCb0JHFQlQ3PXlxS1ZY7p6/RGQwY9Ie8fveUTp6jldDjxsFstmI6nuGSjDe+8x0wGfcO9rl3ckhsjPSJcOAbz/n5DWXdMDo+Yv/kmF67zRuv3WHU66CQ1RwOlsuK2+spGMPxvdfJkpTTg33uHB0RB/BdOnDWc31+zWpV0B6MuHv/DdIk497pMQfDDpZwnh6WK8uLly+pref0wZu02n2O90a8dnhAK4lRHsrao6zj7PKK2WRGqzvi7be/Q5y0uXvvHkeHhxitcU5KO1dlxZOnZ9iy4e7rb9Ad7jHqD7l7eodulmMIwbNxTCdTLscT4jTj5PQUlGHUbfFafx+8VEJ8O3ewbArQhZTTdno5qt8hUoq3BjmnxpAgK38PUqU2q/FKc3q0z1JF7MWa7xwktAIAWPiwXllZXOPJ84R81KWxcKeteC2T1vDWCNujNPiV6A5Gg4R5ZBgquL8nGo3UC5ugHahQvpnGmnxkKGpJRRz2gkuthmVwLLWljNnvRhS5oe/hTl/6vhgPEy2aBbys2o2B/p5i2QgDcDSQYNk4mIQxVSix7eYK21akDo460E5E+Dn1oaQVcIXMw/5IsfSwr+F0IMDCe7hpAmtcAw7aiSIeaHQDh5lU5Cgvws4y9ENxpYw97IkD6Z6CvZ4AChxcI/Pk7XqeoD/QlGGejjpb9mdZBxfUQs5nrxNTZIa2h7sDaGn5PG8R9sV7aCoBe4OBZuXEBG7UDXPyLfh4/J23NeOx683xqugw9BFZCwzXFt0bALDddoHJGnesK0A2K+31GJuUwzqVsC3J3FSNrPdQpmqt3THu2i373DpqbspAdx/vnO+aCdnBLL/6y2a97Fe7EGqHpdgFYJvOtypoTdZ/2/UoCd1bd1NGX8Wl/qsPvlIJsyuiXYOpTRfhXyXK3c5XvbG+l72uRNOxdp8VT5KdHjxrrUddU9c7AtmmCYLZ9TEcdjfv821sHpq6IY4SlkXKRz97yOm9O3z6i89ZTSfQTIiNJop7uKUVD4i4x6dfXFJXjv3DIT/8139BHicoW5K1cxQxxWKJ15ra9PjJjz7h8OSUi5eXvHx5idagjSGJM6qioq5KTBRzdn7J+eUZ+70Bf/6vf0zW7eC8Ik4ilDY0pfDB2nk+/eRzhsMORVXyxcPHuDgm1Zool2Ry2jS0tKKczbi+Oudwf8BffPwZJs3wwCDWskr2jo53JN7z7Nlj0tigkoi/+vQRJAltrciUpDpy24h4sCx5/PI5hwdDPnn8jLJqqFAMY02EIjWKdmOJgPMXT6mbin63w59/9Clxq02qFJ1YkyhIbENXeTJv+eLx5+yPulzcjDkfL0FrBrHCaEVsFEnTkCqY3Vxxu5wyGvT4y08+I251iIBOMDGMvSN2jtg7PvrsI0b9DmVR8vmTJ7g4EVfUJJJFS1MTK0U1n3F2cc7+/pCf/uJTdJLggdwEBtM6cmdJvefi5XNSo4iM5tnVJc4oVqEc8dvaFEK75wpqa5nMpnS7ioe3JSsM3sBBG/CyCj9Ags/tYgKqRuXw07MalRmylpRyai+26T3Aes/1bEa3Axel58qK7qIVSWCNlPQE0QomVYN3DS6Dz6/AZ+ATOTeLrOz7SlI+04UTQy4Hlwsx30oTNl4SHUQUOm0cZdXgWvB0AqRgU2FSbGAgBlrOaTL3RAksNJxNRTxpUvl8LMIApFpEpmXhUS14sRD2xaaQh74qJjAgTsHNUmLOMoZHE2E6yAJYQNI47XBN86BePS/FUt0FR1aLxMMWIqydVpKyqVJ4MZUxdS7VP+vz7CthdG6WjjSFmYfrQsaMk7UhJHS9MDbTxlHUFtOCR7fgY5nTNaCIvVyTBSYzRxSJt8lkJp/douFrfTx+S7rT+hDYdWAF1oHf47RoN/xO5YZ3UtmivA+JGCQ9sWE01uOqDYDAySp+k4LZCC9DaHWvdpzdeE/sBs/Q+XZd5bJ5HFiNrQeF3bAb1tmNxkPCvBJqah3MNxoTzwZMwJZB0euqjqCX8GuOxW+u+1UGSHQcm2qZXSZH775u68q6nqf1XPwSCvI7AC28bgto5Ny8lzp7GwzCBCiu013rSwyfs7NY18iceZmvjVgVtqkZtr8rpfAuCINDumV97rtl1vrvlmn5jW1aQ7Fa0OnuMR+Pee31u/zsRz/GxBm388dkvT6nd06YzmvKuGK+Ktg7OEATY6uaH//Zj4jbIxbPXjIcHTPa3+P6/IKyqUizAcV8ztG913j06BNptW48edphOBpQFzVNmbKsFwwGQ8Y3Y7ppxM8++YgWiuunzxm22hwcHnB7PcG5hshE1N6RZTmX5xeU3jOINVnjyIYDEgXGrCiagna7xWQ5o5XlfPb0KapyzFfndOOIw36Xq8mY1EQ0jUVpR+2gWS55uFjQd4HybiX0tMdXjqqsSNOY6XzOsN3m0bMXYC2LxZxerBn2ulSrBY03+MqSZYblskQ3lk8ePWKgPKxWtFsZozRhspyDt2SRYbxa0mnlXJ5dsgyBqe8VWbeFKmoqD76s6GQx83lBRsJHjx4zsI5FUZBHEXuDFuNFibEKpzWVbWjlLV6eX1LhGRhN4jytUZ8YTbSc0SwX9NspF+NbumnCwyeP0Y3itjinn0QcjEbcTm5J0Niqok4SKip81XBZVKRKdA6Wb3k1qCTApk6xXFXsGRhPA0+PJfKKloU49jhlUJEjUY5mVTF08KJyDI2UxC614iT2nGuFiyX9clPV7CXS/6PR0NaezIveoxfD3CnqxBM3UBeWAXAR/hZZSVEcxHCtRVQZA6Z2pI3oEpzeSYE0srK/aRQ2kzLWunYMPVxWAgy8E11Ix4iQ1Bth3DSifaASYeYoEzbCWvEnuawlNaQaUNYzUGIUlqyNWIInh45Fu+FjuUbtxLn0RkEvIXi0y5jXTsaMgbiWEuFlJYLTOBJNiHbQjQXs1BnowJBkDZx7Eb96hLUZGGFybGjYpj3kVuZpZaRJ35rdGkVwZQVcJA3UtWUU5j6P5b2NE8Huwki6S2kwtQAVapgFAaoN7MnX5Vp+O4CH5xVPik1JaljBSsz6iv+EC6Wq6/QLsA4+m3TKeviQsxbPja3eY5Nu8GtXzV3zKvtKymDdGdduLMqbHTbEbTQdu7qO9eN1KiWQjuD1DrOyAyLYTd6sUzY2eIlsV/S/xPIQgnW4JC81j2ilQ3t0Eak6pbAbvQWB29tlCsLPDVO0mcBfAh5rFxLlFZ61+6qsaL4KPNas1QY82jXwsGHe7QYwbn7q7e/rVBgBeO2m0jZgi+C38uvfjd9o8x7qpiZXNXEUU1UWF8FgNGJxc4GtGr78xc8xJiVODXVRk6QJ2llwK+Ksx8Gwy4vZOctVm5tPP6LdalNXJUlqybM2mapw1ZLhcB/XVCyLghfPnkAUkyea1dIzaDXkaURZipV5t9fmxfU1plF88vgJrTQVHZCCTtaj3e5zeXFJr9WBRLGczFiNJ1Tek2cJRWUZxB5j4g0Y3usknC9KUuf59GpMZBRz5P+gb6TN/Nx7ukqTpXBZOfJVw5dOurM21pHHhlYU451Uc+2nKVd1jfHw9GaK0p7IgG0ahirBxBF1XZF5T5oYXjSWblnz+XJFnhic82g8eaSJvMI6z2Eas2gsJZ75eEWDJ4kjauvox5oo9ti6IfKKbiflelbRcp6H1zOSyAAepTyDLKeJDZX39PIMncQUkxnleEaFJY9jKmfpqogkS9DaQLFiLzecrSzawcPzS3QUGvBZT1RXtMKcdhXUSlGF/63yW7qH19utlxVtqjW1ckQehkpx3gg4eln54BPhhRXzikRLG4cREHnFrfPEeD5rtjoF5aVUu2zkOkceZpWi9lJWWofgOAuv7WhF4zwdQoollI8+tyFFYAEHCYraiSal5cUxtXbyFf88MEjLRoBLrhQVntTLa2eVvO4KOaYJcrG1ZXiOCF3rWtIRcSQBXiFOoTrYpxdeXtvycFvK99DcEYoTQnM1D5FVpN4zQoDRrBbdxoUN77EChGJRPW+uaVqKaFU5mUuApZXzbSGMR8+HFE8lTMhFuI4ygKtYKYow5p4XTUcpaz5eBLeE63D8dpinlpcmkLeNMDdnYc61kmt3iIdWgmfkRUviA3D7OvL5tyPVAkKXNw020Oe+EUGmWgdQpTEqwigtngBrJagHwo2qvEIjAkS9Tiv4Xb8Lu2PN/VUXVGE11l1w13blq2L1inOouIYWlKXYlW97pew4bLJdpa87sq7dUb1SQYS5A3Cco7Gy23VQdhbnLd6LpNn7BoHHFrXevUN7i8YR4TB46daJJ1aeRMk/quzheTyRcxhnMdZibIOyDTr8VLYRCOwsyofjKIfWHhV2tMdph1MOqxoa31C7ispVNLbCugrnShoru7UltimwTYltKqyVvhlyfY18gNjwXxru7LVgdEeE6pwNwE8AoLMCXgSE7opU//43pQxaeYZ7fY7v3eXZ46fcvzPAL64wqkGnLVSSk3T6VGXN0eGA5WpJFGlsXbDX92hj0VFMkmVorUmSlKpccnx6TG94yOMvP+PO3WOapsArRRTFJImhlWisbegNWmAyRgcHjKczTo6OcCYj0watI3KlyNOcVVly+vopadTh/PqSwWgPrzWRSsi0IlUCCrTTZFnKcDjk4PCY55MZB4fHVLpNy0Qk2tBVcNjNqazljdNDkrzLXMW4tEXa6qDzEZmC2Ht6RtGJElLgdP+Q0WiPp9M5e/sjCpORmhStNLmCYZbQOMfd/RHGZKSdHgWKVreHSodkGoyzjBTs5SlNbXlwesLeYJ+XixWD4QirEpKkRao1mfeMkgiUYtBr02236Y32GJcN+3sjimxIrjWRUnS1YpC0qOqaNx+8RtYeMJ8uORgOMToi9RGpVqQousagMWRZSn845GD/kBe3Yw4PDqhVi7aSFuxtYK/dprGWN04OabfaOJ3ikxibZZgs3ZhkfduplqSBYapod1uc1wqVJCx0RKI01nv6Tqo5vHMcpRFZGuHbGWdKYeOI0qQbxmDQQD8VpuugZWi1Ui68pjIRMyVz57wc8yAshnpAO1LYLObSQaM1M6cwXgBFr5EqkbqGQQw61iyVZqEVCyXVSY2XwHjgwWhPamU1rvKYawtOi/175KWypdvAMBaA0lKAVlijmWnFSilqK5+NaqQfTRLJ+HkCpJqFg0qrYBkvY6ahCqQJ4EAphYvlPAslduUgX7f9GtqRMBXdCHSqWThFqcUKPnbCxJhaqnqcElfWRINLNXMFVmmWNhiNOejZ7Tz1EzCxplCalVYskJLkBqla2XeAFuakE4FuRdw4sFozDddUO2g3Mud1I2mXxGisNqyUogiqSk2oCvqa++y3g/EA0Qgogs5DVk94UTYbNEoZ0B6lLCgdAvL2/eumblppWSWH0kvHliUBjdIOjeSl9U4qxoagttYUVAFYlEVJs/GVqDeBzjkn0xxEp5ttkwFZA45X0yrrxmpeKRFCOg/K7rxZYZEVxTrrsSkwDQgWv5GDblM1O2kYtxlp/c6QHgFJd/gt8+CdRTsRKK4ZD6V1SAkJk8C6My9yuuxcz7rPzCsC1B1NiGInzbLbJ2YDLHYmbXOr6jVRIvO4PqYLvX69gE+0dLYkpK/UGpB+C5s2mrzdpXYVH3/0Cb1Rj1r1uLp6TJSk/M57b/Hi+efobMjJ3ftMzn6BLRZ8ee44vHOP5WLCzeOP6B/d4/DgBGcrBqM7pFlOXS158uwJeauFTgZMpy+x1vH2d7/LfHyDXcHd1494+eIRtS/55JOHHB0cUqwqnl+8oNvucHJ0zNn5Oa20xesnCa4oOb+9JlaafrfHk+lLJpOS4+NDYtuwWFbsjwbcTCcUzvP00UMO+wMSGp6NrzCR5rW9HvNpQb1qeLC/R1PWjMsS3TQcDvpczRZcTyd02jn7acTtomTYSZkaTVlbzi4uOWm3yfE8m0/RCu6NetSrCo/njYN96lXB0lrM+TlHgy6TZcn5cko3N+zlKfN5jcFy0m9TFjXPrq/pxxGtRPFwvMJax2k/JbWKWWO5M+yyXJQsvKJ4+oKjYR9bVrwcT4jjiJNRn/lkSZRFnLb3WS5LLm4uydF0uz2ezM4ZV1MO9gZ0UMzKmuHegJvxFOvg8aNHHA0G6KbmcnaLiSPuHoxYjWeo2vL60QHLsmJeN8R1Tbfb4Xa+hLqWIICUj35bm1aQxgpnYTabczeWHNBVUdN4OM4gtoqZ9dxpp9SlZe4cWV1zlCuK2jNuCjIF/VBRYqzmIDdgHbd1waGSNMRlJd8V/Uj0IqsG7rRjVkXDwnkoJNUDnltkpT7KQt+UBu7kErRnjaULtIxiaj3LoKnoxuKrMYwUlZZOunVZsa+Frbn2oikZJsI+lCWc5pKKKKynYz25kgqeqYHcQS+HopSURWqCWZd1tMICb4owHMNI5rKqZM5qD4vak1eWtofGK6axtJjvZ/I608BeuKZVaekgY84cFFp0KkkkvVtGiRx76cBUjm4AbWMtpe7DVMS6roGTTDxCZtbS88LQLJx4b7SReVpWYkzWRMLeNMuaoRb32GuEaRkl0oumruA4lX4stbPkCgyKxsv5WET78rX32b/Fe/hvv3lkRWtDcLHbUklQGwYj0hqtzAZUKC9BaZ01ELS1KcAN4+4AC2dfYT+sCyxHE8BGXVNVu43ZpMJiVaxYlcJ2rCszRPxY0YQqC2u3zqEb0epu2kevy4DDzlcEqLvako19uA0MgEWt4YRyKOVQyK69QyM0s1GeKLAdsfLEes12iHJ8s3uPWbMezqLszu6s3K1eGBWFE82IBmU8OuT3MB6vAuuBpaHB+hpLjffrvcG5GudqrKtxrsGt2ZvAbCjl0Eoo7c3Oeg83xzr5tDYQC4BJBMY7JbnfIuPRNDVEGcdHd3nzwbs8ePNdnj96xmD/Lo1q8Vd//n/z5v0jEtPw6LOf0jt4nQ/+6I/43offZ7UqcFYTpyMm4wnnLz/n937vdzm7eMyyrNg7uMt73/8ev/vhD3jy8BGj0RGoNp9/8jG9/iHDgxEff/TXtPM9vve7H/Kdt98hTVMWywV5q81yseCL50959/33mK+mjCdzkqzL73zvu/zO936XL58/o9fvY1E8O7+k0RHHd4/45NlzjPa8efoar5++xqjX5/zimn6ng20cDy8nHN45xWQZTy6vsY3md995wHfefI2X4zFxmhJrzXix4tJ6Tl8/4cvrCb6sudMf8NrduxwdDHl5cct+twPO8+XVhP7+HnGrxZfnF3gP7925w9HpCYtViVXiRTJZWZ4tGg7vHnKzsIznS1pE3Ns/5PRoxJOzG3qdDjHwZFJS5206/R5fnt2QeccH9+9z5/SEVEmztzTLKOuGh9cTjt96g3lZcjOZ0iLh/be/w7vfeZvHL57T63TwwIvrCUUUs3e8z6dPnuO94q3je9w5ucuw3+fl7ZROu01ZN3zx8oqD0zv4JOL52SXGKt68c4fjw0OK6Zw8kgVMBZsSz29razxUtSdxHu00sfLcrhraWYpy8KSCqTGkETyblvjGcawUSayxhac0hhhN6eFxKe3UZ7XjclUTN5B7RZ7CVeHo5DGJk4qOi1o6qj6b1VTW0wv/xtqL+VZPKREZF2LkVWq4XAEhxaEVTGqPSQ0dK2DhogITw0XtKaynZYNJl4cb62kpRepFm7HyUllzsRTyNPeSvphbKGNZ6XvgYgUo0WPMawEjxgm7c2s9qZLnZrWkPBoNF0Fv0kLYj9rBLPLkjXzWV4UwD0tgupKx4kD+3jaeKBags7JSxmsVXFUCUFrINbkGbvCkTsSk16WAnVLDzUqAQ+YkXbNowCeaVi2pkYsSogiuavE56SPr6cSLmVhbKRIP4zI0MTQiTAU519qKtg/jyUOapXRff5/9xizTf53tYHTk/5N//J8TR4Z2q0W306ad57SyjDxJiLXBOYtvGmzdYJsaW9eyOkfypkaHdIxZ244DSuG0w6ogUl1Xc0BgEyTgb3QcVU1ZldSb8s1QadHU2FDC6Tf0P7+kNVgDjR1xSYiFbqPlWLMAaxHp2hhtd4+MJo9kT2JDHEnJbBztOKaiNoyBD/1MNtU+4acNupRdxqYqKylVLQvKSrp72lCS6ZCW0WiFMhqlDSrSKGNQRuNUAHKEZm8+WK97j/1qSXAAfes5WAt4Xy1HZvNZ7Kh0gmZDhTlai4W3mp11I8FtPx4BpGsn2T/9f/7VN7ab/qbbvdP7/o//yX+JNjk6NTjv2Ds45ebsJfnomPH5E1ytuf9gn+XMcjO7xamcvGWwrmbU63F1MyelYFE12HLBd3/v9/niFx9jSYjShNgVpFmLuirRJmYxG2N1w7A/pN3tcvb0JSZKSSND1czY7+1xdjMhjzyr1Yqq3uzhugAAIABJREFUaXj/3Xd48vgF3lsMFhVnAkzjiNl8jnUOrEUnMW8ejPj84hJjHZ2sRVFX9HptbmdLIu2py4alc7x7vMf17YRl3dDSGhunxDi6eYuz6RQPGGtZKs2Hd0/4xYszMmdJo5Qlnk4eUdWOoiqorKLxnuNhF2MrzmcVfQNECc42tFop14sCozyu8SwU/M5+j2eTKb6ElolYRppcO6yKWFUFVcCl3VbOYWJ4PF/QQeFMArah1+/xcjIj0Y668cyt4/uvv8ajl2cijLUKnSVgHImOmS9XopOxDT5JuH+yz6Pn57QcJElG0VS0ex0m0zmxdsxLS+097x8ecD0bMykbUg9RklBXFa1Ic9NYvJdA5Pn1LNN/ne31wxP/T//Jn5A5SJWiUp4eilVksFXDKvwTHsdyos/qoIGIFJH1pFHEtbXgQpt3Aw80PLMSKLtKMY/ED8TFhqKyhFjOgZGKlUcN9D14LSmFHMVKgWt80LDBiRIn0sJKFcjKrN+jWTZiPmeU+HcMvIyZO6nAabQ8rrTCNV56nyg40VLtMQkBvTDCnIAE0tpLiiCKRCPxzAtjYQIQ6ljAiG9HiQTvUXBkvbTQ9lL50TZCctcELUoYc+jh0gPBirww0mTPh1LjQoanH4nI9NxJtVAd3F9TJyZg1oUqUAXHSspq1/O0NNJXJjKKlfXSGwdxT80tPHMC5JQSINa2UGuFbbxU62g4DfM0b4SpqrSch1cipC2cXNv/8DWW6b8VqRYFmGink+zaP2PNWGyCGqFKQoIObu0mGgSmG2fM9Ws9DofTXkRsoeXabnntulplU7a5ZjMq8Z+o63qjO3HOvpJCcLwKPNYB8pXkVkgzrH8RF87gMRJ6tKwZnd19UxaM2gRaFf5mtNlmeJyX9IPTAmu3pSHb9+kd63ljgq18qHYJ6R/lhWXQeHw4DgEIoVUw71rPrQvmZwqvNc47tBdX2U1J0S7wWH8m6lcAj026Zfd+WHuwbIHiLljbAr6vVrZ8e5u1Frzn3msnnF9dEWcdnj95ifcV9eVjOr0+i2nN7QKUKxl0WvRaCVeFo141vHgxxpfXqKxNN02Z1wW3T57irOXB64ecX16QZD1uxlN8U2Ltim53hK0L6qVnsboliQ2jUZfbmwmRznn24gzvLTqK6LXbFNMFN1fX1K7h6OiI2XRKHqXcjK/xtqHG00lbpFrhGsvlZIZVhoPDQ25vrhlkMVfXY0mrKUU7S4iKktvJkmXtyPoDbFmTapgtS5arMRWePI7IIgXWczYZUwH7R0fcXN1wlGc8n84kf6+gG2mwnnJR4KwjbrewzpIaMaa7mqxwgFaebqTIGs/5rGBaw0G/w2y2YJQazmcNsW/EZjsG4xRVVXPRNLgogzTGFyV5pHl+dYvCUxtNniWoZcmL6yuqumLv+IT5ZEovTbm+vaZ2mgJLL8tEzGwbbq+nWAztvSG3k1sGSczl1S0RsFKKbhzhmobrxYpFbel0+6yWS7RymAgWtRUvC7Y0+Le1uZD99QnUtWfQhrO5J6sFdORKgsyiEUZAx5qZ9fRiuSdu6gYdyjhbWjQR11qCUZpqxqXjqKU5m3nataXREoT6XoKrRwyuCiUGYYmGaeHJArWfGenOOiVUVYR0ykEHLmaQNQ4XCQvQU+LfMVUSyOtIVuOdHG7mkCtPpcWRtWMFcCglzEvRwLANs5WIUlUsY3VjuaapF8DhQrnwXgcup9CR2xelRey5qmX8NBaH1VEmP2sHcSpeHO1IjjH18trayLXudeB2KkZj6xtkYISViJSU1q5c0IQYYUuSVFJRWSR6jYkPPWRiEcce9OBiDC3rcUZYlY4KPVYkY02h5D7spjJP7chTSziguzNPJpHrG7SksZ12SL+WQt7/dZTGbwXwQClMZEIztC3wWJdh+k3w3r2UbUmoVut46zevFaJhR0iq2Xh3uE0ZrKNp6tBHpBKjq8B0NHUwNKubbQM2tzY18+szkGOvV+c7TMsmDAaw9MrlwgYsKb27S6+ZtdHXxvBr49Gx/bsOwAzlcUrh17BqLcneHoR17xptwq7MtiGd0igt+pDAS4Tjhc8hPFZ6y3iAwrvQbdY5tBLQsdaGbMqUNwzIlvFwu5U5a9ARQMi6lHctUdpM2w742IKwbanwpmxYfYsAxHvSLMU2nmJVsJjP8CYnjlqYSDO5PAMds1ooUtPQHp0yq0sWt48F7sVt2nEPW1eMJ2PiyDBbLsmyFlZLGmC5eIkiJo4jovaQ+ew6AGBZiXS6A8pKynoBjImI4gi84XIyIdeG+WpFlMZkccJ1WbJYLvAeYhOT5Rmz1ZKpbegbjW5qOq2cxDmaumbS1ERe4QITd7YqaAFZUxMbTTeKWPz/1L3HkiVJlqb3qarRS51GuHuwzIiMpF28GgVARgTbgcwCeAo8A54DG+wgGLwGZLBoEfSge7qrqis5jQzq3P1yo6qKxdFLPDIru7HojoKlWN4b168bUTO38+t//vOfomBWNjjvpPdInlG2LePGM9SKSdWQJymdtuHaW2blTDp/GkOap5zNFqTArlO0ytOPDbpsmM4arJI8v0tivIKTqmHfCOhL4oiO1hQeptMa7cWhMu1kXCyk++vtyFE4RTeNyazlqqrFklp7bBSjlOZsXtLVYJuGNI7JjWFmG0ajEu8hUo5uljOpKhrn6GtD0zb08ozUWmzTMG4aKTGMInpZwsl0TqZANzVaazqRBhyLYLtpwvXzXvL5bzL/7ZD0bNeIlqCayQzYI9UXV8HPPQ2z3yxSpM7TlMJwJEpm5t6I4+euDhbwkaKrpMlbOXHizqokQC9aqVpJlPRbQUvreRuswA3QVPIYmLXiudF4ceFMQkioRqIrUEqqMiovzcryMCNvlFTRtBb0IpiBtXIMsyY4cSJsSBTSFW4inzslGgynBJB0FSyUpDz6TtInfiLB1AVtfGkFeHktLp4miD6ruYxjo6AN1S9FKz1wGiGKSL2MmRvLXLoNbFGNnJcO46S8MDNNJS3rVQAQBMCTh14xDeImqoDqWq4dCOhovKSZ0jBOFmGI2hbUIoArK/tcjr1XoQLJybGW07XLqRcJpjTb+4n77C9C46GAyEQkUSz24CaSmfaKRViWmC5/YSNYh+C6nFWvq1TaVVfWdbqhpq4qqrqirCpxzVwUFIvFa1Ur8p0mpFmW5lU/8O9Y+nss/92uX5efbQoq5VzXQGDJQCy7uEaRNKxbjoE0xws/N9HNrrubTe+WAGGV8hHVxybrsazy+bN+HpsMSXhdghZhYUzwBgmN9ZavZv1qoggT7N3FdXXtrrpKF722Rq+7r67eR+vtGSPr8n1gxqLNZn0bDq1vYvHA0d07PHnyDV7B49/8jl6e8eEHb/Peew8hvwUmpaobur1t+r2Gs+fPefzwHXZv36VLy7//D/+eNE2JTARxTlFb3nl8n5dPv8AuCn77u9/RyTNuHd7mV7/4SLqjRgmthTROODjc5vjkKYcHB9w5ukuWJfy7//p3dNOUJIzNoiy5f++Qi8k1i6bhl7/8NXm3Qz7s8de/+7VUQmlxqy2c4/D2Ad+entDt5ty/eweVp3z0+B36nR49uaG5tC39foeJtYyqircevMWgk+GyjN/+8mckPtT6ayjblgcHBzy5GpFEirtHd4izjKO37rG7NaRHeMhZi480NjFcFTVHezvsdnLqOOY3Hz4mttIqfeZhbC1HewNezBZ4D4/vH5GnCZ3dIXdu77Iju2ZcSx+j/qDP8WzOzvaQ/e0tmijjl7/4iExruuG7s6blcG+Hs8kY62vee+894jhG93r88qMPGSolnUFxlK3l6OA231+e089zHt67g8oyPnj/PbI0k20qmLQ1g0GHuVJMm5a3DvdJjabRirf2BsQ+WGK/kTt4vcQxXBTSwTUZdrAKtrcSttKIfaQnyAhQRtFGmrn15N2MODPUwLsHKQMrwXtq4AoY5oqLRkBEdztHa0gSxX6m2A9sVxUFm/JEGJJuakgyQ+vFjbTnxdyrMNJ/JY8kEMdAMhA6wykxONv3waY8eF70Y9FIpJFCdzQOGHZhS0njszaS1EbEaj6H6StM6DNzuysBOTLii1Eg/ha1k9m9Gkqs6sTS6XUvpCpcFAKwFmYkycTbwzphaQZegnkVC5jIYgEfOWD6Wjq0a2FK9pWkrnwUOtcK6U+egMkk8G93peploCT9Uyrpo9I4cR6NB1rAhIL9PBjARdDEIirtxYGdihRRTyqOBh0Rtu4qEbnOlTi7BhklvY4cp1Ow1RXQmAfvkD+3vOl7XBaliKOIJOgYlsFNqzWZvuqFsq7xYJP1WEkegi/EEng0bRNYDRGPVnXoghosuauwlmUh76tKwEklzpkiHm1uumRuGIf9udelA6tbeZKsTnWVKtKhy+4KbERhNhttdsD9sfdR6Ki7BgDrzrihIHvJqCwBRCjr/eG6pIvWoGXFkKwYj6X+5GY33hXo+AGAilbnsXofR8SRAJA4jkkisX5PlgAlilavURQF9itaAZBoYzUb4GN9DGs26E0s3kl6AN/w17/9iJOvP6WT5XQyzfHTV1AXYKeYyDC6PseT0u8pbh31mV294r33H/NPf/gv2DjFuhpVzfHtnNm8AhPzs1+9z4tnT1A65t6dA77+5iu80tRNQeLnjGdjisqRaMOjh29zeXnG0eEBL05OqG1L6x1l22KcZzYuMK3j8dtvMZmMsNby6J1HfPLZF+Jn5DzgKOsWqhIDPHrvPZ5dXjEYDCjalkldUyAzs8TDtPZ0iNjZ2YZYM2kdb9054rPvvpcOmx6a1ksapakxHt56+C5Prsb4OMZEMVfjqWwzPHi9hWHtiLOMfHeX87rl/uE+35+cUystM2kvjbkW0wUD57h//y7PZ3Mqrbi1tc3x5Zh5OM7YQ9t4zGJGpAwHh0cczxfs72/x6vyCuXdUhAZc3jOaFfQtHO4fcD2b0CjF0cEtPn/yPePwPeM9ZdPgqgKtNA/ffZfvzq/o9fsUdcWkqqmUBIXcw2JekVcl/eEQm2RU1rO71WU0r1FKYd4w46GQhmw9YG+7y1nV0EZKdHaN9GlRWlxDtfXsL1p0HNHt55zVnq1cM5laWqUwWmbxPQ/xzDGwnu5Wh/PaUgLd1NPWEnCtAt8I29BfCOjJujHnjaMfS0koSq7j1EoDuKgJpa25YR60Bb0kMDVK7qOqkXupWwioyPsJx7UnNZKZ9gjomVmpKolCGaqPFQ2KSQO9LJiTKbnms1a8NfJKmIKsC1eFGCgaJeLUAumTYmvZZq8RUX6cKa4bGMayTa+EyRhX8ncUVcJipAPDdSv7y0LqqELs6utaGIxeI4A2yTVnlZTB2iawKUpSIiaM08CC6UjZb+mktLhpZN+lD03hwrWPFHS6mpPSkwWbVi8vLHwY+xa6DcSxotRKQIuW85VsAz+Za/mLAB4KMEZElBJU1/T5n0VNq4Ap/5Ryzpu+HPZGvxCx6BbBaBVasguzsbTqbpYgw7ahAmZp3770kbjZV0X0J6zTOcE+fdMAzQMov5FaEQHsmsVYBul49RqFQG0CAIm02QAf6xm+0WaVklnpYrQUE6/QBxus0I30S/h8CVb0EnRspis29Ss39SLr/jgbjExYl8camU3AIOcn4CIhTmIBmkkAHkly8zX6EWYkbGeTDVmDj3WvnjexKAWvTo7pdXf45E/P6e0esbU74Pd//zF5JwXdcPfuQ4adIWXZ8u3nX5D3tvj263O6g10uz065PJvQiSOSOOLu249QpsN333yLbxqefPMCnfTZ29/l9//4D0RRTqw0+7v7DAd7eGd5+u2XbPV6fPzxZ+R5l6ZuOH7ylEG/S2QUD+4dESc552cXjGZTRucnlE3DcNjn88++JMWQxzHbwyGD/jaxUrx69pKtTsazL79gr5uRxQlfffMd23lOAtzb3SKJE1jMKcYXUFVUlyfsd1JeXV7i5wXbScpWFrE3zEmU4frkhDwyPP/2W/qRYrvT4cuvv6UfJeQoHg4yfKLJsFyNJnR1y+jlM/YSw2Q2ZzS6ZitLGRrFW73wNzCvMMpx8eo5HVux18357OkzOkjK5UE/oZvFxHjm4ykD43n+/TdsxwpvPa+ev2I7yci14p2dHtpo6smMspwzu77ETGcc9Do8ffmKpGnoxob9boetfp9IKV6+PKYfG7769HMGWhObmK+//oa9PCfx8HBvW/6mi4rFdI6aTxlfX9CLDaNFSVXWqEhR+Tdb1eKR4J4rGF3NOFQNwxS+uyzIY02s4V4us+0IUM6z5VrmV9ccGMfEO64WlkGiUBE8TGR7SokQcTZeMPQ1gxSeTYBIKua2I5ltOwAl+ovxpGRPe8ZKqkk6ORDD3UQcSsPji0VpyeuWbgzHlQTeNJaeKXtJsDBXohcZjStu42liOF1A1hEG4zAWh1CnZNs4D4VjGMFlI6xJnMi6lwRgoyQVMS5g24GK4LhAUIGRHi9xFKoYdegfU3i2IzgHRg2kmehH7oR29lYBEUzmlqEVe/PTUo5RR+Kw2gnfbZVch0XhuKVhouGigjSV79+Jg0AXYUmaypFUjk4sFT+thiQR5mY7lnECAVOjmeWWcpQRvFqIG6yN4E5EcN4WAOpbjy4sqRERa2Fl/P65qpa/DI0HBKp+GVjXgVTBKnD7EEuXJakqBH0V/Cd8EIzeYB+wtDisFyDRhn4wkjJZumdaKclkeTPLDlyw5vZ+2eZ9aS0eBKYbwtaVHFIOWLajgkvoBkOwXONoDSyWs/x1MFfEWjozRkZviG6X+hcRhTq11EMQjj04mCiP1grnlmkotZLILD1IV/oOL3oQtdRhBM1F4JnCL61FsRoVXAsl2af1Wjy6Ev6G67YCvDe2zQ1BqV8f2ErjIT/YQJz+Jv5cjTHL8dcb5/5TmcV/vUVrGQsVeeriivmF43Q2RyvFq+cnDHduMZ2NUWgOb+9zdXVBU1fUi4KiLhmhidMOi8mYfnfA2ckLdrZ2qKs5rrVUdcHs6pKymOOc4+zkFYM8pa1qnG24u7fP5WSM9Y6ynKM9zOZztHacnZ8xyPpcXI3oZAnKaIq6Yd5YmtGIcjbDo7i8vsRoDWjGdc3B3h6TyQSvDaO6ofElbT0jMYrzywuG/T5X85JEe9Jhn3I2Y24tVeHRdUWNxyDOlFGWMS8atroxRSMXedS22LKBuWggzkdXdJOYy1a6KHeynMWiYmZh3FpyZymritR6puWMNI05r1r6icYoQ2UtM2sp25Z4XpBbuJ5O6SlD2YKzlmEvoy4bSgVlY+limRSndBVcTsb044TzaUUWQ5bnlEXJuPWUNJimkJx4VRIlwjVPq5K9foeqbPFGMWksttVwdYqJFK8uzhnkOWfzAh1pkqzLYjIXUyZbk9YW4wRt6FBy2byROzjcxwqiHOpWPDFowFee2zHM64ZEaworYvS4E+G85boWADK0wi5kqWdRetJEBJMdrfC5pi0t0+AQkNRSxdIGZ1MiEUXmqQLjmRcy826dCBrzDkxLSUVVKoCzjsKWnsJJsEtLCfZai1A1CSLRPAKfik+HdcIcpBVs92BSBsMtkd2gO0KVFE58OtJKKlN0CuVCxJtlSI+oTiAygSKCtBChZRXKZDHgGoiCwKIMolAdSlazjljHx4mkjlIFdDe2qcGUYqceSEiSFKpCgJWPYB6OX3mpQOn0YLYQQFIbGduoL03qlh1to4Vs00RQLyDN5ZgzDT50p7UIUOq2kHZhVglwq5CUke4qXONlfBNQpTSJM4k4x2YhFfNn77N/lbv3/+ui1EYqwdyYwW+SHq+fx1KSuAQdzge/Di/C0Zs+HSIeXVawtG0TbM8DqxF8MjYFnysx51LQGZS94ZA30iZq9TMV3ss2lv9WgeXQRJFZpx6SMONPosAGRCtWYKWLiOIbs3oVBKfr1Mhrokq1DszrMZJ3r/dhWWayNutDVt9dlsHe/BU5XxRGaaJlmmilv4hu6C7W2gxhP2JjZI1+eL5r5iN05E2E/UjimCTZ+HlIwcRRRByttS+SenpzjIdzUBQLrPN88LNfkKUJTT3h4O4d+sOYspwwmVxT15az0+eUVUV/uMfj994XOzvX8uj+A3xbM1tUNGVJXS0Yja9oXMv7jz9ge9BjMZ8w7G+xOxxSVg2z2ZyqsZyORszKktzE/OydR8RGUbcFD+48ADSzsqQoSmoPp9fXLMqCh/ff4nB/j7KuydKM27cOaKynmM5pnOd0NuOqLHHe87N3HhPFKdO24f7RbXwcMStKyrKmjVNejafMGsu94YC7t2+Lah/D7s4OpVcsFjUz6xk5zagssbbhowd3yJOUUeXY6/XJsozKeYqigSThRVEztpbdOOHtw30sCuXgzu4taqNpWse48dSx5lVRUzaWD3Z26JmISQM7UUIn7TC1llFRU2nNSWW5bixdBR8e7JN4qK3i1nAHqzVNa5k2LS5KeTGdM7GOd3b3uDXsUzaOfhQx7A9ZlI7ZfEHjPKO65bKqaLzjZ48ekESaaeN4MNgmMhFVYynKCqsjXs0KCmA3zTiIe9I7RimiJKf1QtG/Sct0j8zgi8bzsNvBtYrCQuYjWqspG8d16WkiOC1arueenlPcSlNsoPF1E4vIt4LLGtrYcz6zzFu4myf4Whw+sQrbaEoLo4VUc1w3nqs54GArjnGNVPnUhYgs57WkJVwCZ1Mv1zmOiBrxDqGFNgTZ8VxAwtzDaCopiltZgq/ks7aUVvVlI14XNoKzuee6hK7TJFbTuFDKOpdZ/KQQMFNoqTgpGuhFGrUQkaYrgwFZKxUxLoLrGq5KqayKvJZSWgfNQjQiRSljZQ1cTsQDpBsbdCUpDB3MzQoL1zMBpqNG3isLfWNQjehd2rkIUcsG5pX0szkdy5gNI0NcaWp53FCG/Y/mcs/NgNFM0mN7eQy1pKBcIWNQ1HIuLoHzuWdWQaY02ooWpLWSvonD+59y6viLYTwA1NKWcwkm1DrwrWbMy/fLT70n+JOuzbs2KmCWzp4rl82NGbbsVJgJrzTLDIVSCqeW6RUt6RWl8F7jnNiHe+83AJJ+DSCp1XaX4s/IRJgopJNW2od4rYvY0E8YrYmU5DkFtJi1ABRWpT6rap+VfkREpE55tPY3qj+EMtr43jJd4j1OuR92Egx+JSuecKM8Ryu9StusmrKFN8ov//f69n7kRvSr/4VdLs9FrV7VJuzxS4ZkEyYtQZdaj/0bWLTWZHnGRz9/h8/+9DnFfMG/++9+x9//7T9inWdr7z7T2uFcRZJu8/jtbS4urvj005f0eh0O797m6y/+hFIRW7t7XJy8ANWQxhG/+W9+xj/93cdUVclvf/NrPvvyK+qqppdnRAbquiFNUvaO9kmiiM+/+xZrPb/8q1/y8aefAJ6d4YCz6yuwLVma8Jv/9lf88e8+pm0bPvqrDzk5PePlyTFxHJNmEYt5SR6nZLvb3H1wxOdfPaUoK/7617/gD3/6FJxlK8sZLRb4UAHy859/xOeff0V9PWF/bweU4unVBK0VOyrmuq1InMVlKR/8/H0+/uQryqrml++/w+fffU9kHVGkGHgo65bURLz94C5n1yNOTy/J85yHwwHfnV2h8HS0NCxrG4+JIn794SP+8csnVG3LR/cOeHJ6Jb1ujKLvoWgdeRyxfXsXFRm+PB/hlOaDB7f56uUFIIJHW0PUtKRJzH/165/zD3/4hMZa3n3wFmfjESezOSbSdL1n7sTbI9sZcnT3kK++FVD51z//Ob//5FMi7+jmEX4BqrWkScwv3rnPx98952I6Y7vfxQLTeUGCsPTtG7mDZVEARnF/EPF0XtMqz/1OymXZ0HoxJTzyEgSt1hz0I84rx3XVksaa/SjmpGpQiBBUOwlyjVY82FZ8M5Gz20sMi9ZRe6mG2QLiBhKjIJXPXjaWJIJbSnNqQ5WUkdJT3UigPuzC84UwZINYY51nHmLHthI9QmGgiMU2/LhqQcOBibiwbehJI8EyaeUxuZXCeeNxraQ2Mg8jL8Gya8Tcq0aape0mcNJIX6FdFBPviZGUTU+JHbnWotOYWU8VGIKtVnHmPRnCJGTBiAsNBx14WjgiPNuxZmE9daB9e0o8SDINVhpIc9Y4kohVU7cukgJKAmixBo468GzhMB76kcI7mOMxCFORtMJSFJE0rzupLMbAfhRx2bRiPKmh50Tf4TXsduCi8Djr6UYa42Eeqtka+Mkn8V8G8FgJQq00M9Map6xYm+sQ5DZSHKsAFJw1VxbcYdnUU2gXqji8XnlVKLS4cMJNAOL0yjfEuXWzN5z0Jlm3gxcgYzaBR4BCEo/XAXqlP4jMDb3DJvBYsgNLgWgUrMANS/CxTCWsq3eW57y0LCfs1yu/Pt9QaupW1IZaHmD4mRHnU6+lGNcplmZnQTSzsa/1ua1KfFeMC2sq6Adlz8trvAk8XgMby482379+24af+40LtvrGG7JJf33J0pyqbOgNt3j4+DF//5+/oiobdJSRxYZ3f/0+l4VmMr7ielrx9qP7nL4ao2zLx598ja8rhlt7ZHnMb37zW85OTunGU0YnE/YPdtnr7/DFl18zn0m5bDbss3fnLpQVk6qkvpqz/+FDmtmCTnfAZ598TF1XpFmHKM/49b2fcXk5prQ1J99fcP/hHTKX8PT5S67HIzye/V6fW7f2SE3C1eUFTVmRmoxunnH34Ig//ulj6rrFRBFJnvDro0POZyOqxnP67TPevnePYjxiMp9xPp7igH43odvrcyvf49V4Qto65qdThlnGO7e2+fbb75k3DSjFbpSys7dNWbUU1jF5dcrhwQG5dkTK8NXLVyLqjBW6k7DfG3A6G3PLKC5fXLLd67KdwMn5JfO6wQGdTLOVd+kkhkVj8eMF20eHFPGCfr/LF8+OKZwnjgymk/HOvdtcjC9Ireb0mxfcPzzAYDk/P+NqUeC9Z9jPOdzeQUeai0WBmhfkLqGXpdzf3+OPH39MYy2tMQyTjHePjhitHQNAAAAgAElEQVRNC5qm4fjpOXf2b1NPR9RNy9l0ToI4V8YEncMbXHrKs5haEhx3U7isKgpEA7AVQRQZPI6eiqhnLZlSdI0lU/CyqmiVVLTYWIDUyCsGCmYTR+JgP5HU2cLLuQ7ChK9UiAFkY0VgrB3bwKl1qFDBEQUvjhlyLIs5aO/Y0tA6z9xJUMw8eCNiSBfKc6sCjHJsKbhwLT7oJHqRuI9Oga6W9I92XtrOO/EMwQSzsFh+XgJ9LVbjsff0HYzwoCUV1NGi1ygsdKJgBu0gUZ6sgVPv0cEITBthKwovfVDmC4iRnjXz1on2QongNw7npAMAqyykxjOw0vHWKEmT5JEwH3MvnX3nhZxTX0m6qfCi0YiUiF4rD61R9K2nqSFWjn0NJ02L1ZLq6UciVp2FMatKUN6TAzhP7WT+WSDb/anlLwN4gAR0a3Fa4ZzGhcn20pPKbQbC0ERsxW5seFD4zcBKcDb1MrNf6zMIvhUgAgKFVg6ng8HY0sL8te6yfkM8KoyHWdP7/ibwWL6aG4xHdENAGkexiDOjjWoRpUJDPEGjmx4VayFtELZuHAtIKBbGg5D6WZfuLi3bUUs9wpLx0GKN7jVq+chbMSqSPN00TVvuQykljqbLfZjAijjC9XkNfGyQTJuupZvAQ218yb8OJpbA40f4ux989w0sHo+1nmffvqA72OLiekHaidnbf8jZ2RUvXj5lNr1AKU1RKHqDLicv5nSznPOzF9w/OOL88pzFYkbxbMro4gSPwfuI+vScfr/HaFZA63h0/z6vXp1wcXlFsSjRkaapLZ0k59X3L+l2tpicX7I/3GZcl5TzOefHx4xnU4xTNFaRpQ1928NkEbapeHj3AS+OXzEaXVPXC5SO0I0njiOOn75kkPcpJlfs5DlmmHJxecXJ+RWTRUWmFPOqpBfFxGeaJNa08wVv7+9xeXXNfNHwqr6W9KFraRrLpT0liWPmkzmpgvf3dzk7v+RqXlK2joHWFG1DrgzziwuSPGU+HvPW/h6j6ZRJUXE6LZnWjj4wszWutWRpRuU0vml5//A2p8enXJaOol0wSAxt20qrhbNT8jRnNp1zq9+ntZbxYs75aM6kPmYIzOqa1sQMlUWlMVQlH9y5y4tXL5nMSp7UF5jY4BtLFGtOnz+lk2RMr0f0Ox32o4TL8RWnV2OmVUNXGaq6IjYKc+nQUcRiPuX+do/ReM7MeVrefFVLY6HGh+vqiZXmqN9hNppxWcPUOo6UZ2prWhSZkqZri8qy38upipoSy1UlDMW2k34fPQU9JY6ZysLBMKEY1UytBP1bEVS1xXoRoiovHXsHsSYCytZxXUlp9nYEo1oATqak+gMHWz1DM7VMEH+O7aCdKbzoZ7JgztUxmjTVVLOW61pOfE8HTw9kFaM6EVZGpfhxnJcCThIF80b2nQYAY5SwGb4Kbeud7H9ei15iyWY1wDA3qFDefd3I9joaxnXQyQSBpgaGObiFlI7XTlrYN6HrhAnalBrIYkXspSrtuhYPlMHGNns6NM/zMOxF2GnLBDEWGxpQtWeGCItTJSmuzCiyWFFZx6iRMbljWF2HdHnfeBmntpJzLH4izQJ/McDDB3vvZtmPTPqPeI8ywRllWVGy1B/ARnBbzvgDOa91EH8SWqUrvJeZurUapRxOaRGZotBaUip6CTC0oOgV4+FZg5AASPCsS0qV3gBB6+PQG8BDGI9QobFRGirVKesqkaUpmQ5MgoY1u8A6UK9AVBiHFUngWVeraIPWbtVWflluqwIT45zDeoN2DqWF8ZBNqNWwLjMnN5IZSt0AXUv2BEVwUv1hXmVZ6szG8a6+t9qP37ikPwIm/gXA4021ANBKMS+m6KLDeDGjm+fk3SEvn79gOOihOlvM5zO2tockTc311Suu44xenFI3Ja02VG3NoNPDeLiejnj48BFPn3xLrQ3j8RXD3pC4k/Ps5THGQD/ts6gX9KIuW3nMq9E10QziVGzKcxST2YRhbwuUYjS+5uGde7w4fUVba8ajS/rbu2Aizs5O8QoGWQ/rWuq24vZwhxfnZ6SlYayUVFtpz+j8kjyNGeqYq8WC7u4OUVNxXpVcFwXDfp9Wa8bjCTOgn6ZEzjIrS4ZbXV5cz1gs5hit6PVTrIbvzi9RSnGQGhZVg+1kdGLN8aImb2q6Xij689E1197SjWBHKS6Kir2dIWfTimlTk9uGTp5gYnhxespcwbbSOO+pvGcriXgyr5m1c+KmIlVQFi2jpqEbK7a9YjRfEO/v0NYlp1XBdVuy1e2CMRyfnDDXmq3IgHfMK8dev8/L0YhE1Wg1p5ek6ERzPLoiSyN2lGZRlHS3b1G0FVdlxdhXdPIE6z1X1zOWxRCRCa3K39CigKmCWWhHn3WhmTtOxjMaJHjFztME6+/vWk8fT08DBuppwcRIQNwOTdSW6dgTBz083a7GTh2TSU0RSUpgEIjSAfDESzfUbhqMHwvHNAnpCy3PI20lWJ85KW3tDMFOwM8s8xhUI+ZlDgE8116Ygh4Q9cBNHRMlbEIeUi0KKTM9bsQYK+2LviEuYZ5Kqeh2cCqNPRSJBOBUQzwAPxGNi42CX0moZOkbOA5pj05H9BKUliY4lw6D/XzsZAzPW+hYyLbExKysoI5Fz7EVrlNfwfNgvd7LoDXgFp55IkxLboKQ1YmPx1kr4tNsCO0U3LxlEQt4GS4ZFQXPvZjYdSJIO+Dmnon2lErOByuMSUfDqZV7thsEsaoWlqupRZj7U8tfBPDwHpq2IWqEmVjaeIt3r8eoAOu8WwOQjTboCtYiS/wqEHkC8kBL++UN4y/XKpyWgGydW4EPv0o1aJz2aL9mQTb7jagAPJbuoiubdtY+Iyr0jlkabIloNDAdQdshTqIabcyKUVhmLjRsgJCbwXWTfZHAHQKuVgIUfGA8jEY5g3YGbS3GaJwzqzSN8dJnRXtxILXKhYROOJol6PBrMLXUiBgVKm2MEpCjlPylhYsaINIqzbLJOK18Wfz652rj3z+aauHHgcUKeGywKv/Wi8eTRjG/+uhnfPH9dxRVzfz6GrKEqbXoxRRrIxwZ/WGXvaM7ZEbx/bNvAc98PMFYS+Fm2MgTEWMbiNMOv/7g53z7/VfU8ynTskGpBG9rpnaBcTImLu2wuxdz/9Yh3z/9HG8jZrMxidfU5YwyiD3LukTrmA8+/CtOj58yvp5QtTWxijDOMi0X4D1ZrCHy9Lo93n3wFl8++Zqobhg3lhhF21jOseQIBe2V5923H1KPR1yNxmgstpWHctE0OLz0c7ACiD+6f5dnL16h5jVF64TWNprz2pJ6T+oddeO5u7tNt7JcF3MapIFkrqBRijESHKvK4Rtkm6/OicqGuvGkCGgfe8/Qi25j2sCw2+Egj7m6muAMuFpy7copRlao49a3WAs/e/yY0+NjqkVB0Vpir0i1YtI4lPd0ogiPp5OmvH94xJOXT2mqkmYhY+Os58o3dL2nsjL2j452mV/PGFdz4shjG2nF3iCPuDd1D4MYUyUebneE8jeVpIC6SMpi5MUBVHmYA7cyTdR6dC1phgLRARQKFlZSHHVoo36/o1gsPFHhmQddQ+ak70dOSAEoCXpDxJPCRELtd1o5joUTcFJ5Sf3cSaGoIFmI5kJZ8XUZI8LSzMs2UcKo1C1EhZia9Vp5ysydBPTGCSOwE1IjaSHN5gBMLdurrIAOB6hWqkOaFvICRkqqQJyXVFAEMhF00l9FaQEx1oiY09QhxRK8TprwHDyIhU1JChgr6a2CgysvgCb1wdbciN26r0HFcj26jdioLwKIW3gZ18MUyhLiBcw1pMELZexle2LvH9ik4DGStGI3n7dyXAsr1vaNlmPdScE3oEsxFLNt0JQoAvP955e/iKoW74XxuNEzZWXctS57XaYVNoP8cllVmWiFMQoTSQVJFKomkh9zzFy5aQa/jGjDLyNoMpaVJUvXTamySFZrvHwfJyTJej9rl85kY59rfcfKi0Kv3UeXqZZVemXpZbLSZ6jV+btl6oEN3YPa1GFsGn9t+m8EpsKYGxU7azZkzW2sL9Bq8wKK1LpJmzHi5RHdGLOlWdiGadiS5VlWwRhDpGUVL5BNk7KlKdrGuhLfmj+/BvboTSzeee4+eMCnX3zKdDIhjiNsWXF465CdfpfWQZxqrkcjGlcyGBq+/uobYiU2gtZbHtx/G6fAli1xYnjx8gnvPX7A58++52wyxSddUJqsE7Ozuyvdi5WiaisWs2vu37vLZ0++oHaGykul1sHdOzgT09gWE8P59SUP377PxeU5J5cXxFmCVRqVGG7fuYPzYPG0KM4uxjx+5zFffPelVIhlKRolrE2aSkWY8VyML9nqD6iamovrK7I0pg0Px+29XbF4tg6vPWfTCW/duc33x6csbIvRCqch6vXQvS7KebGGXlT4WGGymItqhjcKbxQF0N/dQWvF1EmDr+tiyr17B5yOrlG+wmlFYaBJYnSvgwbmYSLTKhj2u5xcT3FKo5wYkfW3B3gTUXnZ5vnllKODfS6ur5jMZ0RpLqLzyLC1u0PkofGexjZczKY8eus+n798TtV64iyh0YrO9hYmTbGto9RwNhnT6UY0zjOvp+RRTG0VFqk+MErKT9/kQ9kBJoWrWijz2gr5WAfhYRSuawF4oyDR1NZjrQTFSkEZWsI3wdtiZKHTle6xHrBW0siNkkdLJ+zXxbDQoqMorZTSGiRIl2xMxAxMNUSpBG2Q4B8jwbP1ki7wCnwswKaTiZnYUoKmlaQnVEgrGCPuod6ESZAPJblKtum9pHVQ4qw6C78T+uGtpAEVrKzMYwVtLG6fPgxuHViCAtlmjgASFcs5mVRSLBHSgj4O27Qe+kj6xMdyTEkk1SOtg8TJGFYBROhwfIUGIqm+ccj3441zGhCOLZJ7L03Fwn6ZkrFK7OGVkvPyWpxLvZFzhrVNfBFATqREW/IjnPVq+YsAHniPDQ6jtm2xK9Cx8dnSETS0Q2fZJv4G+JCAy2uOmzeFnRtgYuWEefP1hkvmxu+I8VWyUe4ZSj03y0DjZBVsb+wzjm4G4KUt+tIES98EAGtH0JseHlob+fkSaW2ahfnliCxrQQJroTVq2Z9luQ297MEStquWpm1rE7E1CFlW04R3PnhoeMnD/uC/ZYmxWjMkS1uzP3MDsCxoUpuM0Wvr8jgEXK3ZoBvrmyqn9Y6r83Mmiwm7+9s8fP899nf3eev+Lncf3Ic4pWkb8I5FUXD8/CXel/z8lx+xt73Nvdu3+PA37zLob0m3y7rA2ZaTswsm1xf0uzm/+vnP2dra5cH9uzx++JjIGGosbdVQVhUvjl9RljWP3nmXw4O77O8f8MEv32N7b4dIK5pWnHfPL644v7ggy3J+9avfstXpc3jrFu++95A0UuAdrmlwbc2r02OmRcXh4SH3Dw/Z3d3jg7/6kL3hkAx5kLYOZtM5FxeXWBPz+L33yNOc/e0tPnr0iEwb6WMRSMzR9YRpVdEfDDm484Bhp8fb9++y3x+uxJUK8I3jajSndIp7jx7SzbvsDIf84mfv0otSUoIjqoPxaMb1vETnXR69+zZ52uXu4R6Pb++sgleFBIrxZE5hPYf377K7u01/0OOD+2+RaUOMBCSH53oy52IyI8o6fPjhe3Q6Xe4cHfLeo4fy90qoRLCO47Mzyqrm9t27HN65y/72Dh+++5i9Xj/M5oXFnU4LzicTGhVz9+0j0igizSIebu9ifGhs9iZu4LAoQNcSdLt5TGd3gPHwaDvjbhzRQ4JK6QVA1AuLU4rd21vUJmaoFb86SOgFy/Qxcj6qkm2mSUT/Vg/lYKcD9/qSKimNBFwPUElQ3Bqm1EnMAHh8W9IkmRejrNYL41BbSCPN9kGOtSLOvL8jLrEN0sxOa9l/AXQ7BroxmYd72yIQ7XgJ+m0Y+DpoJ7b3NW24JneGwgxoJfoNjQgtGweDFPRAgv9+LlUhiYdZEHgu2QClYHtHUSnFELi3I2MUOwn6zku1Th2s3Tu7BmVhN4fbfWFaSr0Gg66W39kZRlSJoYOce6bk/CcqeG4g2pDUKIZ7KW0r43RvK5S+akkRKS3X3jnY6sY03UTM73alOd0AuNYCLrwLOhMU29uGxkuq5tZQfjaI///CeARTrxXL0QTA0bbYAD5ca3F2wz0UAhng14wHm2soR1XrWflyxh1Hm/be8Y3Xn1rjaMlqJD8AGj+w+77xuuG4ubJJX8741x1plyJSpUMp7obpmNHR6lXraKXXYKn/2AjRS43EEjwsdRlKm/CXaNYMRwAk6882wIza3J7aSHkstTOsVvw6LbOhJF0zM54wtfEbr34lGl6WCK91PDf/w2+AEr8+15vX/qdw9r/i4iFWishodnZv8fUffs/+7X1ePT/m8vwamhJcQxQl1Isy3DsZL48vGc0mHN2/y9/8X3+LSSO8c+Raob1HO0iUYncw4Pd/+EcGwz5FWfLNd19jEaV6ZCIaq0lMTKw0bVVyfPKKo7t3+M//938BB845KdlWBuctiYnYGw757NNP6XRz4iThD3/8BB9FOC+i0tZ6EhMRAVkU88WTZ+zs7vCnzz6nRJiJhGB85BRbQJ4kPHv+DG8UveGAv/3TJ9RRTBpSh6lSDLWiA2ynGV++eEJv2OPJ6RlX8wUlilTJd2Oj2dWKyBgWo2tmTcXW3g5/83d/ooniVUOzSCmGWjMAhp0uf3zylLgbMSlrvjm+pFWKfijtNFp6WaRK4euGp5dXbA36/OHrbyDNUKzFhanWdJWil3f59OuvybKMOE35/Rdf0RhD6kP1gnV0kbRSL4n49rtv2d3d5eOvv6E20r8kRpEYAd99oBNHnJ9cYLF0s4gnl1e0WknFzr/1vbuxKKRcs6uAWHM2mZD0FM+nLXOnqYyIHZUTVuHIyzNmVpcUriHtwj8dN/jEEMfCGBgvzdS2PKjE8Gq8wHQEFFyUwqakIpkJDQLlQObOMm0adA7fnoFKwuqDuZWDPQ82UZyMK1wi4PJkIjqLLJf7KAIGbtkwzjMqGnQKr8aijahNeGY5SRvueLBGcTn3VAbKGI6n4CNZbbAQ7zoJto0S/wuXyPk0XrQOSgkojyxsI54ek9pT4nEpvLpGaJqU1fOy50XoWcdwPhFHtnED18G91ITGbzGw5QANE+uYtRadwYtrcTglXgf3rodtD22kOZ02qEz6uBzPpGNvnMpjOgaGgW2ptGJU1mQdeH4px24Tud+1E3Cz42X/1wu5aU3wIVFKBKs/9ST+i9B4AAIstNRVOBXoXqWkBDakIggz3M14+INFrf7HstRTa7ELXwam5YxqOTsXbw69skR3Tu6CTT3BDWuKsHlhCcTDw98InoFvUOqGxmPFoGwYb20uy2CrUaEUN8KodcM2vMe7UPoa0i5yrAEQrHQVy20twcNGKmXFfgSIuwIvG83jvIy1X43lerD9al8s0ceNdQkGl8KNlbbD+VWFkBxzqMrZFIyujl+FDd68yCrsUsbWc1OAugm0/u0XpWAyX9Dp7vDqxSl3773Nsyff4HyEiaakvW3ePrrH9XTBdNxyeT5nd/8QVzWoWPPHP/6RjomoqxGDfp+j/V2eHZ8zGo2I44jZaMr+3UOOn72gbWq6cUTXaLb3digai54XjC5O2d/Z4eLikk4345MvPif2MJlf0Ely3rr/gOOTc6qikrK/qmaQdXl1fsLZ5SX9PMU4xdHBAZmOuLwac316zM72LU4urtjd3eLp8yfQtjitydOY+/t7XFxc4RCdVpJFJNYxrSq+efGCnvPixp8m7KUxF7OSqq7ppJqr0TlH/T6nFxc0TcvARPSNYm/YpygWaA++LOhlhvliTuo83zx7ztBatNJ0s4Q73ZST6YJiPifVivH4mtv9LleTGRetZTtSdPAMexnetlQNlIuCQaIYXV+xlyY8OT1noBxVXZPEMfd3tzmZjGmbGu89TVOwPehzenbByeiaLa3ooMl3+mQo/LxgUczoDzJenRwz3Nnh62dPSZTCzxfkxnB05xaTi2u0dTRFic5inPdEFk7HFX3lV3j8TT6UvZL0SOahmlbcSeB84Wl9SxYrUq/YcZ4iglZpGu/o47GTkj0PL2eeLQ2ZdYyBBwm8cAqrIdaexbziMBZjsYWH3VTmHrEXkeXYKerYkzuwi5YD4GUjAs1MwaxVHBrPpRFvEBN5VGnZ0qL/mCDlurYJhmEJnDfSBC2y0BaOW0qEkZkWd9OihVsGZkZ0LC6CxHrRK7Sisxgm0sulsnA7gZNavEEiwLfSFO60FU+OKBHdQ65Ah+ZrVSKaCVOLBuUE0YfEwNyKruPEQRVEoTSeXQXjVsDUTirderUTK/hrq2gST+aA0nHbwwsvviOxCecUiSanUaATUK1ly0h6auql8VxcQ9Mq9mPPcStpssxBOa85jMSCPtHi4TGpwzjFoFHY2BO1ngTPwooN/DCUPet/5jH8zzIeSqn/TSl1ppT6ZOOzHaXU/6mU+jq8bofPlVLqf1FKfaOU+pNS6tf/srvdr4LYpkeFD2kV8dSwK1HpprD0xmZY/64jGIr514zD5DhXrqSv25hHKwtzcdxc27ibtfuo3nTkNCtNyPLnontYrsJomNf2tdRe3HRp3eiLsjQS2+h7cqNfy2uVMOuh3Cj/Da8yVstkxQY7oNYMwXoL6s9A1Q1ws1yX5bxhddbiglZH1s33G5+1G6+ba7CxX1nZr17tShi8fh/2Z5f3h1vdK2/iPlZK0baNFP5TUjUL2rYl7XWp2xZDxNfffsb15SuSJKJxFfiKoqloy4Yoyoh7HYq2wjWOT799AkpjPbRaU+BoZhW2tfTzDq1zkES8vBIxp0kTitbi4ohFU9NWNUpp+oMBpW2JleHTr7+iaiscnqa1VM6zcJa2teRZQuM9rW0YXVzz7OQYE2vmztM6uT7GgbKWbpIwa1tibfji5QnTpqYxirF11M4z9y2RdwxDsJlbR9tYvhlL87bLpqX0msIrplWFsi17iWbmW7zWvBjPuKwtpTGcOykPnDctdSvC0yxTXDuLso4vL6fU2jPWiomSMtCy8Vhv6SpF4RwWxeW85qxoaSLDBEXloLQOZx2JtyQG5rYl1vD52RmFbZjjKbzHOyhbS+0svTjCKk/lHONpwbPRFJ0YxrXHm4wChW1bcC2dLGbcNmA03704ZdTWLIxh5h2la6m89Gbp4Sm9pA+8kj4cb+IeDn/lTDVMUJRIUEwd3FYwC1b3J05x6aA0ikutuCYIOIEDLyzUtfUkCr5tZYY+MYprJ1qNmZfgdgCUdbAHV3BiodWKsZbutw2S9tpBZtqXwR78lRfR58zAxImocqFkm/uIPmQRNA+vWhnTqZF0xrJN/BaSPhgvZJsXyO80RkSsRdi39nALAUfTRuZqJ62AgzqShnGNk98ZeqnkmZTyqCw0TKzoIRbhvGtEO7MbHsmTSp4dp8E1bhHBtJXUyBxhn/aUaDSsk7Lds1aOYxbEvu3ynLxUGo0rYc2OvaRQZkYxtaL/KFUQD2tJE85D2ualyMUYa6kAcohItRvO6Xoh7Oapl3MaaQEvBbLNGGESrZKxMoqftFf6l6Ra/nfg37/22f8M/Cfv/WPgP4V/A/z3wOOw/k/A//ov2H4Q3oT5ufdSuRLAhmg61g3b3CrN4jY4flZU/LpaIrAXPmxrGYTxaxHqSv+xYWO+6qQa1qXoNDKr727agZtIr8WSK1BgboCM5WeR1kRLQGI2hJ9LILQpKg2lussy3CUQWmlDgu7j9VLbJQuyali3WT2iWOktVqYefw5n3Lg6m0ZiS9Dh1t13Awiw1tIsRcJ1TR3WZuO1qWvaulm9/hhAsU0bPrPrFFu7bvonq6Tk2gBOrFtrgN7MfaxpnSPPEh49/pDjkxGDrQ5pBHkqjd8UirTTYTYd0euk1Bh2b93CtjVxohj0t4jQeK+ITEonyiiqgv4w561797kcX5H3O1hjSHsDTOtR1pPEOVXVkGQplTO8/c5jxmVBnqcknZ7cm3EsOd5+zqKcM9wZsr+1R93U5HkHrTS7/SFp0gGt6cQJrVPERpMnEe++8x6nlxekvS3i3pDMxGAhV4r9wYB5WbG3vUU36xClHWodY01C3r+NNoYIRT9S9NIY7Tw7vS6Pjg4YlQ0m70DSpxPlGGvpOs9eL2fWWLa7HbpRxs72Hg2aNMvI0j0xiPKKREMnyqnrlr3tLe4fHHFd10RZjyzp0M8GZJEitTBIEhoHnSyhm3W4d+eQ67olynOy4SGZ1mA9XaXZGWwxL2u2d7fY396hbCydrIOJEoY7hySRQTno5QkeQ2Q0iYl49+2HXI6n5P0hOu3Ri2JSr8nxDDs9ZlXN7e1ttjoDsjRHa00TJ/SHwzWj9+eT4//K97A8C6JWbMCPtgdcWEVlDLVOiFWEc55u46VRWmMZoOgZQ9bJufSKmdZok6MRo61eC53M05aOroGdfsbYaSZKMxNuVxqKVQIEKufIW8iUIu8mXDmYoVi0MkVqWjHgGuRQ156OgV6WUCnDSCvmgaptPNAKGHBaZva5hk4/ZWJh6qXzrHbCAMSVdLZdVNJNNjIapzQzFGOvaGoZn6aStJEy0C4EZCWZpmmlkmXaCLNSW9ChVHbWSAVJohXeaBZOBJp1I5e6rjydFrIEmkLSTr08pnKKqVIsCHoWH8ZJQe08SSPVRkknZuqgVIqiEbDUttCtpdS2Cl1me2lM7QwzFHOv8FZhPdjKs6UEICWhEq3bS7huodSahVMYBNDFLWwl0NSeroIsiXAmpkRRIf3FFJJi+jED6/XT8p9ZvPd/g1QfbS7/A/Afw/v/CPyPG5//H16W/wfYUkod/ktu9rVAcKM53GrZEJJ6z7rm7DXGQwkgucmMhN/1632x4Wth9JqJiF57XbMcG1UXISXxA1Fj2N4y/fJjosdNvcbazlyvPDuWokylVGjzblYgY9WNddkwzpiVgBO1djR1Nyp/ll1z14zSahBuZlB+fEo7BL0AACAASURBVLkh4FgO/+uMRwAhSwaitUGjY7HNUqNjb4CDG6vd6AK8dIt9jcFw/nUzt7XHyiYAWv7uj5/Kv+59rI2h2+vS7ef8/g//QBwrbh/e4/TkGbPJiN3DO+TdPnGU8eDRY7rdhHJyxecff8LewSHdfoevvv6CpNPh9q19Mf/p9TnY3qM/6P+/zL3ZlmTHmaX3mZ3Zp3CPOedMJIYECBIgOKi61KXqXi09hG7UF1pLF9KL6BlaD6Br6ULSRavXqtWtLnWv6iqyCgQJJDKRicyYI3wezmRmuvjtuHuCJNhFsQr0XJ4R4eF+/Bw7J9y27X/v/fO3v/iUsqq4fXSL2XzG9c0VvYNbdDtdwiTmzq17ZK0MTc7P/uav2d85oN/r8ez55wRhxN7RMUZpAh1xuH+L7k6bZy+fMxyPuXV0i6queXHyilY3Y2+nB85yfDCg1coIWjF//bO/YtDuctjv8+r8lNwZDo72CIIAU9bc3d+n3elwPp0zvLhif9AnCENeDc+JAtjLNK6GttJkWUbUavHZyxPaUcStfovz2ZRxkTPYyWhHIcWq4PZOhyxNuTGW89MzBr0OcRzxbHSJiiOOOyGp07Qix26vQ9br8stXrwis4e7egKsy52w2JUkTuonY6Y97HeIkYRWFPH3+NTvdDp004fn5CUQhxwddudyLiqO9Pjv9Hp+fnTCfTjk6PKQwhudnrwnjmEGnjS3hqNOnlWXQSvnZL39Fp5VxsDPg5PyMha3pD1pEWqMN3Ds4JGu3OJ/Nubm+ot/vorTmZjyhQlaqvw06/2N8FmsktjwJFa+nU3YDx1EaMHYlM1fTjmVVXVdwqxUThoqps+SLFb1E0Q41l+UKC+zG4oKJKkU/1mQhnC9z2lgOYihwzJ0Akp1IGqrdjgKiEIx2TBclvRB2tWKGhKvtpbJNVnAQKbIArvOSqDbsxmCVY+YciZZShjKwrxRRIG6Y4bygrWE/UKycuHB2E5lsVQHHieReLGuLrSw9Lc6TlZZzM8jkY7RnBahEGqa5JdKwq6XZXKWhF0IaSU7HrVjAROUcprK0NHSNOK8UIh7VQFzBIIVWAMOiInGOvUhROMVCC3Da8dkbx6EiCIQdmy8rskCA29I7aPZS+djWOeyninYIw7IiMIZBADjJaomVjJOrYU8JkA8CGPux3w9ghmOFRMkniKj1dhoQBzCva1xVSb4LikUp75/8DmTx+4pLj5xzZ/77c+DIf38HeLX1vNf+sV+7KaX+B6XUXyml/iqvCrI0IUtT0iQhjROSSBqERY0Ycz1B/4a7/i2PNyt8/5wmknydRbEGC/K77a+b3ijKiyUbRsWuJ1qxANdUXgjrjP11ZsDZtVphDSi2xKSwxUjAJuW0KacE+o1yT2OBbRrFAevJ36wb5W3uzaRt/N02Mevb2goPXlRDf3wTuLhNkusbYMSDwG3mw1mHsutzvAZiIu4VBml9DyPirXvUnPNo07E31M2592Wu7UZ022Uq/Dmy3wKz/8DX8fY1PJuPicKIB3cf8uTJ93jy/Q95+tlzOu0BtYt4+flf8/2P36e/N+D09Qm91iF/+uf/hI9/9AllXXN9MSQIEybTOeP5jH/2X/1zLqZDaqDfHvDDTz7iT370Q758+pQsaWFdwOuzV9y++4A79+7y8uQlvbTDT37yIz548iGdTo/Xr1+TxAmrVcmr05f8+Z//GXldsVquaIc9fvqnP+FP/4t/ypcvnqODEIvm8uqKtN3l3fe+x1cnZyQ64sm7H/D48WOObx/z1ddfkWUZdVXz4uyC73//B+hWytVwCKslf/rDH/DOowdcDUfktUErxaS0jIOY9965z8kyh7pgL2lz9/iYt+/d5quTIUmSYJzj5SRnb3+f/mCHs+EUtyr5yaPH3D46oixKJsucKAiYVDVnpePJ+4+4WdUU+YrUBjx5+Ij3H93ji5evSeMYgLN5TjTY5+hon69vxlDUfHz/HodHB3TikMlkQRhFzIqKr4YLPvro+xRKuvuGFfz0kx/z8fe/x8uvX4oAG7iZLwi7Hd598g7Pr6+IgA8evM079x9w/9Ydzk5ekWQtytry8mbKe0/eI2wlXA5HVEvHx++/z5079xhN55TOEviVreHvrfH4g34WT1ZL6tqhS0toFTshnC0r4jCitnBewTIKCBI4W1TYynHsNGmscLVlYp3kvABnNaQpTKxjVll0KeWQLIKbwqJDTWBhYmFaQ5jCeWGpaxE5KhSxwfc0kb/xi0LEk/MAJqXDllIOSDTMCocJA2LvNjmvpFvqReUka8PndiQOzo0l1ZL0OSqlBLIKYVzISWg5wEJhHHPt6Hi78CiXEsKFEcYiUMIwhAauvZU08izKspLSzbgQQWrixHpqDQxDR1rLub7JpXQyQjJJnJVthBZuSksQyjgYB6NaNDhnpaM2cuzOiSj2ykJqZU64KLztWMG8kL4zmbcnTytHFSpiK9fbTS3jdFU6KgM7RoiAloPL2pEgfVhGpbAiJoKr3FJVm4yR3DhqbUl9Rb7+zeu/9e3/t47JOeeU+jZS5be+7l8B/wrgePfIZUlKlqbe4aGkR4lqbJlbi3Q/3+qGIVDbrgY/Ea//31g7lW6iv9/kSUSjuEns1MphUWjX9EyQydY2K3w/uVm3KUEoNjkZSql12JhG46yjmYm1d5Zopdd7iS9bSAR7o+sItliNTT8Y2UMFgUNZ/17+n9kCB42uYw0Ytu7GbrQv6zFAbcYWNuyJs2gl42OVRVnFOuDLOlAyJmwBJ6XcmsFqSjqCj76pQ9liUZr9aJ63GZr1WOJYx7Ovx82Duo1E6Dcnm/7n3H6f63j7Gr5356HLlzX/8S//lqyVcvLiOf3dHaq6ZEDMYjnkP/zFX3D33gOyrM+rk695eXJKv5dRTiYc7B5xfXNOFMZMJzP+z//7/+LJW+9yenbOpz//lF7a4mttaO/vEFUBkQ6YLKd8+suf093Z4ej4kIvrGy7/9b+l1xkwWy24c3Sbi+sL4iRknq/41//m3/D+++/z6sUZT599SRhFBBr6/Q5p2qEsK4ypePHqBUEcc//+A85PX/P//sW/I4kiVrZkr5uxqBxZkrDIc/6fv/5PvH14SC8JOL0ZMrkeYaOIlqvYyVIuKkVRW1bjOX81XfB+v8OryYzPnz0ljRKe3sCgHWNdSBooZsby6ekZezsddtOAq/mE2WefopMUVxbc63U4n9VoHPUy59//6hkf3j3m6/NLnr14ThaHnKqAvThAxxFJFTCrLV9fnNFOUx52Uk7mC372t58SRhlLW7Hb2+FmMScJHHle8m//5ue8f/8e+c0NX716RefVGS4JaMcJcasFpqCoDa9en3B2dc2j/T3OhmP+w1/+O9qDPc5nU7r7+5j5nK7TVIXl33/6GQ9v30XpFaejC85vzslaGaaq6WUpc6p1/PTva6f9Q3wWPzy85QoF48rSUoqrAvaAXAfsUDFzcFkYHkZwHDjOKsdAQe0UoYW9WDOyDot8gF7U8BA41ZLI2dYS4d1xoAPNEkPpRBTaNnBHO17VgJIyxtwJO7FwECAC3GsHDxVcaZk020osrl0tva0WiD5COdFK3Avg61rkV5mW9xp4PYJBNBIzBXcUTAMY+ij0QkHLC0gLr6VwFkot6O7aif001AKEen6F6cJNvkhfy+unPhOkQhrG7SrRuzS5HwsFtxHkOC0FSM21aFGUVhRIrHyT53ErEGDX9nqKhZZjKvAznx/TO8AwgOtSQuqWfp+cVmsti3UCim4reGUlFTbx+pldDaWSrJmVk6TYtwCnHTdGLM5WbQSouXf8/K5Gh78v8LhQSt1yzp15+u7SP34C3Nt63l3/2LfetFZkWUory94sXeA2UMLHpStvqXTWoZTDBVrAA6wZgDcKpR5svCGK3HafuA2YaMoHzWPKOh+e6n/flDHshvZvHDBBEEAgjIVtJn5lffCK3pqY1waVX9snsf/qtUakARwNoAE/8TfR5mtNhwcVzqx1Hc221yxIw3i8Ub7Yjh9rNB/e0ttoZ6wvYWm3YRQa8NG8D3ggwtoppGHNMjXbfFOL8uvXQQM8mtO3fWzy+03beym5KNGzbIHA37jh3377g13Hpq6pTM5ev8tsMaXVHXB9PaaucsJQs9c7YrxcMpoXUK3QoZa+EbXBAJfnV1S2JKJFt9vDTA3jyZhVmXNwuM90PKa/s8fZ5TnO20J32n1W1ZI6t0zrMRZLr9dlVeaEoeLrswtsXeAyzf7eIeeXl9ycX1OVC/q7uywXC7J2j5vRFQynWGcYdPqUpkJXFePhFaUxdHZ2WMyndOKU6/EMYy1KOwZZQlVUzOZz8rLCJhmTMmcn0qxqxXI4Y+kc3RCyKCSsDaNlzsIpdrodbpZLjroZZ+MFocupFAwijTEOs1pRO0eZpjjryLTDBIrX4ymFdaSBohtrwtJwOZxRVJast8PNfM7+TpeL0RCdT6iU4iCJcNZSGcPV0lDqiCKKKGxNHChOh0NJ8Q0U3TQhLAw34zmLvKTX7zKdL+lHMZfzOcGqoMBykKWY0GGsY7SYsbSGvW6P6XRKO0o4P78BU+DCkIOdDkwXLKYjrCkJWxm2rABIAs1sufKWW0minP/92tP+QT+LjRMtgfGlgcOu4nzqiFc5cyWTfMv5fXRQBYqhg4NMUZZSIrCRZGLsRkAttaHKiVtkUsPhruJi5MjKilUk+oddJQFfFikfDBX0E0eoYLS0qFge70bQrWDoV9RVKCzA8QCGEwiLmiIRB8quEqZhLrvKRIvro5PBzQxakaM0Ei/eNojmIxDb6ryGgwHM5jIRuwTqXMoNthLQEMcwL8VO3tuB4VDOX4WUK3pKLMNN6Neyht22HOeqgiAFs5LyiTbC/ISB5KREFvZ24XoErdKQR8Ks7LkmP0PuYyXuFK1hsnREsThvWoEwHCMPhuoQZgaOBnA1gqQ0VP59d33pbOaB2FhBWzk6XcXN1BEpQ6FF4Dvw+2kd2EAA314H5is518pHprfCb5Mq/f6llv8d+Jf++38J/G9bj/93XlH9J8Bkiwb8rTelNK0so9Vq0coyKbnEG9o9DHz5wwtOjRcXVnVFXZZUZUFdlnLfSjytaymDVEVBmX/jXhRUeUFVFFTFRvi4Tk2tfJ6IDy9rklObcoKzFmOsd2E0WgU/SXp9QjNRO2NxZiOQNPXGreH88zfR5B50rbHTRixqjDgQ1gJLU1M3MfDrfWtEtRsNRKPFEMbDrLdjTL0GJg7ZgbUepQlfa3QrDYPBZr+aK6spUUleil6XQAIfThY0YWhb921B7uYevinSDbbD3YKtcDC3lvs0PzdMzN+T8fiDXsdRGNHf3QcH4+srnHLEaYZO21wMzynqFWBRQUB/75BW1mUyvqauClRoCcOQ2tZcjS/RyuEUREHI3vEtdKi5vDwlQBMGEa2szXA+ZLlaiUIORbvdo7ezy3K1YLmcCfMUhlitODk/wVf20EHA/u4BYRQzGp5jnFisszRlvJwxXS4wWvoltZKU/Z1drKmYzafgnG+clXG6Klg5S6gcKMVhp0M/1ixnC6y10okzCligOSlqiVRWEIWae62M0DlG4wWRc0RK0Y0jTmvLzPmWCQp205TDOKRerLB1Tds6Eh1gdchJaaQhonWgNff6PVqBYji8IXRC+fciadN+XdbEzqJxtLOU/TTFFhV5UZJaR6QVYRBxmRdUymAxxEqzvzMgDRTD4Vj+ToFWknBTlNzkOSiHVZAmCUf9HWxVMpoJiIuigDRKOJ3OqLFYZXFas9fu0NWa+WpJ6Rw+dgGLOBp+B0v9D3oNN3beg1gYgtVM9i9Q3lliZeUbKgEn3RAOFJQLizbyXGoggKFnLqyWrIwDr5eoJo5Iyao8dcJqzK1MrKWGOJA+K24lke2BAlXJBD4tpVyglTx3oGXVXY1kDAOEhVhZmcC130+lRa+gKmDhFzmlfOaOK2FGHJ6RQPI56pGEhCkEINROGr7hfGR7KeBCGbAjzxbXIuyc11D4qPFKSbhYBzBzEXA223SI+LSxUldOXCShAzOSY8fJfi9qf0yIjkR7loMVBCvvJCnlmKf1psldrSUbJHVQDuUx52mJlRM3T+jZGDQcaggqYC7nKbDC1oy8tVcrAYEtLcefz2TstfUMkAdc33b7z7HT/q/AXwLvKaVeK6X+e+B/Bv4bpdRT4L/2PwP8H8Bz4EvgfwH+x9+1fRCWoJW1aG8DjzQmiSMJ+tJafMHOefdERV01boli7Z5onBPbDomqrCiLkmK1osibe06xyinygiIvKHP5vizKb7gtmuCy2osnt0SPflI3Hky8KZBsIOFWY7nG+VGbzWtqgzPi+1LO939Zn5SGHZDVvWhKmpC1zd3U9drNsS3CbJiepvxgXVNqsR6s+Nf71zWMUZNuGmwBB+n0q9almA2W3QR6bUS1W4BFb9uKfzMAWd/XbqDtBNnGRdQAj60x8e/vNj+suZvv5jpWPH78iKdPP6Oqau48fpckiXnrvSc8uHsLdItARRRFRTI4YHe3xauTCx4+eEinv4/D8s//2T8lChRxoEmiiMlkzA8/+j4vnj6lWtV88P1PiLKMg1sHvPu9Jygd0YpCyqIm1I63H93ny2dP2d894Gj/kDCO+LN/+l+KsFGHZGHKaL7gyZN3uB5dMp9N+fDdj+ikCVmnzcef/JAQAQGl05TFio++9wG/evk5cRRz7/CIII157923SeOElj/y69WK/d0dykCxLCuOjg5Ikog8iHj/yWNavl6Nc1yUFXdvH/Dp1TVaKW4d7+OikJ3DA9rdHj0nq+7cWHQYoNKI8+WCTqdNFsTMw5DvvfOA0E/YBrjJVzx56x7PLq8wdc3bx0ekaUx7r8/tO7fYRSakpbKYQHH7+IAXoxH9nR57/T5lEvP9Dz4g1IE0atOa6WrBk3cfMJ7NGK9y3nnvEXGcEHdafPTkfVInvXlKZ6lqww8+fJ+/ffGCtL3D3dv3SKOIt99+l04rJfB0+Gi24uhgD5tEXOQr7h7dwqmQIgg4HHTW4OO3BYj9Y3wWO6TL6E0ugXiqnQiVngVkoeYAsb6OtZQqXAIz40jSiCjULICDHUXfCDtSBnDjYDdRDGuxZOosQmtZMWeh4tDJecxjny4aSw5FEGmCWJM7GLSl70tXiY11pKATCWAJAdcKCbRM8vstOPQfBSaRXiytVDQXcaAIU2FVk0jAwAHCSNQRa1eGdmBTKYsUTsSae0h/lDgRbJVFcgEmCmgJCxn4SX5fy+pfpzKooVTI0YnoKXIriad9JyUQlYgluBX5hFfAtJRkemgYxHCsBGzUqexTGvuI8kiOqXbQT6WM1UdYjqkWsezKNOOkSfy5G6RSMgq1twYD3cyXhQKFTrU0BswEMO4iwWMjJcmqSmtWFuI0ENcLErnecjIOm+L6r99+Z6nFOfff/pZf/Yvf8FwH/E+/a5vfvGmlSJOELPERatbinGcHjMY4J5Za5VcDjXvBuXV1ZeMI8WWJrcX5N50ezYrd/YagsN8yCoI6t8SYym1ssAreWO2/wQRsZXSstRGeXZBt+QudbSeMXpeTLOaNskNVb/eyEcaj9rkWxlq2596N+2PbYisgpXmNfUMXIeMXaIVVCtWUT7Te0ldssx7+ULyOQ9MIcje23U0E++a8SOroN8d8IwjeaDYUIumQLAXTOJS2Tkvz5XcxHv/Q17G1lunNGFsbfvRnn3D2+oos7bC3l/HyqyFoizU51raZXp7TUUe0Woq7929x9h8vePfxW1wML3E6wDhHmRegHBdXF2As73zwDst8jtaKxw8fcHL6GhfCMi+Jg5TRbMlkXqB1wJMPH/Oz//Rz7hzfZr6aoiIJ0MvLOQrH9eUQV8HDB/dQERhr+d5773BxcY5VihpDWK5YVXB5eU1oFB+8932ev3hGt9MliBNKa6XXhZMPmuFkSRpWxO0Bvf0DXo8mvHX3NqP5gkKJ2NAiK8h8XBBYx52HD7ieTgiiiP1ul9fX11JzRrIGloWlPV0RhgnHd+/y2fMX3NrfY1aU1GsnF0TOcXU9JqpqDu/eY1EbahXw9uEBZzcTlviVbOkoVE0xmZNozf3HD/nsi2cc7u2R14YamVBsbQg1nF2PIC+4f/c+OshwSvP4wQNOr4eUKKq6JsWxqA2X59co63j/ySM+f/6KnZ0eSaslf5NsenSMJlNaScpgsEtrfxd7c83B7oC6kiVihqwqv4trGLydNpcV92C/w0VR45RiL4uYzUpWfiwTz16lU8cyDOgO2ry4nHKYQEcpFj4QLa+lb0mQS9hV3E2Za0dh4EFPyjMjRHvQ8u3hkyU4pdjZiTmdlgwiyEKZ2CxC9bcsqFK+BlmIiTWLJdzK5BgsUjKqcwF98VIEpL1uyFle09HQiiGv5HgmFjpGmJHEgokUUQbjiaMfyeMNI5GXssKPfD+bduZLP1ZAU1WJgHRuIS0l0CusPdBqwcVUGrFFgY/xR5icyEnAmLaQZJqpgto4Bi3Asx0LB4k/pnQlGRqdruZ0bukF0r+lQgDY3AtKtR8vnQWYWLFaWo5SYX2WTgLOlNe1JAt5/U4n5mVZSxkqlnE0CDvSBrCO0DpUHBK2QiZjy27o0Fr0NbHiW3M8/iiSS7VSpHFMEsU0TglnDUZpjK6pPK/urKHRe9Cs0qGRJsi3ygsclUAu6/NB3GY287qE35SYudEZbE+ebwCF5iUeYLjQobVaR6LrQL+JK/w2Ah/T3jAB69/532ut1wFmgRK/kzEGU2+CwIwx3kUjJaGy2ACQxlWyHhBYl1veEJcahzEOa6Q+LayBvEbSYQUgaWelsW9DaTSAyIMuYP1VBkR5QOaf75xX7rr1z2vw9cZ4NyfOj71aF3T8qREBsVXbjMu31w+/i5vCcX59RZJk/PIXZ2SdNrdu9/mbv/wb7j58ANqyNzjEGM14dsPJ6dfEUZdffPqMVhSyLGrGZ2d0+wOKIudwf5fz4ZhXp5co5Xh9Iumjd47v8LOf/Zy9/QMCG9Aa7BIHGTejIV8+/RXtVsqnP/8CwoxAOz799HMO9/aZjaYcHB4yGk+5vLpGK4s1BXWRc3x4wFdfvaAVx7TjBFxMJwm5niy4OvmaXhTw7PNPicKAbu+AX/7yM24fHLKYTjjuZExWBUlV4KqSKAy4OXvBoJNwPZ3AqqCXprSrnCwMGK5K6vmEjoab09fEkWZvt88vvnrBnZ0+IxRHWcC8MHSwrJYL4hAuXn3FTiDN9M7OR+x2WiynU/pJzFleYuZzIucYn5/RjmLuDHb47MVLjns9Qq0ZRMo36apZDYe0teLFF08JnSPWAU+//JK9bh+Tr9jrtblZ5uTjCYV1KFtDseL2fp+Xr17TTmLSNKKlkITXZcHZ+Qm9NOaLXzyVYzq+zWd/9xl3HtxjMpqwvztgvlxRliX1sqCXRlx//YpOHJCvVpTLFSrU5LUl/q4vZiepm5PRnG4KrgOf3xTcbUUoU3IvgelKJs7UgjOG8XBCP3ASgDVz7LQ0zlhuAZelTJSJhvmiIE4ccRtezB37iYbAse8tnZVnhyIc43FBN3CsAphOYD9TlLXjVghXuZRDULCsahIHvRacFNAPJTG0E0FUiUgyQASTN/OaXuiYxjCfwWFbUk73tUzCSvtwMOcoVtCOpLzUqiBNwGnRg4y9SyUIxO2RhTCP4SSH/VRstT0fb+68FbcG5gspT40sLHLophIKtmuk+6xGdCaL0pIY0YGcrmA/EVZkJwLydTVLwOzMsBPAJIDJHA5TAROHTuLWQ8+ULCpDaKCdwGkl+6FiGSddyjF1EPB7My/pR46qBV+N4XYnYJUb7oYSepb5mPlFXVPMDHHkmFjpvuuUMCzfJnP+owAeSimSMCIJIz8pWZzRGBRGqa1QsdCDkk04mNzcxh6r2LLYCuDYOF78RLsWCPhVcqNXWD+viWZXaD/zKvXGHm+AiVI+SEzsoVrr37jq1lqv+7I0zozNPm9bRSUzpAnkclaYCWet13d8o4NvVYm+pBHGKpkEQXnQIQCjuTfjZho9SjMs/lgC1RBCepvUAOU2LAYefDjkKnNbP8MaWKitMVZvijK2CZ+tMZWx9rvjx01h7TaDIpTI9uub+5vszT/uTWuJx4+SlHI1RQeK5xdnWDQvnn3NoH9AGILDcjjYZzofEwSOslpS5UvGZ0tSFVAsb9hp91hVFTu9HpWpsMZR5DNCnfHs6+c4aylOT+i1W+g4wVY1R8dHjK4uiaKY5XKOA15MRugw4uzkNfv9XSpT02l1CLST0qI1zIua5c0p1lpqZYl1SBgnWGPZ76WY0mKCiFlZ0XKwPPuaFMvVxRn9NMIibeI7aSZ21xBU6dCrOSvn6ARiO2y1E1m9ZQnaQWUrxsbQDTSz8wtiC8PRDTthQK00cWDIWin5NGcF0vW1rpkOr2kBy0mJjiMM0A80aRiS1zVDa3EWxpcXWAej62s6WuPCAFcb+lmHPC8xWjEsLSGOq8vXtIDh+IpWHOOso5NowiAlrGpWzlDnFfXNkByoV/J3G7fa1MZw1O2wLHJ0GLIsSxISnr94jnXw8quX7HS7OBxJGNKLW9STKSscVlvsvKC2ViYRJQ6B7xJUawVRC2ylGBnHoFLYlaMfQF6UZE40DQkQhxE6qFmVoIyjawU87CQOs3IEkWyvpZTUEwrLwutA3FKEns5aQreJ2NZxANpSFvLZERtZjfczKAonQk0rmwsyDaUjt9LtVi9F3BlpYR2UP55Eg84knEs5J+WJGnbaosOIfGkgBqJUyiw0zeVWXqiZQZGL+BMtmo2wC9WSdRfXoJBMDmtBWYj87BqE8jFZl6JfofQ6kgyKFUSxlDtSBUEbTC4llECDyqXhmgXwOherIAoUhE6CzZwwLKGDfsfvJ6ACeZ+gJdkbtZVj0sXWOJViT1YKskCjQof1/WQ6FsxCxKur3EgosxO3kUoCtDaUNQSBwxWy7SSGvBBQ+m21amO/4wAAIABJREFUlj8a4BH48oKsgAUiNheOwqGcRWHXHUkDrdY9PxxuAzjWoEOWx1rJ5GvVdvCUTILWNnZM2Y5aA4xNV1WttoGHhyVNOWErgKwBH1oH6+3JXGtl0d+s5Jv3Wu+vv8CbbQL4+HFTVZt48LUotP6GANZrS7ZKR34nRRdiRQC7LscYYT0aN0gDtFRzdPobjEPz1TWghnVJY51gikIpC1ZhlT9XTc2kKa0oQcDfBHDrN9tSG22IqI2FeeNY+WPjOuRmHazyHJV0ePjWA6q65nJ8xoMH7zIaXbJczZmsZmRJS8BG7bhzfETWSnnx/BnKWO7ev8+XXz2jXkFhKlpZwmIxI2v3ePjobYrlgqvrFccHh4BiOF1QTWYEOkEvppS2ZpC0uXV8m9evvqZyOW89eJsvvvgV0/mCqsrJWm2WywVhoHnv4UNsGPPLmyv2uh063TaXlzfoYk7lr+uqKNhvxzy5dcxoNudsvOLxoMuryYK8tIyLFUkScLNYEgL30hZhp8XFMidVmn6/xeubJWZZUimI4pgyL+km8M7eDjezJRMDb3VaXJQVi9JgliU6DrmalwTOcTsM6ewOuLm8oTSKQavNs+WSqDCMqWjFIZd5SYbjwU6XHMPlynEry1g5x7QsMIsSFWpGyxxb1Ry3Yo6P9hld33C9dLy12+P5eI6qDdOyIs5i5osZkda8fXQIacQXswl7rTZp2uZsOmIxmaKjmLmqyPOC/b09Hty9x/Diksl4zpMHb/Hs7DWLVUE1r0izjOFkRGAtu0mXVhpzOV0QK00Sx8yK/HfaEP+hbw4YriB0jjutlFVZkFs4VAEj56isZewn1ZuyIrTQU4o4CLFVLeuQImBqDa6UDqlR6JjMnUR1JxGroia3jh0UcyMpnPMcwhCK0qCtrLq7SYjJaxygc8XcOpyRyO4khMnCEjvYiQNc7SidpeP7qawsIhjxrMN8JuW7QRJQFQajgFyea5AVehAKIxECLa0ILBgn/XSKhXTPLXyXWaNgMcG/v8bmlsLJNpf+o2ps/DH5bruZAlUrtHEECvKlF7XmPnI+gIuZAIhepLGlpXLi4plVwgatctnPsnLYQgBgLw6whZGOtcuNlTf3x3Q2l+e1Q42rJHohq+X3pYXlym/TWWaFgKrdNKTMawzQKjTX1lHjmFkJRrtZGjILaRgQGUXtapzx4lN8B90/dsYDwBpDXVUEekOpa+U7tOKEgtLKx5tH6/LCOjod1pP5GrHA2oXSCD/XMeJN2uXWpCYr7Q2bsQEgm5JAE7K1to3qN7UlYgH2ws6tyRkURlmc02hlN7ZQrYXBQQnIwKPjLfdL45hpgIdpSiuNc2VLv+JgbQ02Pi107WCpjQcq0vemYXuUUk2l5I3jg2aa99tdk0ZuDT6sdWiM+PaVwrf584BKo7Vd22B1k8HRjKXajDN2Axi3MUZjWbbrNNpNmWzNVLmGVdly3vwj37QOiZKI9z98xMmLCy7OL/jpT3/I3336S+q6ptU7Zmk1SpVorXnv/QdMxitGkzE6jHh87w6n5+egAjrtFsV0JJoZrfnoRx/w9JcvmIxWfPzDj3n25TPqsiZN2oRBQF0WBFpx+/iIONJcX1+xWC34wQ8+5NkXz1AoOq0u42lJqEBpxY//ySd8/umXLPMV7z5+zHA8YTxeEGhNpkJyU+GUotXvcevubc7OLrkaj/nkyTv86vkr8DRzq/YNxZTihx+8y5cvT8gnCzo7PdpJwGiaEytRv6+aMlwU8t5bD3h2esH1quLDB7d5fTbEGF/jR4RyRinefXSX4XTOq+kSwojj/R3OR3NiHH0l6ZMxIsz75N1H/OLkkvGy4N37tzi7HGP9h3wLr9pXioNbx0RhyMV8ways+cE7j3l6ek4ItHVE6ApSFEul+PFPP+HzX3zBYljw1r17TGYzZqs5cRAQBRErWxHrkGTQ4/DuIddXYy5GQ3784x/y+WdfUNU13SzFLSoUDq0UH3/4AV+8/JrZeEWn08NpzXK5wC+5vtOW4QrJwrjXCzgvHGMDD9opo7zC+IXDnhOh5BDFQSdgWjkmTj6fd7VibB0Woe0jJ6C8BO7vBrxeOFYO9pOQeWUlzROJNk+tZE/EsZRbrp0Mxm6gGHpxZKCke23opNxwuwuvc/k86ESa2joKPx/0kEl0pnzpIxIthg6gpwQcJcgxtZxYWG8Q1uLGMwlZqIgszJ3MQRlSYimUiDF3U7ixDqUlRyQ3wjIU/pprWekD0419czYENKUWJv7aDRAtRq3lGj1uwaW3FvcixbJuPoV9Z2MjAs8gkjLK1DlUADs6ZGhqEjzT5M9TARy34aqQ89CJFMaIXbrpWxMZ6dFTB9BtST5KqeEoiLiqDRpJOe36caqA4x5crSTVNA00EYqlM5J7wrcSHn8kwMM5EZJqBYEmDDax5EoHEEi78SgKMCbyzcQ2E2gzCTWgoZEeONiyk25rHbxYdStq+9co+m2RZMN+bD3ePEcmByUUFl5PgtgBnXPgLbMNqHFWiT6EQGxNFqE8rBE6zVksrJuofRN4bN+t8bkdW4zH+qtzW+LTeu2Iaay3jeOlQRNrvkW9ecwyLupNYNPoQqzDKYNzaiPlwIAzW8CjSYt9U9uyZpHURnyrrKCfDWHkNtHo/r3dWpPimprQ1nX0h7gYf8+bcnSzFtPhmMI43nn7CX/32QmL2YwgTNjrtzk+7FOZBOdKbq4v2D/oMbx2ZGmHXz19jrUF/b0Ddo8O2T2+LeFS+YyL11cEccj9h7d59tUV09kSVMCDo57YdS2AYTgcsXO7x3y84MH9t/j0bz8lLws63S6D3R6HR3vUq5KBKTh59prWoM2g7jAbjRgOhzjnONzt0e/soK3DuJrZeEG5yHFlzru3Dvj8y+fMy4og0Aw6Gd2oxaJccT+MuHh+QqeV0atzKhwvL0Zo52inim7WYieImCtLNq+4uZ6ineW9/R3OL68Y+1yL292Y/azDpCzohTHT82uyQR9VT4mzhJOrK/LakoaQdRJ2wph5VXAnTjg9HRE5zTuDLoubIbOiwDnY34nYjTIqHaPCgHw0JTjcJzY5D/cHfPr8BaUxRHFI3I3Za++zXBY87DiuPn9Bu9ui7xJWsynX4wmVc9w+OGS3lWLQ1Bhm0zl1ZaiKgrcfvsWzX/6KxWJBlGTs7R8R3gqpliW2Ljn56pTB/h6T4Q2BVlxNRoROJusYmRy+y1tPOeYzg9M176WKkSmZO0sN7EcQoVni2I8j6mUl8eihIwrhunLUSsSXWQauhMIpDmLFfCpL8TshrGzNEq9v0AI4cwWdUGFLx8JBK6jZCeDKOGEokG62lCKyPEw1q6Uw4QMlZZSZlW12FYS+82ykZcW/KCFQhq6FKQYXiAB1J5KJdFlJfHpVgrJOussaEUuaCNJKXBtFJSxJL5LXhDhaCMtSKzl/O4HPxKhhJ5FSSGUg1Y7MAxAicBW0MumkmzuxMS8LwFl2gLqW8TTKA6lQrKrdWF67sBApS9fB2NQQSEllJ/L2XwOHCSxzKK2lB2BEzFsGkjwaRcL8NJqdYgVa1aLnsBVlIOMwiMSdtlBwmGjKhSz820qARG68qBcpG33b7Y8DeADW1JhaoZzGEqCV2CcbTYRVmtBpbBhQ22BdRnBuAz6aiXIzPf5m4OGswxjtHR5bwWDfAB/r8shaX8D65+2JT5LErQ+y2ioRWIfxHXbX29MKXOg1JBrVBHOhPBhSOGepqpq6KjcAwzMYjTOl2ee1UNY2XXjtumPrGnjUm6wRY41nKozffcmLUA6cdminN8FfW0uvhglpmKHt8VJaxl1+bXAN8FAS766VFmZHi1pVef2MAA639f2G8WDrPewaKLGu9WyYD95wKn1X4MNagzWKOq/Z7fZRRLh6yb0Hjzm5uOHLLz7n9p075EXBfLZkb38PZxOOb+1w/uo5xweHDCdDpqMhZVFwsL/H1dU1aZShlKaTdWm12qzmX/Pwrff4+sVLXr76ir39Q0KtuBnN2e/vo6xmf/+Y2c2YXm+Hbl0xmkx4sXjO8d27TG5GOEL63Yx+1CFJIy5OT3n7rUc8e/4Vl6MplXG044jJeEI7zNBFTtdrI8Ig5HjQYTgacTFaUPcjgrLmarqgF6f0rCVMM06urrm/t8t8OGKYW2pTMGhr5rMFCke7TulECaG1uNLyaHfA1c2Is2lJpUpSY7mejNmPYqLaELa6TEYjdnt9ivmcWVnyelay1w2pF7Vsv9WhG8ckznKxLHmwt8fF9Q0Xk4qqHZGFjtnNgp0kIq1LXNplPp+x2+2BNVxNp5yO5hyHCcViTllbeq0WrSAlixK+Or/m8e07nJ6ecH51xbLbpptlXI9GDHYG6FXF3s4BVV2hlObg4IDrmwnPXn7F7du3mU2nlCtDL0vJSsOtwR6vTl5zq9/mZrKgaMIIv5tLGJA/n9xARzkipyiswznF3X6H4XDORSmahyMNw3lJqhWp/8M0taPXSqiLipW1nCxFYBkrx7BwDDSkTmECiTA/7rdYjJfMkG60hxHMctFrtJTQ9ZWDMA7pOsfKGC5zSclsW4nt7itxWdSB6Bi6vZBqWpMjTpG+lhKJsgLqHJsws04IthZxKEpSVceFlERi599bSZR7mgs4ucolv6LGB2VpKeU0nYVbCagCJsYDAC3dYlvIZFx7pkYl0KskD+Ny6fUdzXO16CiMFWDUzjRuaZkj5ZvdAOaFsEmJknJJ6UAniq6DGsfIC3pTDcNCGMfM+a5nDlqdgNbcMFXynvuhgDS8fgatBPRozW6sqZY116Xs4yCE69zSVcLugOxrmkGQCyjMf8fn8B8F8HAN46FAE+K88EFpmbwC3bAEkgoa2gAbNgmcfiLd6j7rvjE5OuPAWa+VkLtWCmtFxGmVWvcvecNxsf6q3vi5ecK6LTyCbteViHXC6SZ5s7Heaq3QXmasgu332YCHpuxUlqWUVRqg0IALu2F5tnepSSptQMY6ZKx+M+Rsw1649XytmpTVrfAw7bbYCNSahVgDrqY8ZdmAkm8Aj8AG2PU2g42lVn0TgGx0Nc5tWq7YdWM4z874k9AISdclreZ8f0fIIwhCZvmSxakm0FcEaUJ7Z5eTVyf093Yps5TL0Zjjw10SLDeXp1xeXJO1Umydk3VijHEM+nssi5JXL1/wg/c/5rMvfsF8OcdqR5p16B/0OXv1gl47pVZt5vOadjvh8PiAi5MTrocx7SzEVhXttMvVdEivtwtVzauTU9559JgXL55xVc24vr4ka7WIs5jXr08JA00ShLhlzrisuHM84MuTG+bnc0Id40JFFgfcjMfEiLJ9MhlzNOjQrkrO8xXTYkWYJmjlGE9HTJSlFUJa11zPFjzc7fD8ZkoxHREqRZxEhIHjcjjBBRKItJjOUZ02vTTi1bKgdXlFlMaE1mLyJcOyoqOkM+7VZM77gw7PxnNOlnPSlSJINEnopH9MAH2tqJc5y3bK0V6L51dzRstzVJIAltRVDFcLurEm0SHnl9e8c/uYVxfnnE0LsvmEMG0RZhnn19eYKKSvA8xyxbgyPLp1hy9PTxjNxiRxG+MqsiTj4npIp9dFGcvp2SmP7tzhqrxgNF8ynDq6aUpojLBKzpEik+rv6nPxD3odI7qMhRXwMcsUamU5Hy+wnkkInMU4OAjgqXH0kTVKpCBYFkwDmbB7Sh7vWon0vrTQwWES6W0yn67WzddayHruMIAvapkk01hW10FRMw4BP5HGSFS49bHhPYBYEdWOelGzCoVh6PlcjT3ga6ScEAZQZd5eq2Qbsd/3xIkb5saXD2lJAqoqoIiFlej4ZnPtGq4iYT9iBbYDwVIY7NwHzLQjAQcxcOogM17kaiAuxQVjKmm6p4GOhZsIriuZ0E0H4hVUhaX2jd3afpwGCl5asf6GEbgAwsKRh8K6pFrKLW0HLoaLUsZUdyBaQr005KEku+74BIi+k3FaWkiVwyYQ5ZZZaQVUaQEYUS1lpWsjgClOxFpclZIHQiXX8bfd/iiABzisBx4BHmRYh0ZEp4FPI1GqWQEHbNI5vaPDmS29w6aU4KzDaZmsRWjqbaVKyffN1+049M1u/dY6lXP4YDCzBVq+IbrcErOKXsWLUZXGBQHK1w2b93BbOo51kmpdr0Wxm3KK37ntKoNznhWx69KKJLhuMR6e7XiDLfDblLJH0x8n8BHwbg1Emr4w8s5NOcd6gWojs7DgDNYDj0CJw0f743V6w258k+XQWuF82aUhML7JeGzYJg88thgPYZ2cr119BzcHcZjyvY+/x/PnLyjymuvJFOKE5XwJymIrTV6CCdoc3x7QbWecXV1Sq5rx9QhnLfP5HKUgVi0m+Rgdaj7++CNevHxJWRpm4wJrI2bzqbhPXICjg7aK/YO73Ll9i2dffoZBczMeEgCL1ZxAaSIb4kxBGmU8eushN+evyJcly7JGe71UiSXG0TKW5aIkihPuHe1zdnJOahQ304IEcEqxdE46d1YlhXHc2d+lnM3AWPJarseW1w+VONo4llWFQfNwf5fr6zGRswwrS9spcqtYadlmYGqKynK8v0taw3w5RWEplgUdBZUWt1sbaRZWWnh4uMfl1ZDIOuY1pM6xUopcQYxDlSVjo+h0Ohy2Mm6GI8CxWMxl1WwUJY4EcXAY4L1HbzG8PKOsauZFTsuXVssAtJPV/rIqSNIO7771gF99+SWxDrgZjkkcmGWODRSxc+RVSRgmPLp1j8lkTD6bEscxq6JYh4cp5bUo39HNeF3AXiot4NsOrpWMZYHU7necrLAXDgaJJqodsXXYQMoNXSdUvnKisZhradq2n0KeC1txo6Hlu6MukfcpS5k0s0AmtMyCi2DiV+slwkJkFnItjMhBAmUhuoepllJBjJQynAMqAS+x3lhAw1oYlraTibTwDEduxaHSC8UV0zbyHsrJ4qryC6KglHEIESDjLHSNaDl6nl0pnBxnYcSJshN6gakVxiNHtBKl32Zs5bHAwF4k+SJtIxknXf95OEcAiatlnzMtZaTYyT7OnACmGgFVaS2iVVtJfH1Ryn5OlQcsbq2/hVo620ZKHC/OeFst0oMmV3L8XSclmsrAIBHHWmg841RLKab02/y2JeAfB/Bwwipop9YCq+3I8KZni8KLILXCWr/6tRqlLNYJbLPOSkYvds3Ny4Sl/eTaZHw4T/P7iDXlyyVKiz4D2Ey1m/1svllHnOPtvm4TVGYbu+9WGceuXS1K/rK3tyk0ic/pqCjKkjzPxd9flWtAs3bWfGPS3m4G57ZyO0wTke4BB81E7uwb+9qAhw3wMDgX4ggJmrqHZr2NZjvrNvVsQIJqQr6UlG6cc9Lrpfn9b0Fyzvmyy/pn1sfdPGC3wJaD9c/WCYe4BoDfwc1Yw/6tQz5/+pTlaELSSnHGSIR6XTK+GREFipurG3a6Cdmte3zx9BzKEdY6gjjkcP+I68tLinJJHEWcvDrl4eMHvHz5WkSoSlNUFe3OgHba4/LiBB3ETKdjqjLg/v17/PJXn2FdLZ9+KmDv6JjZ5Ib5cklLh7z4+hW3Do+ZjkcMJxPCKMG6iiCKGOzscTW8prJSN5/P5tw6us3w+hpjDTmKEIjbLYyxTHLx7bllSdyKsc5QmhqlAgwiDk+6KcWyZFYbdnFM5yuO9naYTKbUtibI5WSqKCSJQibLlVDRqwKSkDgKmI6Hcp3ixMq40xW2oagZaJgsl+ztdpguFjikjArgwpCklVDNliycY2BrKhuwu9tmNryhsq6pchL2etRFwSyXtukXoyGD3T6z6ZTZMieNInSgqFVA2uuQj6esnMVVhuLacv/RQ55/9RWqKqmjGI2j2+9RGsNkNiUJAy6vrul3dyirguvJkFYUsahK+dvzdfSJt6p+VzcLhLFv9uVglctnQxX4pmq+PBA5IEb+tq0TwKLAaRH6qkB6k4SBuDySVBI5FVD6ckmtZJIMnQgrIyUUfRhCWMqk3EK2W4J8BsllzcxJCmjpRadV7ogDmfCtZxmM38eF8dbUWkodiax7qI0ADYX8vgj94sY/XhWSMroCVOVbwvv9mxoRV+tKtml8VHnpQUrs6W8belG1RE+xLCSd1GgBEBHy+jCUMooON71YTCHMUYGci0YIayIpH+lQ8jcqz9AYJYAgQJiMMBAw47QACYVYbeNAzmHtU1crJS6lpZX9oJJ9175cU/ht1LXsd+WEYamtXAemFJliYT0YUzCz3y4u/S4F1Fs3EWnqpmU9wm4I4LCbiW57sluvbt+cDN94bjN7+ffYUPxvCig97niD7tc0Gg/1BgjCOR+MIoyMWHv1G9uCZuLc7JtEqG/Yhga4NCULax2mNlRVTZkXrJZL5rMZs+mU6XTKbDZjPp+zXC5YrZbkeS4R8XXle66Y9Xa2S09v/FN+wvaAYx297ss6VRM7v23XNWatGWl0K277WKx/zzfOix8nWEfBb4Qbclfb99/gRVljELcpoTjnRNuzJa41fv/MWiT8XTEejjJfMRtf09nJ+PBPfsjh0W3eeXzEu++9DUGEdQaconKa6c05dX7FRz/+gP1bd+l3+/zJn/2I7sEBQaA9aLQUec3N8JJAK376Jz+h39vj1p09PvzoCUGUyfjUFbXRzGYj8tWEtx7e5/7dhwz2evzoxz+gP9gV+7m/Do2f+JQO+cn3PmG33WWwt8cnH31AppSEHXkGaZWvGC9zdno7PDq+xc5Ojw+fvM1eKyPzzyudsGDXy4LcKh4+uEcrjUnbKT95fJe2leyGwsqHcF3VXBf/H3VvEiNblqVrfbs5rZm5mXl//fY3bkRkRGRkZama9yhggnhCYsKACUyBEQPmbwYDZiCExAAGoCdGTJAYI9CT3qNEUZWVmVWZWdFH3Li9d+Zu/en23gzWscZvREbWQ6qM4IROmF9z89Psc+ysf//rX/+qsWnKg3t32M0yHtw55GS4QwcJfgVQ+8DVvGDhPPfu3qXf6WKTjD9+7x06TpEggWsRAqFxXBYVwUa8884DOknE7v6Qt44OROWPPGgbH5gUBdel4+TWEXf299jZGfAnf/g+O1FMhnxV6xDAO05nM5wxfPDhB3TSnOHuLn/4wfukWsusLoDHMV/Omcwn7A53eef2PQ6Ge/z4w/c52R2iEW8H7wLKOa6nMwyKx4/fJo9TbJrxzskJEWKK9T1mWgCZdc9riOOI3sGAGLg3TLidWAZIIF5qCW5VAw2KwaCDjyzWwwfHmm4jrMVCC2iIvACAWCu6BxkhwCCHB31FJ0hwWyIpa91qO3q9CJdZTIDHB8ImdJC0TYMEvdKBUYqdfUvwMlu/15eKDmXl3kQJuKmC2JSrrrAEhzuSOukAy4h180UfBDh0d9uAH+CkL5+zWtgWr1pwEkQrEg1WZagwiKWipzBtyljJ9bcKdgdaUpYe7u0J65K14+RpQViAjlHk+3LuvQQOu7LNJhJNh1cyTi7ATlcRMvk+3NuX48wRC/qVTqUOcj16ewbvRadzty/26sHINQpK+rLUATqpIfRiogAnQ+gjFTXTFsxohC3yKHZ3Y5xSJAr2+jKv3mlTY79t+UEAD0XrzaEktaJXgZ8VkPCr3AaETYAJbT+UN0HHNvhYB0DE0lsLt7I27lo3RVPtilr/vLa0WrMVtOxGCxzUpgRUb4GODRBqj3s7jbNdRRO40cvFtSmWoihYzBdMp1Mm4wnTyURAyHTKfDZnuVhSFEvKsmz7ybgbWojgVykIbjSTXalQbqR06pqqWq1bPW/WTfLcWiB7o2w3bO9ve7+bPa3BxjZN8Vuu/7cuYf2/DchZldeuxMJhi+nZ6hb8+15CUKTGooPirXce89f/8i/ppl0W4ylPnj4D5fBuSZxnuLog3xmQZR2qJjC7uuStd9/ln//v/xxflTTOYY34wWgdo1XCw7ce8/Of/ZJOt0cUZ/zqb35NsOB8QRRbqnJMmg6xytDp5Dx58iW3bt/hL//yZxR1LZ2JlcPqgLKaTFvuHB3zyZOPCZFmb7jDn//Fz6iUghCw3uObQI9AFOB4uMPfnb6k00n46KtnTKqKCnlARwGoFIdB0elkjCbXzENgf3fIn3/0jJmVPhqrPHqn8XSBe7u7/PrVS3QW83y85OV4zlyJ4ZMN8mA/BOI4pgoN52XBye0j/q+//ZgiiVmRnhkSaA6BO4f7/O1Xz3BZireWL88uKZRUnYUgE5q+AqsUaZry5OqCvf0hP/vVJ0zZpDmSADjDwGiOd/f57MuvwBqGu0P+71/8ioWSCYlRkiZOtSX1cG9/j988+Yzd/T6ffvkV1/NF+/wJpBrqxtE3EcNej8vLC0rXsDvI+fLVKU4rqvD90tAK2Glp9u4g5+l4jOpozpeeSR1otPg42EaC90kT8EazxDNxDZ2u4vPTgIs0SvweSQL0GynDjfOYV9MSHcns/HIu1L0xgJMgvC90Gc4oLoqGNINnl+CtwlsJttZDVsO+B59qzuaeygrDMJoJ9e+UACPtxQ491tLN9mImKZzLuQTwxoiw0ns5r0GQDrXXhaSBiOBy1s7yjaRBjBedR1dBiOFsCj6C60pYmNLIveTasRx6UFYxd4FxEzAJvLqS4210u80gKaMeQKI4HTsaK4B9XkiflAoZN+th2AhQalBcl4EkhtdXolupW/2J8mJvv+uBVDGae2ojrNHVTJisYFr2w4uDaqqAWHO6qIhTuJiA14pgBTDY9rP7DoxRXC0cQQfiCMYTuYmKtnvxb1t+EMADpAZ80wW1XVbgYR2cwybAbgfaNTAJ2xz9OuKu3Ta3wMY26LjRyMxsbM3XnVbfED9uMxsqrISXN4EP28AiBMJK2LqaqTfuRsO4pm6b2RUF5XJJsVyyXC5ZLgt5XSwploWkYNqGdk3dUDer8tjQpisUqxLVTTXOls9IW8oaWiZBgviqXHe7ZHdlNLYK9OEmYAphPdQr6LDeF29oONbHsHUttq4JW39381rd/PyKHQrbnh4+rC/3BujeD8DFAAAgAElEQVT8/helPM8vLul093jy+Wvuvf1Tri9P+eLzU5plgbUZP3rvJ/R2hrjG8/Tr1+wf3mU2rkmSmL/7279BN4a6bOh2dnj08D3SeIfTF0+xxvD62QV3ju8yn1zyxUef4LxGB8X9x++zf3gLYxKePPuKW8e3ePH8lKPhgKdPnlLNCpqyJI0T3nn4mDjushhNKZcF89mUbjenKSs++eIJHaXI8Rz0uxwOdki0YjYe008Np69ecdLNuZ5MWYyuiOuaVCkeD7pYq7CuoakLbLUgWizpeM9nr8/oUbPjHL3YcJLKd6laFPQNnJ694n4noliWXF+N6NU1uVLcHXbI8pgkBGbTBakpmVyNGWjDFy9ek9RLOnVNHlnuDztoo3B1SdCB0dkrTrIYXVY8f/marKrICRx2NcM8IlKK2WjCfmKYnr7iKEt59voUN5+Q1zWZMbx7fEQcxYRyjnc1y2JM1skIdc0nX35JNzgGwXOw0+Go3yPWmouXrxh2Mz579jWHuwNen54xv7xEVyWR0Ty4c4s0TQnlgtnVBVld48o5MYFXF9L51oTvbhL3+7mRhXrvaZicj3lgwFWB63lNrkSTdqiknFOjcAoGONx4yaGHs2VAh0BfS/rlQSQz6UqJHqGclRzXHuXhohDXS4vMvPdjmUEvtbRlr6cV94JUndReUhRNgDtW0gxOS5DVhaNfeTIvFRrKttUoAQ7jtgGdkRSDrgSgLlybrmjbg+0Z8dfwqm0WFyBrRKcxrmV/kRUm9lYsoKY08r5vxJ688rJdm8o2d5QwLA4BPNYHbBEYehGQoqQJnQNux7LvSsmrqzx7PqCddK81kaSP8iAlzQFYGEmVhMJzFKQbcB0gjgREHRlJt3gtoChUgV4jPXOuKrCJ6ERiL+dUK2FzUg3VrOa2h0ktKbM0ljTWsRZ7eJSAJuM8SeWIPJy33YhDkHP4ruUHofFYCRH1yjxsi2GQRmm+1SC0wZJVGmEtMXwjFbN51VushUf6foSVnwQr3YgE5rDFntwUiba+HCvh6XoiL/u+wbD4bx7LuodKkLbYK/v0pk3RgIhCq1K65i6XBcW6e26xlnQabbBRhLVt6a4SjwyltJisGTkjsRnfeGd4r9uD1qyaqdxIy7zhY6LQeLMBHcF7wsr8q9W9CHBR62NTaFCeVdntSjOyAhErJukGINFvAIw1MFrtqb0XgviMrMDStp/IGmOuL8n3Az601hhf47SnKcbEo1eU5Yy0kzOfV2R5xmeffUJkI3aGQ6ajaxZzCThFsQSdYI2nKhYkWcZHn/wNg/4+ronxRlHWE64mhuWyIM1SimVBlnR4/fQpITh2BvuMry8pnKMuloQQqJqGpJOxuLqml2V89OXn7OQZ2lpcKWLJeqJoyoJEaZblDO0Di/mSa+fo5DGzUh4qpXd0fYmm4SBWnNUVHav5fDRHqUCUpcyLGu8dy8aRekdfBXwjFHvHGL4sPVlsKJTki+vGUU8rgg/sKjivS1JteXa1xCnPTp6xWFRYlTAvK1Ivzdu0ClxUFZ0k5uPLOXmimQQpDWgah1pW+KqSCpmqRKEYL8SmvZclLIpGGsKVtbTzVp7cWM6XBTtxxEevz8hiS6ktVeMIZYObzfFNSaYMZbWg8YqmqLhqanZ6Gct5TeGhaByVg6YoyTLD5XxGbmOePn+FjWM63YxiPGdUN8QmhsbTC5661S+kfL/iUg1UKcwrTe09ug6kTnwpxrXHKuk2W9eQZoaFc8yaQKSFKTkIoGO4LAJxAl+3VP88V7AIoi3QYjy3Y6SRmQqKSsOkDiSxZhk8pRPhqQZ2g1ROjJaBxMLrAHgoM4UqA6UWD4qkgqO2mVzlpLfKeS09WnwiDp1WAQZ2K0gymBTCGhRGqjKSTNxJSyStEtXSJr42MF1ClsBp6w0ScljMZdwqCzuV+HyM2y5/hRab9LTViVSrRmzALQQMjJdybmetPqLOoFkCQbrL5m3QnzUSzJWR8tjECvuyKIUhdMChF9BzvZTfj5BxqnMR4NbI36QNHEUipq2cVMW8bu3cixhmS9GeBAV9L+N4tRDG7lq12o5U+uaUiGjXVnCghSmq22P6riZxPzDG4w3Q0aZX1mWpW23pN/4cYa2foJ393mA/Amswo7nZul2vmY1Na3ZtzJr1MG0J6Ir1WGlQVn1caI9z/bo+ZtbHsdZDuNZfY5W+WLW0bxpcLYxHU9VUVUlVFvJaVdR1Q11JQ7iqElZEKl7aihXvpQcLIMxBC0T0CpRs2I4VEJDDbQN5m5bZZjVWGpA18PIbi/V16mY72rcMB2tgwRb4YAM24A3WaFsk+82Uy1p9s61IXe97xWatj+DG6+978V5RVSXWaD74oz9hPp+BqtnpZHQzLY6xIZAkPSYX5wI+4y4PHz+kaSpUWHJ4+zZKB+rGo4y0CpvMxmgT8+i9n9A0Dm0csdH08wTlRdtj4oz59BKlAq6xvP/BB5TlEq08t4Z7WCUeC4nWJHmX69mUNIl5dHSLNIoIyqKNZa+zK5lLB1lkaBChdW4tH9y7S+E8JRFpNiDWlroJGALDnZzLoiSxmuNOj2G/TxE0HstO/0BEd5UjNYoki1mWntQa3r9zQukVlYlIsy6dKCX4QAwM8pTroiaNDD0bc+fWMXVQaCy73T1io/FVTVdDr5OwKGsybXj3+JBKaUoTYeOMLO1JV+smkJmIWRVEZ6ANP3rrPqUPOBXT7x+T6EhKHbWiu9NjtCiIoogH+4fEUYLDYHTEXv9QSvwbT6INRaNwIZBqwwdvPaCpK1QSMej1yUyE8pooQB5FXE0XdNOEg05OP+vglKIwhk7WI7DW9X1vSwAoJD3y1rDPzCnGaIKOiJShdhAq6EUwKUWtuaMNg07OOMAkKFxjBMCUErhNDMuppLwPugml01wFxdJrlNMUPlCVgczA3DtUFUiDYtDJmdUw8Yq6keKBshHWIkthOpdqtp3IgtfMgJkDX8rMvyyEEZgB1QLwkKYKKnFIXRagnKQ5WEIWS9B2jaTiIq+okAoZV0iKZ1FImqHRMJ9IyMkz2eYYWFSyzdIBJXRjYQ1UDTGKyFiWHq69jA/AspQUj0pgOZNtpqnFV4oxorehkXRQvRSWYurkOkVAkliaBsYoykrYmrKWEtckhclc9Bh5ZNBuM06uZZKqJWudTdP2nunkmqod+6LtmFs04AvxKpkWAeMgVwaDpUSx8IrgBFTUbkun9y3LDwZ4bIL0pgncCnSwSqWwqja5WYa5ARHqm2kRvZVOMW+8at02ZTNYa9Y/r1ZtDNrorZJSzcYa/duXtZZkW6+yVZK6CsxyjK2WRG1+v1KWGK2x1q5XY8yN7WzYgtU4CEi6CThW6pYVDmp9QNiIabc/uzo+2t9tKkq2mIb1uroaG+ZIr/f5zTHZ/ml9VN8yiOpb3v7Gv9843jdfv4/FRBHdXo97dw/5q3/xLynLivf/4Kc8e/oF11eXHB/dIe32cCgObj3i5Haf5ewlf/X//AWHe0fcvnPCR7/5JdZG3D4+QalAkmf0+33eenzIr372l4zHE9778Y+Zzsa8OnvJzrDPzk6GIrB3cIv9/T5JVvHnf/EXdDodHj96xN998nd4rRgeH1G3s/ThYMC9Hz3iV19/xfnFOffu3MZZy5OrC0yWMcgMTe3pWEu3k9M92OPXT75GWcvbt4Z8Pr6i8I5hx5IrRTVdst/rcOd4n6fzBWdnl+wNd8jzlCeX53gNB6lBNwFVN2RZzPHxPr96/hKlFe8eD/l6MeeqLMgTRU9DVdQcdDP2jw64DoEvv35Gp99ld7fPZ5cXBKPYzSzagykD3U7G7Tu3+OWL15RlzeOTA86amlfzKXFsOIw0wTcMugndYZ+60+VvPvqCKM24f+uIj189xRs43G1dW+dL9vo9Hj1+i797+ZLLi0vu3T6htoqnF2foyLITG5QPdGNDr9ehd3TAzz/+FGMj3r37gK9en1M2NYOOJVGKUDsOB31unRzzcjbj9dkpe8MdojTlajYVceH3cvduFg14o9jtWL68HhNrxYNuwqipWTpHHkknV9XArSSimypmyjOaLMisYmgVF23rh91YaPy0UuSRYrejeDov0cFzlGiWBOZ4YiOeILaBQ61JEw1WcTpdYIzi0FouW3OTfiRB0i5hmCgGKZxVDa7xDIwE4lmrJ+q1WpRDL46fWQTjhdib39IikA1KurQmGuISDiJJj5QuUDaBrlEMgmLRbrufyDUaOmkX34uFidEGbtm2WqTdZteIodaBEVBTEZiUDamBXSVlrbodpyhAp5TtDVO4bEUSB0ZJeSwCOHZiiBthF+JYUj3jRYO2cKQUk/YaDiPRX8UF7MVSyjyqJIU+MIooSPVRomAQiW5jF0n9ZBFcLuS63DFKgJcSp9ZcgSpgP1J0Yph5R9E0ZEaRa82i2Xi6fNfyfd/nm2WVylAQlJIyrbbsIXi1zhIovUXBo+T3BOkoGIyoaXybKw1hzW4YpWV235Z/SRXtygq89f1QCr3yp4C2zaCU4Yqbt1+bjW1rPfxKbBo2AVUjfiSSGoKVv4QE6A2I0KsAH8KWtsRgTUQUxYTAupOsghaAmBusjTEb8AKggxb7+TaKrytC2u3QHr+kYcRMDb1xDFVb4GOVlpFrtAEbqzTHilLaRrDfNWPbvh+3x+u33BTtrSGgc4UrtrMpqv3U9uv3sbimxqZd+nsHvP2jmL29AX/1y19h45ymtly8esY/+tM/4NXpjJfPn5DtH/GP/433ePHinIuLBV999RVaG8oyMF2M+bf/rX/CX//8F8RxShr3+fEffEAv6/PXv/hrGXqVMbo850fvfwBe8+mnn7J3uMv7H75N/uuvwHs+/fhTjLHUjeNydMGf/Zt/xmcffUJVFNQTxx//oz9Cz0t++dHHeCVps1lVs3fY562jiM9eXjBQmtudHZa7S/o24tPnF2hjqLzjtHT8+OEtTkcTxouSaQ0fPLjNcjFjdDnlykkPorkPTOOYR4ddPno9Ig2BxFsOh30OcsPHLy+wxlA1Dee15/27x8RlxdnVhCws+Onjh5xfXrGYTHh+cSUeIs4ziWLefecuH794ia5rXOF4eHKL/TzioycvCErjgevas3+0z4nWfH0+4qAJvP/e+3yMxoTAk2fP0cawdI7TxYI//qMP+fjLp7iypLyc8Sfv/RirPL/+5FNKhJWY1o7dvQOOujEfvXjNoYl5sHeLumzopAm/+eJTrDVUzvF6WfLTH73Dq9EV1+MpY7fgw8ePeX1xyvV0xqxx4reCpFq+r3sYNlUlaunIUBwmgWezAm8MZeNoHERphFI1V6Vj4KGvAk0MiQttykBRE7h0YnF+4QLGKZpFIAsSFC8rh9ea4AJVkCAcJ3BVB3KCeKAY6IfAq6YR1o7AxEkVyTQIqKiCeHwkSlgAp4WR0EhvFGukJ0omBWXi4+HhhRKn0k11hvQqSdxGEAtQNIGi1UFoZNZvFZwHEYI2bWFl5OE1AmCUzJ8pFNCadKVetuERRuRUtYZlSCoy0XAVZP9laI3HAoyaIKXAQSp55k4MzCovniBts1yiGl5ov3YSLZwc5zWyTe1lnCwwbQKNkXFwCPuRRDDxm7HUyDg+U55EKXQIFF4EuqWhtV+Vzweg9h6nRIdS/j3uM/V95cS3l8e37oX/9j/5p1jbBl0rwVS3LeJXgVEpteFo1NZKmy5ozcS2+68YbbAr4LGaqYctvw1apoWw1jNs+2JsUjxuU03h3Prv3yzrDK3DKIinyLZb6Coix3FMmqYkcbJmFrz3zGcz5vM5s/mMRVEwXy6pqnot/lRKCRtjrWwjy4jTlCiK1syI9466qSVFsyqTba3Xb6yNW/e8aZqmZZnk+IzRrZbEYk3Udt7Va6C2WlaBXtxlVzoSR8CJ6+wWkNp2Ln2TaeEN9iassmZvil9XdvHhBvx5Q+MB//X/+b/9dQjhj/+BbtdvXe7cfhD+o//wP8MFQ7ffo6lq8jTGu5py6ZnMLgDL4dGARW1oyprGGXaHHabX1xzs73B+fo5WEvypFjy6/4CLs2tRjKc9IlXjrCGzlsvRmGW5wIfATienkw2YF2Ncrdjp9ZkvrukPdrgaX0v9fTmj9p7Hd+9xeXqJoiYmIutlFLMxg909Tl+/YhGEao2s4X6ecFosSGqwaU7harqxoVaW5XTGDHnIvN3vMl4sKJ2npwykCc1ySX/YZ3o14bJtGRCU4u1uxotiQeIgi2Nq2lx+nDGZTrhsH853ej2Uq5nWDVkIJN0e8/mM/V6Xs9mcIjSEOjAH3tvtczqfoKpAHqfUCkxoyHt9xteXjFradyeN6RrFuKzI0MR5h0VZMOj1GC+XVNWCRS3ndH9/j/F8jK4VeRTh4wRTzukMBlycXTBtdV86stzupVwsanRV0ukNKOoFSd7FVZ75csKs9jik4mU+m1KVNTmKuNthPJsx3Mm5mC4ofZDcOvBf/A//5e/9Hga4f3gr/Kf//n9MGiAxmtJ5Uq3R3ZR6smCEiBAfWBF6jhqpwnBaJm1pFrGsHJWXbq3KwEMFL7xUgqRaUbR9UEyeUM5LxkgcO7ISbM+clI56I9/nxBqaEKhrT42IJe+otomcF6+JAjkOk0KxbNMGSFlnhPijrLwulGnv8db0at4+yPa0+E/41oOiVK2rpxX/kjLIOedGqm+uXWvD3k6GE0QE2pQCjBolLEgZRKCZKNlmqkBbhW8CTRCRqzHSs+bCC1BAtQ3dgBBL+miGAIW9Vn08dq2baBsWTTterpF9Bi36lGt5LKO1+KT0laR16qWwHnWAgZGxv2p1RsGuyooVyiqawjNtj+lhJPsut84/AWhNyhZBPvff/6//Iy/OX30rjv5BMB6CHTwERcBL7XNQtPiQsEXRw9aMOqz+IfPdEHTLhsidtdYUrEDLaubsDR6Z6Yu/RcuatIyG9m9U0gda91EvU+6WKdgOomLKqfBOEZSki1S4me6gPRPpFeOo63oNPFbN21CsA/UqlaSUxbQuotZaIhsRJzFJnBDH8SYVY4wwMNq3qwACr81a8yLOp8Lo6HZsrTaEFphBCxhQrf+GJ3iFd1tMSPt/SdfQjv2KkRBGR+QeLZDYEv+uNxBCqwPZqhC6cU+ElYx1zXQotWVAFtb/e2P5foC0d46qmNHdGTCfXDAc7jMezylmU5LEcLh/h+vJgqVLcMUVNDWxiamWnhAqXr4a4eo53bzLwbDPxXlJMZ8zL2f0ej3m00uG+3tMx2NGiwJjFbu7ByxnBSFAWU4pi4I4TZgvxqBgdDmiWi5Jk4SDwT6nVxcU0ylVvcSkKWVVoCuZyZ69fs0swNBaYhqWPjCtGq4bRWotuinZTSIuFhXOlwQt/R2KBuZNTeECSxNROseehUopXo6uWQSpkNixmnEdGNUNk0aRWsO0ajjeSbiYlvjllFrDrY7GFYFFU6EaxwxFqWCnKUDB0+sxixDoR5pebrGLmmlZM6sDNo6Z1xV39zu8vqyYXlyx0HCQGarKUzvH3CumGGpjsFVFpDUvr8dUjSONFId5wmhR0CwLlqXDpAmLquKkm3KxcEzOLpiFwF6kiIJhGmBcNkzqmixOKYsF+2nMxXhKVTcYqznMRBy7KJYsnMNHEZXz9JzDKLgcz6mRh3imxcjp+1oCUkJaaEUSAocDw/m1Q08XLJQErTzIjNsFmGpFFQIHOVSV4mpZU0fy9R5YoBE9hUP8N5Y+sDeE0TUky5J561K65zdW8cs2wA0jCZazpZPgr8SnI2paAzEF45aNGA5hMhaBad0qdPeMiJhpA+20hNyCzWE5AZWKFiGxkr4pGhFYjjWEBnaHsJyCbsCnovPYTcQJtGnzYuPW3n1nCOOR/FxYYUD2lACO2MDSCAOz34OigqYI6ByaArqJ7GO1/2l7TnsHMLpsuz+3pjUHptVvtJUqV42kX9Aino1S0cF0YkmfLJxU40wQ4DfYhfE1pBXUiZzngZGy4xoBS1dImXCWw/U0kNhA0YKtoYNpLdel0qIR6ecwX8qYq1iAV26/+0n8A9F4BFTb40PSHPKfzJ09jfI4Je2TmxZ1Nj6068oYSLf20QaUFf8Dk6BNhNZWZtimnXUbjTLmW1bb6jpsu67el2ZnarXqm+JUvSrDNQZjN7qQjYCyxSvrGf3Gs6MsS8qypK4qvHOi7zCm1X6oNctho4gkSUiTlDTLSNOMJE1IkoQkToT1WOlVtKxGGawyYju/XtXGr2SlJdGib1mtpgUehJUo1hGcIzjfanAExAikUjdEtUqrtUBX6W0xa8tctH4brQ+p4Ms3dBqqzcGotbtsQOltALL5nawepTywev39L0pBEiX86Cd/QJb3uDo7o6rAZB18knP6+mvKcoZVkOR9bt19j5P77zKdzXEenA8oY6jqmvPXr9AeVBSjdczbj9+n2+syubiApkHrhMjEXJ6/ZL4cgzZESc5wcMCD+w8pqwXlfE7TeLQWAP/s6hSLwwWH1oZHJ3foZinVdEzjnGgVjOXKeUZtrwivAom1PB52iRvPYl6QB0+qAqk1fF3JdzFWAa/gwWCH/SiimCzwwZMH6BvNUmnOKt+6UAaMUrw96JERWMyWZN6TERgkMc/mnokLJAj1cqu/w91eh8WsYNk0RD6QKY1XlieLWtrIGwNB8c7hPkOjOT2f0gSPwdO3lpdLz3UTSLRQ04NOzsO9XXRZ4suCpGnEzVJHPFkUeLmlMQHeunXCbhxzdTEiOI/xno7RXDbwqm7ICCSxIY8TfnR8gmoc4/EMU9cYAqmNeb4sqVrgrY3l/u4uB2nGfLmgVtIULaI1Q2vp7+9rcW20uJsrch9YTsTyMkY0C2dBgj5BAs9erESHMAuYJmCVaBAArmuZTNRa1jtWjK38WAKnbUHMuJHZvEXYjNTAsZFArwphq3Qt37HrhrURYo00TEsAfyVjaAKoUsZxWUnmvfYiiB0asDXE09ZldSk9XSat94ZvY0sP0TKEkTAjIJ+tvFTB4OQaNa7Vpnhg1Dpu12BqSfusnDxr5LwHGvykFdyadpsBJiXQXvfGw76Rv6su2+djK/KYt0LYlcGf9sKS6AKistXnFDJdH1dtCikIuNrVwmi4kYyTDkApaZZZw7qUWytp1qdrMHO57qYVrI4aOUYfhGHqWuhqqGai6dBext6q1sfjO5YfBvBY8+Xr4lg8be8RZEA8fONnF2TdmGQppNJcHFK0ssJ+SLc51Op1u137G+v2e2uvj28pA6VdV+JVtb1dtans+LaEbQjg254qa/fQptk0kzMbAaw2RliOKCKOYuI4JknkNY5jYhsRWdsCBtMKWvW6ud7Gj8RsVrWp0DEr0KENkbEtYGnPYfu6rMuEuVFN8uay0o6sxmVD9mxKj9fykG1xqrqpC1VrvBw2jIjayrCtP7v9ubD179/vErzi/Q//gJ//xS+YTQr27z7CmIqHbz/k1sEe5AfEaY/R1Yxub8Duccbnn3zF0ck+aZxgaPjHf/avE/DYJKKbdzm/uORP/7Wf8ukXH3N9PebkwQO0tuwd7vPwrfsopchsxGK5pHEFb//4Hh9//BuGSU5/uAs4PvzgvVahL0zaaDbl8TsPuJheMZnOODo8IIoMTZpycveOPJw01NozrmvuHB/w+eU1mTUMuhkzrdk9HIAx7CDfxbNFxXAnZ6bgsizJsw5Ka5ZGc3BrnzQEGqAkcFnWPLizy+dXY5SCbpaw1Ipsr09IEqGWFYyLijjLiHsZz68nDHZ36OYJc615+PghwXlixEvgbD7jRw9u8+XFiEXdcNQfEmmN6XXYGfbpIQ+6Re0IxnLr8JAvTl8TdTOyPGduDI8e3cewcqdUXBYLHj26w9l4zHW5YP9oj6A0VZpy+/59kiABoMJxPS956+Ed/ubZE1Jr6A4HlNZy7+FDdBwJDW0Mk6LkYNij0IarYsrRcIjXhkIrOjsxBkkRfJ8P5QD0cni9EHZXRVaAWCLPzmGQVMu10MmESDNtAjrSxFYxC5DnijwIk+EiGAUYpIrLtuIhxAatBIzEkTADAVhYSXt0OmJJrozCWsUC6XyaB2n8FizMDCTxZrxcrLBW/p0b2EfKZKNUSlkTu6pWAZPI54yGTptOMUYYBKXaABzEzyOz0n8mszBEjjfKZZvdSMBHpICk9RXRooPYU5KCqFofEWMFCDiriCPZZm6lD0puhJFZKhGhLp2AAx8rjBIWoqNhv00ThVhErFmrH9FGEcVqfZ790ApbI9FjxK0JWQT4SGGMHH9q4UBJyolYUiRZKr4hSimIlJQVWzFB20Wu2XTlD4LE3ziS41y0n5VeTt+tVfphAI8bAXoV3N7w5/i2FdjoNtaZFLa2tNn+9jC0P6rV+2tm4tvXb1ZMqNUONrP91T7Xx3MzWL957D5smaEFvyXaXAVvYTniKCaKI2E0Vuu60sVuiVT1Oq20BkKtN8oGROl12fDm9Q2gtSV6/cYYwJrB2QZi2xVESmnerLi5OYbtkG+PI1vXby0o5f8Dhvh+QAeA946Xz7+kKa/58Yd3yBLPTm+PO4cdbBSDX1AVF2gNZy+fcvHqlDSe8N6799DG8/jxfZQuSToDfAPLxQxXFzx98oplUfDo0V363YzIRjx+64SgPTpOKOoCmgXj8TXPv3qJcoF3PvwxhsCdo2M6/S6RiQhA6RzaeV6/OmU+nnJ4dMjg+BaNjrh/+xirxdPGe6Gog4P51RjlAgcnJxRJTjdLOR7skiqDRx42SYDprKQaz8i6XW7dv0tjDMdH+/SyZD1hcMjscHoxJ7jA3vEd6PUxccSdgz1SpaiRB2AETGYFy+sFKoo5uf+IIlju3DomT7I1HK0cGBc4vRihqpr942PSwQBtIx7evkUUSd+Yqt33siy5PL/ABcWD+4+obczB7pBOmqK0oQZKH7A+cHZ2RTmbs7d3wGD3CGUsj+7dwRqDV0q220BVNVxdTPHec/fttyBJGO4MONjpEVsjBlrOYb1ndDMTFcAAACAASURBVDVjPpmQZh2Gx/uAYjjo0496wirwfd7F8o20C5m97gxyXJ6iUNwdZOy2NvFlkLH0LmCmDdpodoYdRkGzF8GtjlRNaGTmnwYIywAO8k4CeUzdwFEm6ZQQJBDW7Wxej+U5MxwkTLRmYOCg04IWByMvaQRdC4ORpIa4Z1lUUqHRSYS5WCphM1Z+HAHIOyJk7QI7ucwf8SLsdHXbu6WBKIJOX3FdSYO1nnQnwHvx0TDI/l2ATiqW69ZLRUpq5P2xkn4rALqU+e+gp5g0il0Dg0yYDRUkZaIC+Eq2000h5IrQSDO2LJbfL5SkaqyWbaKg0xUB7UBJ2iO07MMo0M7QRTCcxJB05e93Y0nx+CBtDKZ163HSeogMBgljY+gq2O1JhYxCSosjD9RS1qyMJutFLJxiaOS4fZCU4Xchjx8G8KCl7BXr3P0qBr3Zd2UTxDf0/oolaf9gMzPnu77EN9MgbAVT1nT+lseEUutguT0z34CfbUC0KTddg6iwkaRsZv4b0LRWasI6vRJFouVYsRtRZLGRxbSajhUjorZKaFcpmlXVywpMmDZdpNt0k7zqdVpkJeRdb2u9Tf0NEHHDh2MF3LbTSnDj998G6lBbY39jNP//u1xfTzHW8vT1nNPTObfv3ecXf/W3KGPFD6PTIYkz6qrm/PQMozJ+8+uvsViUsvz6Fx/R29lBqUB3d4iyCVdXI/AN49GYFy9OuX1ywicffUYxlbLENE0Z7PRxjef8/II0tjz95HPqsqS/0+HnP/sFO8MBSil2so4E19kC29RU8zmvnz/jpN/j6nrCxWhEFFn2I0NmtDzcipJMw+TijHJxxWCnw8+/fMpOp4PRcCvTNCg6ePKmwZYFL59/zU5iWdQVXz0/J00ShpGiEykwkDQVqQosri6YXI04GPb51VfPiaMEg+IwtQSliPH4+YwkeE6//pxUeYwxfPzF5/R6XXKt2EstVit0WROHwHIyZnTxnDsHQz5/8ZpmUaO15jDWxFajVUAt5nS14uLFE0K5YNjr8evPv6LX6xGh6EcxSmlsVWLqhno249XLJxzt9rgcjRiNRkRxRNdGdNIYayLK2YSu1Zw/e0E5HnM02OEXH31MnmQoYJBmxFGEqWpUUWDrmmfPXpFYS+Mcp+MrvNXSofR7vIcVEuByBYt5gS9m7PYVH10sqY3FGzjK5bMx0pI+ITCZz+loR23hi5EnzhQ2kVSIU7K9HQXzsqYpCrpdeLGAuTdgFXupMAUK0RJEBMaziiQ4fApfjiBOgQQO2tbvkZbPFo1nORdr9QsnTqMqEuOtSLWMgxIwcV1JL5oihmdTcS71qTAEaNEuZFoYhdlcbMhHAS4WwpSYVPZZt8+52MC0QXaSwrNF6xIaS0da2nNKW1bneumJTGBq4MVcthliGRuPAO7UiHizmXtsCqelpDaIxL3VagE2iZIKl8kiEIXAMoanEzlGnwg71BaEkraVQMtFEBv0RvxFTCIGYakWMW+ipMLmelER+YaQwpMR2EzGaU/shUi0XNMmBKbTmtgGFlo8Q4ISbcl3Pc5/EOLSrSnwjSWEDX0evjEF3orUv/WtFfpYAZNv7pa2I26rcGWFOsImgm7YjjZY/rZCoE3Z6RZY2n5dAQu+0fdWdhtWgVljrJUmWN5vPEq02bAdtvUZWZXkrjZzg31YiVM1Wm/SJMEI07I6Vh8CqnVlXb1uDmsDJlbnzzbIWL2HWpcor957k8VZI7rvWP7ViY41Wv1eF6PlvPKdAeX1Nf3+gI9+8TN0EvP08y/JOrsMdjs0paOX7zGZzOh3cyrvKcopX3w2Jo5jLl+/YHewR5ynGJVQVks6+Q5lU7OT5Tx58gXOwWwyo5Pm9DpdvKs52ttnsShIsw7T5YxA4DeffkYeHJcvX7DX65MnCVYrYq2pi4JKyQN5enXFxHv2TKDjIMpz4qbCKoMvPdoqzqqKXWt5dXZOGuDq4oJMa3JjcJEjji2udtTB4YkxiyXT+ZJBC6x9HpF7J2DWQ5ZHXJUFfZtwdnYus87zc3aMIc8SLAWxTajLGp0Y5o3DVzWvXj6nQ6AoCpI0JYo0HSoSY6itYepqdmzE6elrSicTuD6aJEugaQhENFWDSSyjRUOE5rOnX9EJhvH5Gd0kIU8z4maJVYbG1RTekRNzcT5iTmBPKxIHyU4foz1xVeCahjSNuCpLchPx6bMn4OH89BXdJKbb6VBUc6JgaOZLKiPVdlVZ4ZYFBqGoHd/zbFC1Ab5RXDeO3QDzsZfqibIUEywHXR1QiUF7T1MHKILoNZBZv6oCXrcaAKUIibAUk8bTbcTRM45AB4cNosXo6TbAxkAFvhFd0FUN/RhCIwxFrqU6JMQK007iLKJvsEYARl0Ke5FbCeI+2zAakRczrkErLtVOHEmVE8DiI9FqREAoRcuSp1vbNNIRVmWiHSFIue603LAtOAniViMuDxHQ9mMxbeVUL5FxMFZEs5WHsDpOL8G9KKQ3jtKis1DIOZaAS2X/FgFTCycsimvZk7wdM1LRsthGjl9Xkq7KIihLeQYkRqp0yIASXONJjaRdeqkIWmkEwHgNqmVgVC2utVUlYDCJxJjM/g7G4wcCPNiqbWiXsPXa4oEQ4Jt2aOFGZcRmewEV2qC0lcb5xl5VaLcgx+C1R3lNUOIBsrEs++6c1Qp0rFNAfPNVtcgjqJsISbUAKKjQsh2aSFmU0XKzrVIaRrdmZ7ZNleiNi+obaGgDAHQrMNRrNslg5Hja81uVEAcvlTBroLQ6c7USxuq1YFSLzex6/4ot59kVO6RWwLFVaqwQnro5mjdG41uQR/jGD9tnuWHHNjfJ73/xIVAs5/TSnN39XSJraELF8eEDpqOXLOs5r75+jbUJmobKBfLeIXlieTq5JEosJ7eO+OLLL5hNoRxdkqYpZbkgSzscHR6Q5j1evHzOwe4edeNYLJbM53MBnxaqomQ4PMb2Mq7HY6JGcefwhE9fvsQXBRetY2ldFJgQOIg6pPkO49GYvdhijGJUV5jpkloHjDV458k9HHRzdFPTeDiMY55VDTYEvprVGGtwRYPygeNORKxg7EVQF2UxLxYV+bLhMogQs248WfDs5xkmeK5KuJNFvKykH9PV9QJlNcFV+MZxspMTJRnzcoQKgW4n4utpSaeoeFp4kshSVxWxVux3M6yJuJwtOTSGOVoqSaYlXgWUNrjGs5tqDgY5s9kMUyv2exFfTgNR03A1nZDGlqousAGOsx5RljIaz9nLMoyBq9mSxWRCrRRRpKnKmt0k42jYoyhK3BLuDXOej5fYxvPi4hKbSHm1Cp6B7ZCnXRbTuQgubcS8qX8AEBouKrAh0I8s3kmP9t2gOQ/Sh+V1LcHKlx4TAjGKXqSgEt1NqBTjRnItX2sRH09KqdTYsYbgJLXcd4qpk07Ay0qCaxNgWslnu1aLOywQ1Yqpk20+bz0qZkXAtiW6oUHuDS/uoo2H4MUbRSlYLqWqo2sUuEAcRDQ5bcu3yzZt4Ut5hMQISLBBdBiLQvQcWos/h1MwK+Q4e0bhahEJZ434YYh/jOy7ahumJUEcUVUI5EjpaeVkP2ctM3LdHmduFE0l/lBpA/NGWA5VSghslIAJ0+5fu0AGUIpGBAWXbVnwvNgAmdCCj54TC/gmSPpItyzKtBBg1rcaVXtx3K0FlDjgZZuScZV4jVilCF4RBb/uAK3YTp1/+/I7wbVS6n9SSp0ppX699d5/rpR6oZT6Zbv+u1u/+6dKqc+VUp8opf6dv8+N/o14FLaOfMUY+NV0fZWaCFst17kRlNQ6r7EFBt4MzFvpFL2li9DbGgW9Yg42f3AjXSBbv8l0tPtb+1Csz2UrJbQ6vHX8XWklVhoLg7URcdxWrSSb6pU4irE2WqdbtDFvHM+Na9dqPsyNtIoxrSNqZG+6o65EqqvUi5bUzMo6fv2z2bKS1xudyJsOr5ott9eV/mPd9VdOPrQS9fXl5psr6yFsYUx7o6yZlhUsXIGPb7vH/qHvY23RVnP34T2iOOerr5/z4U/fYjZ+RtOUZN0uNkkxOqKpGx7cP2ZRLJlOJoTgOD7Z53oyRquIrNtBa3FDdd7x9vtvEULg888/4t1HjymqkuBqrI3EBt0K4Do83kdHEQHNbDbn/lv3uViUWCA2mg6BJIpwzvGTP/yABs2ri3MO9g9wcUapU6xS5AQGRpFozU6ecnLnFi7N+XJRcuvomJFOSJQmVZIr37WG4AMf3j9mqWLOgiZ0c/JBnzKkxBqxwNaKPDJEWvP43n1s3uWLacndkyOuQ0yiLJZAD+hHlhACDx/ex+uIeeOYK83e4RFTlZEqiIKiq2SbwQU+eO8diHO+Hs84OTqiiFKUiYkV9ALsGNEoHO/v0en1qWzCRdHw4ME9xiElVooO0COwExmcD/zk/Xeo0Dy/mnB4dICPIhofEWtN1xq6Vmywe70OB7duodKUF1fXvH3/bUZNhFWaWBtiBamN8N7z4buPCVZxvZiRpAmq14UoYtVJ/LdNcH5fz+IIuNU1+DjipZcuvhOlSVC4IKWvuwpcCBxmmihSjI3hEkVsLdOg8EhQ3m8Nv5SHky7UsWEUIFjDXEk5fx2g5+GA1nHUCgOxiA0jBbG1TAKtqaN0UO0rwMF+AqVRzBGhcaE21Smxhz0kUEZBnEwLqxgrEZNOW2ARAnScCEK9h70IglEUSlFaRaMVTftsirx0r820/DxMoLayf2sVM1pviyAN5naVAIs9C9YoSq2Ya6DVM5n2nIZOBKQ4KdmtjGidMG0b+tAKOZ1s0yIlr6mVPjNzLazrohWRqiC9c/oGgoO9VLxWChTOKhZBcjsuiBHZvpexT4FhDEVsGGmIjOI6tBVHQXq3HFgBMocZKKOZKs1iZdvQ3j8+/Pb7GP5+jMc/A/474H9+4/3/JoTwX924aZV6H/gPgA+AE+D/UEq9E0L4nRViGwXFG8sKb6wAiQrf+Ixarxs9QXttBYT81hFQ3/yXBrzkgoMKG+bg246NrQAZVjPvVYIhbOKgUBprcPANncRKV9JqPhShdSHdSvGs/u4GONLrY9o+ju1TW4/H2uBrA7ZW4tYbZmneo9cMyGbs1vqRlvF4U0AK3Gzyp2nPZWvUVj+uczdvjqRag7KbiZrftvwrpVn+Gf+A97HWim53h+n1BZeXE+7ePeHFszGT0QhjEu4/2mPRiVC2g00M1y+fkqaW8WjB7u5tXj57RbGYMtw/ZO9wnzSL6GZdet2Y0fkFk+mcw71DrqdTJtMJIQQe3L5PUI5Qe3p5wvnlFSFJGF9ccOfkNqdPX3A9m5N3OhwdHlLNFxij2ct7jJ6dUnhHL4ow3jNZzPFNw9Ful1QbirJmt5MwmxQURcX8esKjvV1m4zFXiyXWKI56FuUiahyPe7sisETRcTVZGnM6nVPXDf1ccZCkzJ1Cm0DkNReTGYvJlMe7febjGeeLOVor7g1SOt4yQdHvDykuRvg0wc+mHHR7nF1eUFQVeRqz10spKohi2Ikzrl9dMJlNudPtEJYF50sxWLvdseQ6oSBw0EmYTRY0nS6LyYj7B0POzs4YzZbEecywl9OUclfd3c15/eqc0jt2I4tuaq5mM5xzHO326RpN2XjyPGM2WbCcV4xG5zy8dczZxUtG0ymRjTk+OKBTFYSgOBwMOX91Dlphy5JON+fsaoxqbcZj2nTD93APg3yjdgwsC89SLXkYK2pVMcWjlQTFJCjmIXCnE9MsaxYhkAfPIIZZ7SiQfju9XPqQKK84SZRsM1QcafB4rkOgURIcYyUVLfux0PrzAKap2dewdI5aBykfzSTlUQW4nUnjNec9fSSIz4L0UenptjlbJQHd67bEU3sGSKrCGwEou60Z2qyBo1TSKI0Tk7M0tJ+NxFI9T6Sk1XpxZV3WUAfZf+OlYV2pYNiiyEUNB6kIZ0sfyEMg8bBA3EMTBzuZbEd5OMyFCXEh0Gkfvwsl59QPYGNhWgaJjMG8FnF1B7Fk963Z2SAR91JXw2G6asoY6GpJeS2BKpIUUR5JSqXbVt4sGvC+5lBBQWDZju1+ex7zGm5liqYM1MGRKzBKUfpAHaR8OP0dlMbvZDxCCP+CttHd32P594D/JYRQhhC+Aj4H/vR3/tUqvv5WhBDW9tqqjebreW77t1L22qYEYB3UN5F5Izhdb2ET17e0CxvmZVsUudF9vHGMa+3JRljaRtw3hJSbypJ16e2K4WhTKNq0rIONiKxUskRRWy5r7RbLsaliWU30bwpb19F7CxxsRKZ2tY8owtrVuukJs1k3PW3eZITebLS37hGjpezum9qYmyLTm6mW/5e6N/u17cjSvX4Rs1/92s3Z3Wl8Op+0nXZmVmVVXVEI7r+AQAgJiZeSCtGIF3TFCxISEi8g3hDoXsQzEhISAp4Qr8CtutVk2mWnm2P79Lvfq599RPAw5mr28bGzKqsy7Tut5bXPamLGjDnXjC++8Y1vbGQm4dbnalNEDKvzujyDm5BjJXL9tivot3wd27pCWZ9uu8vh4S2GNw4YT2bsH9zB6IRPP/2QKIkpZlc8/dUXdDo73LxznwcP32U+X9DvdQnihMuLK149fcLuzjZPn35NPqvptHocHd7k5uEdzs/PONw/wneKpy+fgDJoDz77+hmJ3+Zw9wYHh7ewRY1SHt12m8ViwefPXxBvDbmYTDgZj0AHPNo/5O7RLc4uL9gZDtDAq6s589rRaic8OxnhTMV2krA13KLla0xtOOp1CYzj8biibiVUTvPs/BIPxZ3tPgf7N5hOF+x2Ovhac5E6XuaWpBVzNs4oi4K+HzAYDhi0EhZpzs3hFqF1fH2VsYhirIKnp2copbm93Wdvb49pOqfbbtEKQ+Z5yYtJRqvf5mKUMppM0Wh2ez12Bn0uxlNubg3pAC8WNXPlEUcRT09GGGvZ67TZ6g8hr1BW0U8SirTk6/MZYa/PtMi5mk4IUNze3eFob5/p5ZjD4RAfOLmaMClr4iThyctTLIrdToeD3T2iMCCva25s71DXJV++ekHS61LVBS9OzlHKZ3+4xe7uDUajKf1ODFoKkn1XOu3v4l5skUkwsI6gAqxjlju2k4TAwHEB51ZW/KezkqqpLOw5mZRU7NFWYuT4MpWDKY3jMrfohoWwFua1o9cOhfI3InYMPbhowiTd5n5gjaSEdpQiVHCaCzCzFi4yYQIS1fTbQpho2o2Hxnkut6Jx1VTTbdYpzsrE29US/riqRB+hPbjMpO2k+WxuwYTQKuVWdtmA0qkVALBMq7ZOGJR2oOhYEZxelbJgPssk7bWFHFvloA6FkfAUnGcSosgtjNJGB9IwHAsruolWLeN0nklY5LKAupJ+qoapST0xQguB80KAR61glMuJjZpxy5yIajuV6ErOG53HuJRx6tDMsxZSpRmGHrGDs1xYGN+Hk1SsLmIrjIoxjjB0UssFGf/v2v4+Go//WCn17wF/AfynzrkRcAT8843PvGhe+8amlPpT4E8BbvS3rk0o17eG7lButShWbjn/b2oLNkh3tV55S3uNcHJTTaA2J7GNTSuwov1Qyr1hktzsmbs+6W9kryzR1JKlwK3BkF6Gd66FIDY4HwVojdKeAJ5fq1tYTtZLZ9J1+GdTAOqcYnlbE3vdDTtyo7HWoJTCGotyVtxMV0cj/RJPE64BkCVIQ8PSXVSp17Qb106tWp2va8cAK6CxAnFvYDQUoofh2liLhua7SjF/y/YbX8eb1/Cwv8VsMeXLL0oqX+G/eM7u3j4Xp8dsDTosFoovv3zF7aMbDHfg7OQJx6cvaEUBrqrRQRtrLP1ul7o2/PIXv+D3fvx7fPz5pzz9+ktULemzW/0B06tLonYbVxtOX53T7Xa5fXDIy9NXXP3lMUnUIrMVW4M2p5cpg26Hqij4+NNPeefuPV4ev+Tl2UuuRifgRbTaEWaR4oceEZBOZyxyn0c3hvzqYkT29Dn4Pk4r2oHH1SIljiEsFc9OL3lra0C3KnkxnxFnc3QY4imFyTOscnR9cEXOF+clP9oZ8PhyxPPjYzzP48r36CcRo9mUqBUSlDUvzi/Y7Q/YbUW8mk6YTie4KERZS9v3uDKGbujjWctnz4/5YG+bL6+ueHl+SqQU51FIO9Jk0xkqgI5RTOYz8iTgqB/zdFZQPH+C1j6Fc7RCj0le0Y8VtnI8fvaUB7du8uL0FS+vLriajXB+SNSNKbIFfqAJ8JjPF8zKkpt3D3j2/JTFF5/ieRG1smwlfU4nI9pxDMbyxddPuHfzFovqjOPJJefjS4IwRFlDNc+obBOjV01U+Xd0Db9+HW91eqRaRJexEhfLxDrmaYFRjZ22EbekwwC+rGDowPkyAYe5YaLk/bYSi+594NiDs1p8UiYxtEuoskrqmTTARSG26V/WTSE4HxY+RE29FIMINmsFN4CRD8e1hBwWIXRrUIVl5gm4iBTgSbjlFRKm8DXMI2hXMtE7r9m3kgnXDwQEtRxUoYRgghIZEysreRfAfg2vfHEJ9RXMY+gUUFVuZfUeKikZn3jwqoaOFV8TT0FcSZE6Y6RN5cGWhStPUoADBVks4MBVUs7eNPv3lLA0x6apF+ODi6FVSIjG+U29Gi0AbhYK+AqcOKB2akkFLnwBdokCfNit4DnrGjfTADqVJUdRKjnOCgm1KQ9OG7t8G0i4xlRQaFCmSVP+ju03FVD/D8B94KfAMfDf/l0bcM79M+fcz51zP++3OuswCbA5XW32fwUBNibTlaCRjUn2WwMj3769vu83T5hN39kQzrhvhgRW2pEmxKFXlW7F2dRbenD4G3qL5nU/8BuWI+D16rQr9qFpe9WtDaZlzR4se3Wd8VizHk1FXn9j/9f0HUtNh7eycH/9ecnWbKbnLtN6X2c83hRx+eaYbhzDGlX8Nre/13W8eQ0ncYvAc9x/eI9e0ibxe5ycnGLrgsloIimfpmA2yzGlpT/Y49b+DZQTK++TC7FRr4oCrRWhjhlfnaKV4d79e4SdFrEXcTm+whYldTrH05pQK0yWki4uaXe7HNx/i8LVRFpzfjrC1oa6KvEDny6KdD6hKg2Ht27j+zGxdizSgnlaUJQGhdyww9pyMstxfshwdxeUCPMuFzkYQ1oIfT1QkBYFae0Y7OwQBAltDZUzXGYFzsh59DW0rGOcpRg0Nw73cVrT8zXni1ScfNMKpbQYbtUVuTEMBgP6W0MiwHeWq+kCGhddpzVd4CorySvH/sEepadpa8WkMLiqxlbgIVoQCsNVVhHECVG3h1KQaMUoLfCspSwcytMMlWJ+NcJWlv29PbTySZRiPs8o01zKIaAIlCKpLaOrOcrzOdo7xDpDqH1ejC+gtmRlhfI8EqXJ0gXOeuzvHRC1eoAiCKUeyrJGS6T+zpf9P+i9OIlbwiKE0o9hKH4UnrOr0HEXcQYd1RAHYmnf8iQ7Y24dQQMOPAVRLR4T1jZZHE2bUw3KSgE0mtTMshQRZdIYekVaMi8WNFkSyDXXtiIKdUayXYwT/44pwib4zf4TLSLI0knqreevNSRTJ3OHcZJy2nayb2skw6RS4jFSaQFPS+Gr1pIVsrDCLES+rN57gdRE0U6AY6kbkFRJP1uN5Xu/WeqnVsbHODl+rxbWxW8YjtpJnZl5w6gsme1IS9ikbNqsNbQ90VWkTf+MkWOKrLid+lYyY2rEkySjOW4ESAQaXCHHGapmnJD2Rw481ovJgZOxLw20AwkrtXyoPGkrbM5T+Guu49+I8XDOnS7/Vkr9j8D/2fzzJXBr46M3m9e+c1uChmuTlFpWPN0Mq7g1i7Ci7q+HRFbN0NBFf4sf8hpyKF7XFlwTg26sxtehleXn2ABEGq3kxugAvWIfNkIVq1osYmOumiq4qnFJbYqdvIFRWbMbgBR3a/pmN0ITK7ZgyexsMAzXWRhhORzXD8QphbLqOgB4A+Ox7LcAHLdGh6tsoY0vv7bJJ9Ygzm081kLd17/TNOXWjNVvClL+Ia9j5yzd3oDz01Pm4ys8Ld4d7fYQHXqML87wPZ/x9IpuoEn6R5xMLrCFpGL6yqcz3CJPU+aLKYkfcHp5Qb/XZ3o5Yj6fEesA3yn82Kcd97kaj7CIhXftArZ3t7g6u6CsSmqt8ZRP3E2obc14saDraUbjCZ1uC1NU5HmGU57UIdKOYafHdD5nah1Dz5JVJVuDPlU2p3KWWS3KfS8K8T3FZVrQVmDzAj8UYWhhChalo3YyAUXthLyQYm9b2jHJKwa9Dul8Tm5qdClqeB0G+FHE1WyOUhDnKQQBrVaLyeUlppICkB7Q6naoyopxUdBTkC5SBt02RZZTG0tRlOJm6WnCJGC6KMitY+grcqfoRAGuyklrI1U4HegkxjnHKC/oKijzjKSTrIou2roSJsJTtJMu48WC2lmGymKLjN3hFpeTGYvaEDqHxhHGMbHvczmfEWjN2WxGEoZgDVWxQAElVqh6X1aK00Yc+H1cwyA/I+3JH9ZBmjYUPaB80SzEXuPW2ay+21Z0F6GWibqwcvtaWLEpzx2NOlEmUTOTSdk27E5tZALVWlbMKNEh1JWEZnzBjKAkfNDTYmJmG5Gjr6BeyKRcOWE7lJPPRp5M3trJRFxbUE3YpK4FENVKAI1pUl+da9iBhbAuhdekqCKhiZ4vYQ+rhEWpHLjGNrxEjskYOebaCQuhGgCRZ1I7xekmJVfJeMVaQiAWOXYFkDb2407Ai1MCjPAkrISRc1MVotOwugE6TvrZ0QKAlJZx8pBjCrSMd904ydZImCtFdC9BLeMU5c3YGulnappUYgfWlzklUY4yEwakbsJoymucZ7/jOvuNGA+l1MHGP/8NYKmy/t+Bf0cpFSml7gIPgT//W7a68dd1KLAJJpbV3jVLxkNdYwDeqFv8O+39uza3RB/XAMi6EbUGH0t2YZlNsmQ6Vs/XH0vdxdIe/RssxDWH0etZLEswcv2xDnWsQjxLC3Vv7WC69ALxrjEYbzYb26wyq72lOZlapVZL4wAAIABJREFUP2v9muiUjb5+9wivQceS9dh85/W//mG2f8jr2DlIWi3OLs7xfZ8fffAz+p0+D96+xYN7R6A9PDSmdARhhLUTsskZ7z56l72tHZJWwr/+j/+YVhiKN4E1VKZm2OtyenmJMo7f/+Cn9DoJO7s3eO/RIxLV1IKorQByT3M5m7B3cMDh0QFhv8cf/at/RKx9IidgM7OGTjvmcjbFGMsfvPdjekmLTq/P77//AS3toZHVSwmEUczLeUan2+berSPiTpsfP7hPN2rRbY49dZYk8BgXJWVtuf/WbTpJgh+3+MMf/5jYyWSaA7lztJOIl7MF2vd5eP8t4labt966zcH29oZI0KKVpjSGWZ5z+85Nhv0uOkn449/7fSInJcC1gqmztJOI4/kCgEf37hLFEYOdIQ+ODukh186iFi8dqxQX84Kd7QEHO0OCXoc/fO8dWp5HB5mAUmeJo4Dz+YLaOt790SPaUUTQ7vCzRw9oK1nVVTgq40jimNP5lG63xzt3H9Dt9nnvg/cZDgZCpTuoa0Mv8pnXNYU13L5zCx1EGN/n4dEeAbKK/rVK/N/SNbzcQi0CwkRrkoG4he32fPYCjx1gbqWQmW3GvzLQ7YboQGMs3N8S/UIM5FoYi8gTRiFQEG/FKCUr+8O2WJGbZjI0DfCqLbRiDy/xUBZuDqHjJJsl88WV1EMm2NBBeytAOwkRHHUlBVb5EqIom2OqLLQCBYk4q95oi8HZECniVin5HddOfldtqQyANnCzB31kIi51wxQo2X9Lg+5rNOINshWKvXjZHNNS7qAdtLsaHSi0hYNBY5muxJ69bNqsnNhphAPpR8uHYQsGyAXiGpYIGiYpARVLls2NtoSeehqKQMCRr2Q8E6A1VM1iWMa+30wSld8wQ0rGqRNo/E4ADm70hdncAuZKxK5+A1yshU7Pk+rECvYGIpjt/BpK49cyHkqp/xn4x8COUuoF8F8A/1gp9VPk9/wE+PcBnHMfK6X+F+ATBEj9R3+bjJY37vcbj43/lLpuVnUtTLOc4twb+Itv2VaMxpscSK+zDK9bti9DGU41q3ulwFOS6rt6n5WOYxM46AagLIuyKb0UjOrVxaqafSml1lknel0dd+MQvl0RsSSSNl1ImyCcdhqnHcqui65p7bBWr/Qarrk4r2XjvPZYDvxy1P+22zoHiDeGrf5O23fs+rd9HTsHpkhRrub9n/0Rv/zrX7K9c4jWjqdfPwNlKE1BGPdYpHP623dph2MCpRhNxzx8+xH/7//zzymsbeoRKZQxlGVJ4Ifcv3ePjx9/ivI9+v0eH37xOWmz35avKaqSRGli5XH74IB/8dFH3Ll9h48++oTcOSocnjX4QF1ZhihaN2/y5PQVuefx9uE+f/Y3HzHHybVnHDWGRHtEaO7euc1ff/IZu1vbvBpPGFUVKXKjalsoK8eOp8j7A6Z1zbi2PDg85M8+/pRMKWpkxekr0EYRA2/fv8eHT5/SSdoUxnJyNWaExNwTIyvWIx2QtlrErYSvXr7iwZ3b/H8ffUTq+dRUQlU7hzYygezduc2vTk8wvqbV7fD4xSljpC5HZKEwji0LC60Z9AZ88vQpd27s8dGTZ0ytKPgjK5OcLWr61hLv7/Hk7JxSaW5ubfHnnz0mVZIV5mvI6xpVWjwU7zy4x1/9zSfs7R9wcn7OKE0pHSgko2GRV7Rjn2DQJ6sq8rpmb6vHs5MRtZL7xrfdlH8X92KFVHgNgKQb8GKR0woVpRH9QqFlLP1Snret48LT1J7mvLZsteBiKsyBQlbmsRNNRwz4LZ+TeSk1U7QINCstTqFBA0x6FYy0QsUBx/OCfgzTmazGjZPwQdRYsScWTMtjVFhq3YSGUpnwS0BVojXpVjJpei3FSWrpBuIXopR8NjUQG2FzugbmoWJWw9w4hiGMFgKOjJasG9+Jv0WtIGgpjheORIvmQxs5ptRKwbzEEyA29xW1hknlaIcwnss41UgmS+gkNBUCKoFzwdEESBiq0vKb8CsBUi0LCyX1X64yRxKKiZmvBZjNK2FkIteIQBPFqCki1w1k7MsGmLmySc8tJWTldwKeL0qGofh9aBTGk6yV2EBkHR0H81CzMIraOjq+nCenGsbnu66zXy9c/O1vjw7vuP/+T/+ztS6gyYxYVoJVq9X0soaIXqWbarUBOjYFmstNWSlTz7Kk+sZn1WaYpQlXWKmdYoyRR22kmFtVURtDXdVYK+/Z5cPa614hzUwth7IJNNbgA7gWblkZdDUhDNu0Z63UAZG/r6e9mmbfpq6pjcHU9brfxlzr0zKFdhN8OJo2jb32PTk+i7WmOZx1G98OPJQs65rxXoaiVtu1aMgG2GDzI27js6/97SSUZBvH1WuGbSuGR/7+r//v/+MvnXM//7tcg3/f7WD30P3Jv/sfEMZdtI7pD4bURcrlxSlbW1ucnZ9y884t5rOK8cUxTvkc7u6gdU2WF3J9VzUaxyLPuXljn6fHL4mcIvAVOvDp9wdkZc7FZMbuYMDl1SXDrS0UmvPzczzPo9Nu4fs+zvOprWExS+kmEZPZlLf2b/Dy7ILIWQlntGN6/R5X05xpljPwAuZlRpTEtL2Qy/EVnq/Robjoxp5P6kfMFyNuxB1OpnMe7PU5vpoR1pbaQpD4tKOYcVmzQNGzhgoJkw7jiOeTBV1fYT2Fh2a732daG05GE272ehxPxtzc6jNdVFRlCbam00sIgoiirMi0jyorIq2YFzlHvTYvRjO6Sq4/rRXtTsK0dkwWGTeiiHFeMOwIRzwrDV2lqHxQSkSweRiSzadshQkXec79QY+nkxkBGuMcYewx7Pa4WmTMq5J+HDBOS3qtkBif89mUWGtUu43nNGEcU3seo8sLtgcDzs8vuH10yMXVGSavxRAr9iCMKbOMhXPEtaVSkBtLAvzn//S/+p1fwwBHuwfun/xbf0LLk/BG24OJD/MCbsaaUWkZNC6btVl7RiDO5xwjE2IvEMfQAx9eFmKtHniSqtnyhDFZVHAQN4ZhjU5hbERvoZrwRwwcK3Hd3EvgvIQ9Dy4qWcH7CEMQBhKqmNSwF8rEVyuxIj9rPhtoYTVaSD9dBUdtqeTaboBCsAzdOAFGDji1MNTCcKXAroZXpYhRA0/CPm0NF07CN4ctaTPUgBUGIaRhoLWQFSdOwG0vhGkN254cW4KwNsbK/iYI2NhrSWowel3Rd5nR4pD2XyGAfRjL+1saLmtIGiaoNjLOCyehkBuRMBaVEublzIgY1VOi3Wh7cIrUm7nZUlxUji0tGo+gOfeZk+MsED1I3wljN3Xwz/7X/4mX58dvpLp/MM6lgEzYag0ErrEdSjXhlWVRss0QzKacdHmcy8ntzdObAlZuoSvGgw1fC8kQsc5ec/bc9L1Ysh6bzIMCyUhZgo1V2uxS+7EWXa6P5XrIAqXQVszHlLLCJDRaDt0cwdJeffOQr4UrNl5XqG8WcHtN76HsmwGFWzezBhlvepYPNIzHG6gHtXFmNvHIxj/exHe4157f1LZCrdxgvy8YrbWSm3BdU9RXTF1BmpWEccTl6Ip2e8jZy2NCP2DvcJ/Li0vSckFdWShzlIYQR2pq2lGLp8ev6LUTnAXnDLO6pprNqYoU7SkuZiNi5TGbzjHWsL29xWgypbCWWZaJIM1BGFim8ym9VpvHp+f0w4AgjMnSGXlpWIxzTDoDIK0LCW+UFQuTMxx0mc9zsIorU9O1YOqSNoqT2YxO4PP8YobWFt2KMKUhM4ZFUaGrEk9BpSxZJSZUL6YL+u2IonZYLNPaUs4XmCon8TSn0wm9KOF4usADOoMus/FU4ul1ia4qDCWRdoyzmk4c8nQ8oxdqtBdQFBULY8nzAl1WtBxM84xAadLMURlDKwlJi5rKQV5XtAFTZsQenKYpnSDky8mUIADfDymzgnFlyOYLdCF13qdZgUIxTS1jt6DXHzJfLGjhGJc5iTGUyhL7mvPRFcNBh5enpwRa0el1KOYLJgYwJV5VE1vxs/Ab2r36nq5hkNCJ14CBUgmtH1awH8KiFmfSDAElSayxOCa1eF4kNWw7qd66WIgw9NJCpBS2A2nqWGgwHkQVtEPJLFHNjW1aQhxq8C3jQiZTjZhrRS0YL8Qwa4J8x3UUVe6YNvbkSSlZMRbRT3ix2K2HnoQiZlmzuPRgUEqb01wARqkbG/e2wtSOWZPeG5ewr8GFsEghiuDSNC6gceNo2rTZLqSK7rSxUTdKGJA4Vlgc81rAT1SLWZrfEtajFQnL4AG6A3Uq33URxAsBEmktYCRpGIgoABXI/gMlupKhg6QDs4WISeeqKXrXgTKXzBzfh6SQcaqVsDdRM06xp6kjxyxf6wVbtdjFTwonIbhmbP2WoqwdqQEXgM6birwhpOW/REXi2FjBsrGKfX1bh1M2wMfG69c0Dss23BvGYGNGu5bCueEhIaDDrcy0rgk8l/3YBBEb7p2ipfCuO4QGax3HpkOobpid1bNulFYrZKWEAdoUiarrh7IEHMusliVj4pBk4s1nt8EOXAsrNf/ZjTavt/9NILD87OvfWZ+t9dl5vZ3XRaXf/MA3z/o32339ve9ns05R5gUGx6N33kc7izEZO4M+vVaMNSVlWVJZODs5pqoNnbjNwwf3sc5Q1Yb9/QOcU6RpJsBWe1zMptRVzft379CKQorK0A5b7Lb61CiKyuD7PqPFgsJUtJTiJ++8A0BRVxztH+F7HlkuXtAqiXk1GZM6eLB3wLDbojKWyPPZGW5jcNRFhecpJmVNXld4OH7v7YcALArLcLBF6AfUVjIyvLjDq7SkMIb7vS63dneoLFin2d7ZQ2lFnpegNZUfMstzlFN88OABWisWtWKnN6SftKiNoawNfhhwPp1hnGUrjnl45w7WOWpr2d8/QnmaKq/xsOh2wvkiw+J4f3+PSPukRpEEEUnSpnSOtDKoUHFV1aTWEit49/YRBkduNfu9HXxPU5gKsERxm7N5ilPw8MYug06bzBpC32dnewftaUxV4McRi7Ikq0pq4Cfv/xiwFHnJ3s4BkfZIpxlVXROEMWfTObWz7PY6HHQGVE5RKE2n3aFysoI03yMJ7ZD6INbCQSuirmR1TKWgVmQG0kLqoYwKS545OkbTDSIKI/qPKhOnz0UpYkcTOEYTR1HDjSSEWjG14hlhKmEaprnoKSbGsphDWCt2kpiyEsFtnSmsE/OushAgcTlzZBXshAG+8Vg4AUR1KWAgzeXWmQHzGbgadpIAWwh4KYvGMKuCLIcggouFY55DR2ki55FbCcPURSO2bTwx6gBmc9G3DGMfculnmQO1mJWlOYQhjEtHmkFgFW3PpzYieC1SGfBFLlVpCWEyFYYj9IBMdFFZJdk5hRFQ4Wk5J/MUlJHMImoR85YpOCsMVd2Y642mcoxdX+NV4m5aGGmzcjDPZJzmWNK5g9qx346pS5hahSk0xkgbixL8GC5SR1FCW3kE1qd0wvw4K6HSejkhfMv2gwAemymgq1TQTTCwXEc3/7ue1aKWJMnGrNiAgwYsrNbhbv1YhgKuP2wDMKyAjuVr155f13gsWYONsMkG6FgJR5dmXYGP1zz0m0Sjeh1eWoKOJVtBoyW5/qDRVixBhawmHW4NPjYAlXUO27x3/bHJ+rh1e0vUpl4DN29sf70f5zZBQfNvp157bsCHiBpwzeubj9XOVyEivTrvzeCvxkHqwXw/AER7HkG7zTvvP+Tjv/kl8zLjX/lHf8iLl8+YTcZs9XokcUToSrZ6XR49uk1aLfjobz6k2+/z1v17fPbsmaSY9rsY59C1oZUkvPNHP+GvPv+Ss9GIn/3kfWZFzqvRFWEnphd7VFVNK4w4uHVIsDPgLz/8EKU83n/nbT79+gmVc3QHPQlXFTX9Vps/+Ec/48Pnz3lyfMK9e/dxUczTy0u8MKCbhFSVoeP7dIcDdu/d4y8//YK5gZ+/8zafn19RGUM7iQiVpPP2WjHvvvcjPl8UfPHymN39Gwy2t/jq5ALne2wnAbo2KGuJ2m0e/PQ9fvHFY6Zpyc/fe4+noytGaUrYiok9D11Zhq02dx49YAx8+PnnxL0eR3du8dnz51itabdCtAGXVQRxxDsf/IhfnJxxlZU8uL3P2Fou0pTAhx0fVOXohRF7N3YJt3f5+OlLTBBx//Yhv7q8oga22wGhBVeUJK2YH//Bz/jV6RmvLq64/9YdVBhwfHoG2mPYSjB5ST8MGGwPOXjrJn/xiw9JK8vv/8HP+PzFU7K6pjvsSiZbUdBvtXj03o84m6U8Pz1ja3tA0u9ytVisKPPvc9NIiGO3Bc+zEqPgKPGZ4MhxRJ5Q+K0SdrWin0CpLedZiRcotgPNpXPUSOpoy0KvUsS+Yq8DL7KKyjq2Y48KRYpQ9QOvYUwQu/QwcrxcFNQeHASaq2aV0vUlRNHOoeMr9ttwVtRktaHti1Zuhqzmh02bAycr/XYML9KaWsFN32fiGsGnJ2GTTiHW5rstmBrLtDJEoaLrKSaN6G7oi7dHtxTwtRXDcW6ogb2g2TeiFel4Mk5bWtGPoVKOq9ygAhhqxbgZ854v4ZN2KSLc3ZZU2C01bPtaBK9KMl/6gehFdpywP6EPk9JBCDc8xVTJOez4ErZJCjkPRy24LC2FdfR9YdfmDpySsW9VsOsUUSCF5p7NC2oNt6KIK2UpgcSXkFmcw5avGLZh5gyT2hAGHrHnSfouvz6U8oMJtax1BNfkhvLaxudWU9E1tmPjGxvL5+9Ms1x9eLnydhtMABvA5/Xn11iPZWioCRMppdaAYsMFdNNwa3WEy2NuGIx1JsjyNdVwis3zGxb+11gItwE+3OY7y1Jq67DSGqxsQAz3jVe+/YSxDHr8uuXZBvh47cxKX98Qlnn9+wpWCleWz+tWv88Qy6oXzhAHIb6LObp5i62tbf7iLz6SsBw+WZHxe+//jKvJFZdXFxTjkvd/9j5Pv3hOsZjzxWefY53DDxRekvDHj97hi8df0C0V5bjg/sN7dL2Ejz/5jKIqsdZRGctbt46wRnNycYFbWO6//wBdSc2Mj//mV1jnqDxNZQ3/2h/9AY+fPKPKCy6fnvPjn7xLUlR88uUT5kWBtUKlH+xsc7vd5qtXJ0RVzW57wGxnh+1Oh7/61ec458hQLKzhvYf3Ob06Z1bUjJ6d8e6Du1SzCceXEy4XGcZaNJpg0OOn94d8+uKYjlUEi5qbB3sMuwkffvIJ1srEVjjHB28/YJSVXI7HpGdXvP/uu7x8+ow8y/nqqydyyj2NbSW8d/c2Xz17Sbuuyc6m3D7aow98fXzGotE5lSgGuwPa2uNslmFnc45uvYVXVSS+z+NnL7EOKqVY4PHuj+7x5OySTmlIX57y6O2HJMrx1ddPmealCLyBnaN9brV6fP38GYmDva0bjPdmDNp9fvkXvxStmPLIa8PPf/IBpyenpPMFo2eXPLr/gIuzU9JswWiR4TsRtsZ8v6tBi0xYVQmxc+wAF0WNQmGaX7BR4tsAIkT1LfieFF47sU3KNUKSxAGMLMRKUeaO0Dl6CqalTNaWBuwglH3pJBRhkdBjD3hViybJNm0mvniDJIgle4Cjq6GyVjw3lOgPChoTMifCTWopfjfU8KquCZToEXwlnRjT9LN0UgBNA7XjkqYCbNNm2PiAJDThGSf9vKjdqp8+0o+Fh9yuGpt1hSOs4QJHpNfjFCgJt7SBvAkzRRYurMVryO+gGfu5akStRtgxT0FQwRmOwF+t41Baxr6jpAhe5KT9hRENB00/ayVW7DMHkVVQOiLl2NVwXOVSEJAmQ8aDuW6y1EoR9zrlUMZQuPW4e7/mOvtBiEvfPrjt/rs/+SfNwrYRlq6Mt5apnZtl4JuwBGt9x2r17ByiP7Tybw3K4zt8iDfDDmw4eS7FpXUjKq0wxlDX9UrjAWt9xxoQrYGH53n4nqTQroWx6npIZxNgbWg8jLGNwHOtJ1mLP+1K9GrqmrquqeqlALamrmqMqVljI2FNPO1d06MATfsGa901cenmMa76dw0gqRU4Wol2m4p9rnlWr4OOFQ5ch7PeCA6vIU3Z55IFEyZq2YawN0vAuDyX/83/9b/9zoV5Rwe33J/+2/8hSit6wz5FUeMUtFttTk/Oqescz/fodFrYUqGURWnNoD9gfvaKrZ1dXl1eYmtLbUus1uwMBmSTBb52tFodgshnMp3RHw45Oz0hr2s8X5OEMZEXUdQ1sadod7ssZlOiTosizZguUoypsb7Pfq/HdF5iqRi0YrQXM59P2N7e4eLsmLmxsmIJAtpJQlmUaAXdpEOVp/ieRvk+k8kVMwN4HvudFvMsx7eOOAyJOi2m4wn9G/ucnhyTWSMGWZ7PdqfLIssJnKPVamPrnFo5gqTPeHTBoirRnkcvaTflvQ2eVnTafWbTC7rDAbPRmNRUOOOwnuag22aapnJjjVoopSgXMzrbW1yeX3DpwNOaru8TaIdxhlhp/LhLkS2Iui3KvGKaplTWUXkeh902szzFQ9FudfE9n9l8wu7ODU5eHTO2tinkFzJsRcxL4ZaH/RukizE6DDHGspiOKKsK5ftsd1vUaYlqTBnarTbj2YRBN+ZqlpFZYWY18F9+T+LS2zcO3H/yb/4JcbPOsQp8rYhbIfmsYKwkC+JWIyjMGudL16Sd+olPWRoK42Qi0gh4cZKF4ul1umrU8clnNWOEJdgP5B6+NBGzrtE9RB7OQVkYMgAPDpVYt/uucdSURT9+y6NcGOYIqBj44skxsTLxomUfvqfwA0WRWebI2u6g8edwVkBHRVNRtq2pF5bUNWBKiwB20hyTa/oaKAgiRZ25Feuy50n4rDKNf4YTPYoXSqipsqzGqa+ln7GVNuumTT8CVwgwqJy4lhonJl4hkpUTIL4mgROB66I5pp0mLOMhY1858f4I2gH5rGKBnM+tQDxTplbex/MwtcH3NTrU5GnNHMmsues11Wrd2vU1BHQoYGThpM1/+i+HuNStWAbl1JLzZ3N9rK6v77m+mmYdYtkIo6iG0n+TBmCdGcEqzrCpC/k2pmP5WIZHVq032R0i4hS/C3XN0bP5vGucVlZBpGZTNGm5atWvTRbjdU0Gy/eWfzu3DhVt+C4759BoLFaAzar99WdfDyWtxmATFSjElnz52pKQef08bvIlG2Gw15meFbv0OvJwrCmtN5255eXx68iS3+XmHFmVE/ghF6NLer0tqrzkxbMXRHHEzs4u48kUlI9zGWmeyyTj+xilOLm4ICtLenGHTtjmanyB1opZVUjFz/El/f42NZbj45c4T7PV7VNm88Yq3jIrUwqlyaxFAfPxhEWW049juu2Ey+lMvCfqlErB2bxme+BRKcvZ6QWpgl6rja0KSmswWjEqCiJPk1VjWlHErMgppjWer7gRSCl3g6J2jqm1hHnOIBALrIvTM+bW0AsjYgWTsiRUipMyx9Oa6WzEoNMhLwvyszN06LHX6nJZpBjnqLGkdYnvHEZ5ZAqK0YS0LOkFAaGyTBoXprQ2pChGsxk73YAZjunZiIWCXV9+URkWH8156Yi1peVlhL7marFgntUkvmLoK0bGglbktaVSmtl4xM72gNw5vjo+ocIxaLfA1OR1DSphns0JA4/z0RlBGFHnGfPZnG4UshXHzBcLrNJktqY08hurixyL42KSkiM341iL4PL73EpEF5Fo6PRgMXHkWUHeFHPrmfWkeII4Zm7FwpJkaU0ZArU4f9IYbCngQjWhlyGkEzBZTRZK2feuWnt4TJRoRYYN/ZNlhsoXcNJp7MDzZqV/YSVM0d+CdAxhZkib/W83ReCUE6HswkHXEwFoOnN4viPTIuhNmok8UpJFE1ro96Gcg1lYslA0EcNNIzQFl06yZLoD2b8xjtwXhmWIHHusJeNDW+h3BXCUBdQtEZJ2mtAHVjQZ46Ipd78N+UjSV6tQbM5veOt+TiPR23RjCY/ZFPJYQE6iGxDSgKhLKynIgyFkU6jSilkEXiXA0DUgIkUAVQdD3Ib5woKyVFrGThlJkQ6az0UKuh1IF6BrMBFUuWQufdf2g9B4wJsm9+UbG59p/tdghG9MeG41W8pDXQMu8E1Rorr23aWuw75R47GeMDf7DNc1HqsCcNpbl4lvjLfkvaVeY/m4Dp42/UNWfd8cj83xWr3nrn3vG7qVjefXdRnWbj6vwYfdZCM2gdgKPGz2daMfSwbC8Y2/l99bs1ObJ3QDa1474d+9/VBwhwICT/PBO+/Ritpk8yl5lqG1xaE5uzqnrEpizyOKuty6/YhHD39MthiR1xVFWeDjWJQpZ5NLtIKW5xF58Pvvf8Cwk1DPLinSVNwareJiPiWtDaEzaOfYHgx59OghdZFR5hllXhIpRWUMz6czQGrzaA9+/PY77CYhi/FIGDNb4zsYpSmTssbDI1aadhLzk/sPCZwlz+bUZUWEBeVzXFUY54g90Dge3LnNze6AbDqlqCtUVdBVmryqOM8LEucorcHXmg/u3SVRisVkSpWVeK4msoaX6RxbS0ppyw+4vb/Pgxs3KLIpqiipy4pYK1Jruaxq8TzQ4KzjvaMDBr5HvahQODwMHc/nxMC4tiTKobRlq9flnYMD6qwkywpcVjVW5ZqXpSU0DmVFJ/Xju29xY9AhHY8pqgpnDImCUZZylRc4pfH8gE6rzU/ffRefimoxJZ/PiIECy9l8Tu0cWvsEXsDDwyMOuz2KIsfzZBJLmttRbdeGU9/HZpsV8UEkNLpaNA6dzQQ/McIkOCeMxyCUCd5bNJNnQ/ujJE3UOQEMFXArkvCEnsqk7RkBHTMnAlNl5HOJhhs+qEI8K0rE48NTwkgsze1qB0dNm4zX5pJhJSxDWkubdZPCehhI33TahHKa8MPUNpkpTlxEdwJJw2W6Du6GpRxH2sSH8ub1o0AYCjVrbOJrCYFMjAAyZ0TI2dOijfHm4kxqFehMxjKtQTXMR1UKoxEBwVjGUdegcjn2rBZQUlrJDBpo8DLJKql5PRiDAAAgAElEQVQckMmxLIz0s2rAx14gYRamwqZgRdeROhkrTFNnRTfnqYaoaNiMWkKA48YV1TbnfjuSNuu5iGG1gaAQMFKZ7743/2CAxze2Jn6yMe+tV83LCdKuvS2cXc1w669vpHuyzIJZiVM35nzHtbZWIQdjMKtQxzfFpXAdfGi9ruoqbp+y3xUgsK5Ji93oZNORJUdgrZUQihXwY61rHmu/kE3fkOuwau2pcU10+6bh3Tz+a4DFsplZdF31sbldByzLcVoBmCWg2GSp3PKcutXzUgxrWYI9u5GRc/3oNq+FHwrgWG7WOe6+dY+/+fQTiiyj0+qCdRweHDLoS0G3lh9wPpsStRTD7TafPfmcQWeLMIxAa+49fMDyyMLA58XZOe9/8FN+9eRLxouMpN0FpYm7HbZ3d9BOMpAWdUGB4cH9ezz+8jPCVkLY6WC15vbt21LjxzkC4GQ85f7d+1yMrphkGYP+Lrp26NDn1tEtfJzEdG3NeDHjnbcf8ovHX2C1Iolb1EozODzAD0McDuNLm9vbA0xdcz4f0ekkGDSp1uze2l9ZgNcKLhdzfvr+u3z6/Dk4R7fTw3ma7vYuQbeHdg4VelymM1Ss6A2GfH1+SqvVQgU+lbIc3LojlugAHhyPp7z36B5Pr8ZkrsbzPWoUJDFxr0vUjOqiNJRKsbe3y+PTY+IwIElCcqXYu7GN1kqcvRWcTufcPjzg9OqKy/GMuD+U31QUsrt/QOjAUxpXV0wmc95/7z1++atfUVtHuztAac3B4QGRH8nvyfe4nE7pDFoYz+dsNqHbbUlmklL4LY2PrDh/XXz8t7lZpFbHpJIJvnLyu6uUjEu3ARdpsLYYrwwUKPzGtMv3GrMwT+j3qYJODDPJRsYoJVbgTZsDpM06kuNPosYinbWlt2rCCbEDPNE5RFEzuQO1UlJYrflsb/nlUCbsViIVY00zB9SIeNNDGA+nGz1GY+jlnPQz1NInlLSpmjbniFh1UTf3owb1VEoAUr+ZxKtQ9qk9CavUNAZf0iRttw69pFr8SKq6cWVV8tmCps2mbaIGjAVywiwi0M2bfnYRkaoKpBBdEDagBKhoxkkJY7zdDBOR+HP0IjlPToGnFRUyNhoBGU6LxsPzFQa1KmioLKuQVURj3vYd19kPCHisMzRYaQVYARA2VuBrbw0jE7m1YmK/Ah/uGuhYz+9L2/ANI60GGFh3HXQYY8SU6w0mYd8QmLLUdmg8z79mc64ayLw0vzJLT5BV3ZnlMYv2w9gNIy+z9A0xvG4atuzPiiLYDE2o9Zh+w5tjA5zQaDaW7MXSu+QaM2LXoZdvHH8DpKxZ9tFsgI81c/VNdoTmu01GzQpcWcwGwFvuc/OY1iDINREZtdKdvIamfqebtY7Ts2PqsuDo5gFbewcMB31u3b/F7vYQ7YVkVY4rCy5HE14+eYa2hoePfkQr6XLz5i2Obh/QiyK0c2SlaHe+fvaMdDZnZ3eXo7v3STo93rp9i/39PRIt14ytLNki5dmTZ+SF49HbP6LfTrh1cMide29JhVTkRq+c5eTVCdPRiFZnyL27t4nimFs3D7kxGKK1R9VcZ4u84sWrY0xtuP3gIVu7++zu7PLW3bsM2m1CmrocCi5HC0ZXY3SUcPfBQ6Io5tbBPkc7u2jPQzmHMQ5qw9Pnx2RFwdbNW+wdHdDr9Lh79zY7/YFYUlc1ATCdzXl1coLzAn70k5/Qaw+4eXDIzb19ojBE0dg2145Xx5csspzO9g53HtwnimLeOtznxqAnNUBo6l6kNecnFxQ1HNy7i9fqsjvo89b+EUkgbRYOsI7zywnj2YKkN+TuvftEUcKDO3fYv7mP8mScFJAXGU+ePifLKu49fMRwq8uN7V1u37vLjeEAD6jrGq8umYxnnJyfEMUxh0d3QAUM+l1uDW7gOxEC/kZWz/9Amwe4qgkLtHyCbojv4HAIO6GwCzMHrqlzonKwWrG9HTFzmr6GO7tC83tGWA/PgSubSqyRRzjwcTXcaMFe3FD8SlJlNaAymUwHg4g08BhouDOUkEaATJDLCmeqhCTw6G37ZLXYlR92Zf8lkgKqNLhU7kODbkiReLQRG/aW1xRT82TyVEhqq/Y0wxsRM6sY+nA0WK9rZ3VTfbUQnUOv5WFbHpGF/a4UrtO2qWjbmH6ZQsDJcNsndYotJW2GyO9nZOU7qpY2WyG0+nIutiLoLcfJE0EtTT8dMOgp5p5ioGCvJ8fgGxHLKiusS11BGGg6WwF5BTsRHDa1BArdjBNgs8aGvRexiAM6Cu7uSJglAGbI2DvrsIXDeYruMCBzii0PdmS9JRWpv+NW/IMBHt+2gn0z47F8Xq7Q14JDcMv5dB1MUdf+dW2Pm2zEyhW0ARtLUPNtDMNy26zNsqpv0ug6hM14DayswMLm8S0n4bWodGVW5tw1sPFNBobrAGQJLlaTNRtTNat9Xx+ONbi7FophHX56HXQsQ1JmCdqW4+cENC0B4vW+NkwOS2HodVZlM9RlxT1rDWA2+v9DYzwU4GpLpBWugq+/+JQb+wd8/qvHpFkJrsb3PVpRRF3mVFVF4imeff0YW8zpdnv8iz//a4JeD6U0nShCaU1VLcMGjq8fP+ZwZ4uT83NeHZ9RaI3veURRgMKjKktCrTk7Pmc0mrK1PeTP/vKv8Po9nFZEno9SCr+uCa1FO8tnXz5m0B9QVjVfHL9EhwGh1tKm1riqItSKfDLixfETdraH/OLDjzDKExt05eFZRex5+MagcTx/8YIwDAmDkI+++AoviYmVIvGa201ZEaOgLHj67Cl7u3t8+eVXLMoCg6KlPXylRZdUVTgFz588oSgztno9/urjjwiTNoFS+J78xjxjpYKtMXz+9Gu2e11eXY05ny4wSjPwFcopQg/apibSMDu/YDqeMNze4s8+/wy/3cJX0A6lcGOEIbSOwDo+++xX7PT7zIuCL754Cr5PqBVh4DXL2RJfK2bjMS9fnbC7e4O//vBDnBb+ItE+Gk1oLYkxxM5x8vI5oVZ4nubJ6TnW11Iv43u6hkF+VwGi30itY5EXBG14OpFwSO1LPRKcmGhtOZlgxmmFVhYbwFdn4CWgIll5g6yWu0itnsmiJmjBeSEVbk0AnUR+Q17zOa1gVtTU1qASeDwCHSlUJGmqFgmTdIAcx2heEyYCSk4zcL4wJ1rJJNdH9CmLylAUNV4Lvr6S4zGBMAamYR/6CkrluJiW+L6j8ODVTNgbP2yyYJywFW0FC+dIyxqdwMuZZIzYUNJ0nRIQ1EX+HqUWpxx5KGOqQiBaZ6xESJuZE8M0F4vz6qIG4wuLZGlK3iOX3rh0GOsoQ3g+FfaEaO2WGiEamhLHeFERNezGWQo2gjiWsddaxtNXkNaGoi7x2/DpBbjQwwZite7ceuwrBdOFIfAdlYbJDNHl1A1/8C3bD0hcup5M1Gur92YqXU+U15CU2nhSq4Nt/tkAFrehHZCrZjVxvuZQ6t6wYr/mHdJQVJtAY9M0bKXzeNPqexmeWfZiOdkvwxPXwhUb7MMm+FhNym41gbvlRP6GSXw5sivWoRmgdbpuw3osH6xZBbvq77qK7LJC8LLNzefV+XKS0aLc65kv8jG3bOy1kMrrGhocWG1RVoNasjDX33ebz+s/fuebbpbfSavF1eUJe1sDHn/+sWRYTMf045Dh/hH5PCOqMsqipNPpkBc1RW355LNP6Icxi4tzht0+O8Mtzi7PqKuaJIqYLVK6rTbPX7wgt5ZEKdpO09/ewtkKPy9I04xBb8BkNiP2Az78+GPaoc/k1Sv6SZv9rW0ur85QaALnMK6k1+lzfHxO6RxbvkdsLcH2gFB5+IuMOs/p9Dtcjqf02n0+/fIxGsc8S2lHIfvDXWazkRQLqw1hK6Q0lnIx57P5lKGvMaWh02vR8kJ0lmPqnHYcczYas9Xr8/jpYwnXzaa0fZ+twRZ5VVIZQ1WUDDodqkIqUn305VcMfUs2S2l3ErZaLa4mU+qqFBHuIqXTbnFycUluLW2gpRXdfgeKispYiiyl3Y6YLRaEgc/nz57SUZb0oiAKAnaHXSazGZ7VBFiquiTpDzk+O6Zw0NUege8YbA2Jlf7/qXuTX0muLM3vd6/N5uOb48UcnJkkk1lZWT2oqgGpd9KmN5LWJUhoaC8B6qWW2ghQAwIEaKfeCRCgP6AhQMuublVXZWWSmRyCZExvHny26Q5aHPPhvYgkS4sqUga8MHeP5+bXrtnz893vfOc76GJBM5+yP+gxnozpdDK++Or3RF5xNn9JL03Z3Royns5JnaOpDCQKpx3UNZdlRaykhLNtPvqjbV4BsQSWsrbshHBVSdVFqGQFnVtpB2+UwiaepC2x6Du4QGzAtZFzOQjgXEMTtZbl1tGjNcVqA6ltRHvRi2DuFDb0xBZMadkGjio5prLSK+Sg7e7qI6nUUN7RMcKYzLVUaBgn1R37MZw1Cpd6EgNVY9kDThrxwUi86CWGWhrFOa2IIk/qPKH12FrErv1WiFkqxV7gOfWt4NMq6X2kpNIjjIRh0ZUAs6RtR+9TCI0naDyphUtEH6OtsBy7oQhAbQzKir9I34uDbBi2P5WU5CYxzKwIOX0jotHMwrkXq3oF0B7zWss8Bxqc9XSd9IUptDApdSmi3r0ILo3CxJA6T1kadhWcWCkfVt5inIhb5yGoQBBV3Hgi73FNm1ILwZk2JfU9208GeCwD3xIsrAIj6+CoUK+/cQOYLFMqwKraQi3D5g22Yk37r8zCNmj/m6mUdduzpYGVVuCUb9vbr51Hb3dnXQ7m9ZW6X8XI10Wh65TG0qb9Bti4NT4BJxsgxi8TEbeC8ZJ5Wc6uYh2kNwEIN8ewnsX1pKoVaePXwK79LMXrwEPp9Z7VOa8Bzm29zOa1FaDilmjljSBl9eotVuTvc/NAYWp0rInjCBVI871ep8NsUaAsPPvuO8IwIoo1ZVkx2OnjGovHEemQbqfPdTHHlQ1fPP+GPEmprSGNQvIsI041tbMM85TGNFS14+jiHK8UURxTNRXdMCeJtKzqtKK/0+fV0SXdxvH7l8/J4laW72En6aNaIWU/ScR3oGngaoJRAVkcUJYVO0lIkMYorfAeBt0Ol9MZiYevTo9IwgClA4y1bHtNkoXMJp5+EhEEilFtyeYVZ3ZBliQ0dUOWJqRxRKLlZtrpZlwvRG338uIcFQREUUhV1yRk+DignstKPEsTrsZzbFnzdFaQxQFzqwi1IwkDgkBhnGM7zylNTW0sJ9dznPJEUdiWJLZl7k1D5BW9LOZlU5M7x9enV8RxAL7Be8dOmqFNiXOebpYRhBHFbI5txpw6R5amVHXNXicn0QExIQrP7naHo8sJgXN8d3JGFEYsAo93DblPpRU6ng4epxSV98sMwo+2KYTZWHjIlKK0ntALY3Bdy+9cuLX/hpaiBzIt37HbSOAcNQIqnrdOlkVbVREpRd16ffS9NDUzXlJ2YykmYmbbYypF48UjI3WiOwkDeN5qICongTtQisaD9p5dLxoF58A7eNW+fmol/dDVUoGVedGrjFo9w5ltF1ZtyiNC4Zx4iWx7qBuxP/dKzikCri0ExpO241w2rRsVMo8TK0GYUMCF3pinAaIOKBrQIRw38r1aOxGohkrSg4kXXcu4lhRG48ShFMRRNXDQQRF5T98LMJm1gf/EyjiKNt2SekXpBOBue6mIqaSym2mbEps7Ecdmuj0nxIDtshB9yUsrImLdzr1HoT0EeIbI+Fx7Hb/vm/gnk2r522x/u6CyTqustQzrwLgMzksR5KpJmltqOeyqKVv7DjnqhpZAte3llz4joudQq9bwK3n1xhFWYOAGqNho0rZKVaw1HEuwsVm1AjeBxVoXo1r/k00dy63+LBtN6G50qlWbv7+Rp1p9zk1w5JYpk8301I3mdRtamaVmZXV+y9TQH/5ZfoZzHtvulw6ra0SlNmb3x9+U0lI3f7DP/sEhL46PuXdwF2MckdKEcUwYaPJMgtT+4T6m9mTdDs57trYHqEATo9BJSKQD8jinbhruPbzHsL/Di7Nrdnb3aXxAHOakYUBHa9I4wXtHd6sHOmAw2GYynXFw5xDdRMRBQJCEJFp8Loq65sGTeyRRxPmsoD8cosMQHaWkQUhXB/RjhQo0aRrT6Q+4c3CHk4sr7t7dBx+RqgCtIzKl6WY5ZdPw8K37JFFGbTVhkhHHOUk2pBNqlPXkYUAnidAK9g/32d/b4+vTcw7u3GfhY4IgI4wSIh3QSTKaxnDncI9IafIkxXnHzs4uPujSUSGJV/R0QDfPqU3DkyePOdi9w9F4wc7eHpaANMxJwkDo5jhGecX21oAkzuj2t7helGxv7+CCHplShEFIHih28pSqaXjy6BFpnHJd1gy3hgRhSB7ExEFAqEO6YUSgArI8Ju+k7O/u8urijDuH91jUATGa0Ct6Gva6CaY2vHV4QBxHVFZaKPg0JUyjtg/Tj8t4KAQ4bIUQZjGXHmwYMPMa7RWVk/4duwFY5xlEkIQak8ZcKkURaBZeFoHewraFbgy+hl4MpBFTr6i1Ytr+LZdeKjR2NXjl6QBZoNB5xCXgdbAq4XTtMbdCMe/aTiBKQuZKUwaaBQqcBO3IwLaTIJwY6ESgOgmXDlyomTphyK2DrhHXUmM8/RB0qCl0wFQpCqWwXmEB3XgOHEShVNx0I1BpwNhBFWjGTkppm7bqZDsQbUtPQRQoTCTHbAJN7dqvMwMDC3kkuo1OhHhnOEUZiMNo4NsS5qbtiYKkeuIASDQTD0Yr5k4AjLPQMTK+phEWSMcBhdcsAiU+J05AbtzOUxhIB+V+BGEn5dQBYcgETYDCOBg2UnVTN56tCMJAUwcBhdLU6FW6zPlbiYlb20+C8VizHbLyfhPtvw63t7ZlTkWwV3uya2rfq5uMxxIGeC8B329UjLiNIOffIN5UStwwvA/w+I30ytKn46YHB2qTOVmu0tfpAs86zbIK4qtS3nZilqfZggK/CRaUAq3x3qO9x/tg45tLofXqbFGo11JByq/NzJxrjdmUljlrGZ0VGLjNNCxfW6U/2vQM6znTbSM7MU8TB8tlM7flsW6IdP2Kj5HHLbXrb2etlqmelh5b4hGZ2++73f/uNq0U3TShbgzPXzzlYDBAOcX1ZIzWAY8f32M2GoHOuLN/l8vJKcYYpi8u2NrepSgKXlwfs93bZmtnyBWeQa9PEGuKqub06JROmtKJIk4Wc5x1PDo4xFQLGmJ2tvucX1/i8Hzz7bcc7O7TFAUn52fkeYc7d/Y5ObJs5yndLMWVNa8ur0iVYtDv8Oxsiqlqdra3yKOI0WzGvb1dzq+uqZzj+OlX7O7s4KqG49EFaZzw4GCP0eUFaah5+94d7KLiejGDxrC/tcv5+JrT0TV7ezsMgoDr0ZRe3iNAY2rL8+NX7AyGxN5xOb4m0Jp37t1hNpmDCjjc32E0m1I6y+jVC3a296gXC8aja6J+jzu9DheX1/SjFLYD5mXN6fGJ+IYEIUfFHKzj/t4QXRtqC3f3tzgfjyk8nB0fsb+7i6kqjkYj8jTh7rDLeLQgCRIe7qU0VcWr6xGRUuTdnKvpNVf1hHuHd8g8jCdT9oZ9rmZTKgcvv3nKne1dKGsurs4J4ojDgx0uryZgAp7cvUtRFCyaBlXX7PS6nM8WlKXwHBEiivyxNo20cfce5nXFbgBx5LmsndiQR9JqfVHD3UxjGsfCO7KqYhgKmzFTngTx4Sgq8Z/YS4SBmDY1W0CiFeO2NHYYSDnx3MB+qmgaz8R5gqJmLwTvPNdKVti7maQHnIGDXOGsZ9w0DIE0UEytiDo7HoaRpCq2I02Jp3aeel4y1MLhXiNOo9sxuEZaz99LRbA8M5Yu0NGKhYW59uQKBomcU+akYVvjYFEaBgpC5blykmLaimQuSwP3MmmoNrGevDF0ET3JRAu7MMzEeCs2IuA1DuaNE7DipaqmUjAIpJ9NUYs4tHKi1fCVjNUruEY0HTup9FWxtQh4sTAxhgGQasXMSVqqpyU9M69hqBU1yDwtCvZDCHCctwXeuwmoRlI1dzOwBmpnSZw0AjRO2CqHpJl+6D77aWy35RBsgo83AZANENLaiS8rV5b7zSqHJduwyXhIlUlbMms3GA9rVymN5dhW7ECr61hWrYhDqV5X0GwwHWuB5oYQ03nssrqlZVo2K2mW7MCm9uGGO+oG6Fi6oQZay0/r7rruExPccE9dVtsEWn42+8QENxrV3ayEeRN0XTMgG4/b6pQl42HaubXWYv0Ge7GsntmomFnhFU+b9uLG7y73y5ti2cfFb948PxLoALDOoazlcLDDkwePuX/3ISfHx2xv72DQPP3mK+49ekLcifj2+bf08l1++atP+eijT2lqg3aWKIq5nl5zdnnGBx98wMvLM8qyZHewx/sffsjH7/+cpy9fsTPYQgHfnR2TD7YZDnO+/PYZCTkf/exD3n3nbaJYYxdzsjxnvljw1XfPeP+D9ziZzzkbT4jSLp9+8jEfv/8RT1+e0M27GOD4akSJ5/79u3zx7TPiIOL9x2/z6NHb7O7scXY1ZtDrU9cVXz1/xv1HT6jRvDy5ICThVx99wkcffszp1QVRkqC15vziilFlefLW27w6P6U2jv3+Hu8+esKTewe8OH7FztY23lp+/+KInfv3ifOEr56/JIs6/PLjT/ngvY8oy4LGOlwUMZvMOL6a8Pidd3g1GlHP5+wmHd597z3efesRR8fH7PSHKDzPzkdEwyH93QGfP39JrCN+/tYTHt29h/KeaVXTTzPKsuLp+YgHjx4wqUouxxPSIOQXH77PL979kIuTMwadHhHw8uSUMtDcfXCPL49OUFHCW/ce8ejRW/R3trm8uiDv9Wnqhi9fnvDw8RNspHhxdIZzIe8+fsT+nTuMpnOiJEArRdtf7EdlPAyyQg8RnUbo4KL05HFE6qRK5dJJeuBo4Wg8DJ0s+3zjqUJN7mTxeFyK+HHO2hQrRCj7y8YTJQGpE7OwMyM6hpPSi++Fl1JbZWCkFR0CNHBcgAmkQut84UVzgggjJ41Hx4qeleB9VEmTttPaURtPx0nAC2mtxENN4kXkukCcP0+XVR3tfBTGY2LRUBgv50QgaZZpJRUxSzv1S+PpRIrEw8iIcJYATguPsZLasU5+5gH0rJRvnxXyFXjpZZ5CJ0JY5WDkIIhEVzOzknLxGs7aKqG+b5sKeml810OOeV4KAKi0pH6wrYeKgqnxqCSkYyWtdlxBnMBZ7Vk0Mk8K6bZ94aAThsTtPM0AH4gw1TgxN3MWGushFLZqmQb7vu0nYZn+7t2H/n/6r/5bCawroy2NDjcrRSS4rlvJr0tDdav/CNArxmHZ0n1ZPeGWtjxtoFyWq4oNekNjjPh2bJTOLktxV6kMpdYMCG1KY1k2u9IysNYmwCot4ZGAumQ5YDPtsikslc/WbVpkmXrwK73H6/tlJc4KQDkBNMvPaYe7AWDWjMON8uHWft0a06aeNo3U/AbLsQYbK33HZgrGO8Cz6tjbWsFrHdwYx41jLp+vBgvcuM7yXCu90gEJMfL6uP7Hf/1//r3bTT+8+9D/+X/6X5D5BJ84GqvYyYeMygVJljMaXWNcw6MHD6mKivFkhMaSJB1MU9MbDri4vCRLUqqiYNHUfPLJh3z79DvwAREKrx3dKKaxltIZ6rrCOUtvsEU3iTm9uCIJIAozSltyZ2ebV+fXxFGMrQumjeHjd97hxbPnWO9IYo0jJsaRBRFXVYFxHusMYZxy//CQ569ekjhPkmTUpmZ3sMX56IoolLLXWWN578FDrkZXFEVJpjQuS3GmIUlyRvMJgVJ4Y6g8fPz4Pl+9PCZWmjQKmDeG7SRhbBx4Q1U31M5x784hznsuLq9JcERpB2NLtvMtTsYXJFGIaSomteMXT57w9Og5kQvRymMDTSdPMLUk2SeVtDvo9fv0s5Sj80sS7UiSHkU1Z6efcj2pCQNPVRsK5/ng8A6vLs8BRYqiiRJi5QnCmFldURuDMw1hkvDo7iHfvjgm9oY4yZjbmt1OzsW8RHtHUxsq5/jZo0ccn19gTQmNI0xiiqqiE4dMa0Pg/cqf5L//kSzTH+0f+v/6P/svyazoaaoAek5RhRrT2LYkGw61tIJ/UcO2gjpQcp9ozdhLlYUGCOGeF4dTayDXwkj0HBBqisbRxnKGrf/HMyNlxbRZ68Rr5gowDqcEkNxTcKlFIzFUMAmg6ySdMbWeutUZdANJczwz0lxOawEuHauoAmgaj1VSUXJfw1zBRXvMQrclvEoxdZ7GifYi1LCr4JUTY7VYiy9G14EJFY3xKx+L/VDGe9IImKnaY2qlKL0ssLQX75RtD+ftPCWt2HUJwBrXlq4j5bqhhaMlmAmW89RW1PhWZ6FhT8EVYlLWUVKOO7BAGDA3ltLLde5G8vo3TtiiMBDjtcxJWsw0jqoNgQ/b+b6q28qWoDWb060JmpNql//5//jDluk/GcZjxXCsNAvL1ze1DX7jtdW7No6x/h+Q9fCS7xBrkPb32yuzYjzs6zqFG0EVCdZaqRsMwbJvzJIVWLIb1jmMk14qxkowN41Z91ZpX2+soTGN9IJ5kw4CbjAPavl5G31fVizIBnux7BNzg+UI1izHWkS6wSPdEF68+QKtUisbbI5v53XFVvib/7dZhrwJsLxblsreLJldVebceO/6OtwgNTZSVstx/aHh/11vAmShs7eFJaCXZhxdnTNbFIzG5/TinDhImMzmFNWCvNdnuHMAWmO85fT4DFM32MqSJikBARdHZ1R1zc7eHo1yJHHIxXTCZFowLwqyOCMIIlgsmIynBHFEZ7CD94ZUh3z78hRXVdRlTZZ36aIYnZ5TOc/uwR0gIk9iRkXJ8WSMqWuSKCIPQkJjuTq/ABQ7B4cUtqETRRyfHWOqinnZ0Mm6xEoxurxkUZbkwy18nhEphytLZlcjqqohdIo0ishQnF6OqYxha2+PaWPopQlHkyKAShwAACAASURBVBnVvGRS1XQSEWg2sxnj0YS826G7vSe9h4zn1fkppm4wtSNOOnRUwOnVmKJxdHYGGO3JkpSLyxGT6ZSroiRrU1S+KJnP54RpSm+wjfU1URzycrSgaBpMbekmEQMU4/kc56C7tYMJQvpJwtV8wfVownyxIFWQByG6MVxcnuE07BwcMmtqhkHI2eUIW1aY2tBJczpKc35xRtPUpJ0BpBkBmk6kqOuGwMt3VaJ/tFsYaPujOAkmtYJhBy68xztL2Va27HgRIc4bCZgTBd0EfKS4Ng5C6U6baMgaqfbwFgglNTDsSlWHtW4VNPtKjLMKKxUYZVsREsdwaUXxWSvRVvSduI3aRqpIxh52OjKOwnp8JN8TAy2Myaz1qKjaapheKufklJSABgFseRgbqYSJQ/Gr2O60HhfWo9r35qEIXWdt/5MmFD3JoCsB3nuP0xL0h0r8Mer2mCUwSKWEd2o8LhAxaRRKmmXWVrPoUF7fyYVZsU7M2pySTrZNJXMVBQKOslgYi7EDFQoTEbSdgcetK2rQNsvb6cJYQ2UtPpRx9rVoS67btXkdChDrpnDpJIFeaQFYux6urIhto0jukX4m81ADOpJ9+gP38U9D43ErXqyCzBI4bAajjW6tN9uQrYOSwq/TA37ZkdVvBMYNxmAp6LQ3AcjNHiwbLdlbkKFbBmS5XwZu51kZf22KWF8z34JWLNnCqlteIcpLi+fbTd3QoJwCvWySJ3Tjchy0wEK55ZiW87hmGTZ9MjZTHktJi795EdbBf4NduMl2bIC+9gVhjPxa69JC8Pbp6lptinhX584m9lSrwfgWaHm18b7VmNb3zI+xeQ9JHBN7sHXDVVGjNKRxQpikbe+ViLquUHgGeY/5YsJ8NsZ6YfrSJMU4x3g2JQ5CiqKgk6REDoypua4rwBMF0Mt7XM+neO8JgwAVQK/bIbA1s6LEIzlvHSd4pzgbX5PpgHlTkkYhkdJYVzMeL1DekShN3O0yLhY0xtILNbap6WQZpq6pm5pJUxGqABcp4jDmaDwi1lDZmijUdJKEq/mMqiwxLVPZS1OapuG6qOiHiqqqpDLECNt4OVsIVR0phlmXs8mEQGlUWRNoRSfNaIoFs3IBStwxozjBARfTCblSNFVBJ01JooiRtcymE/m70QHdPONqPkMhZbAYRafXR3nDoqzwQOQ8QRITBgEniwVdDUldoaOQLA6ZO8P56BpQIn5MO0yqEuscw0BR14Zu3kFZi20aRtagghAdaOI45WI6JtYKZQ0q0OSBxhpDaaWUQXsJangJHj/ml7JD/r46gWgezFS8LbwSgePEQqokXWLb1X/uoJzLfRlqETOiJIUy1OKaWQay4m8AMxa30CUhW3jxnIi1pFA0spI3pZTtJlo0HZJOgT3dHidom5MB1USCnVKia6iRNEKmJTh61TIOBuxcmBXbyDGnRs7XOXCRAIrQSk+TWG4ZrJHPXFg5p2XDuL4XJsLNBJQt0x5ztx5P3V7bFCjmazbBt+ZmMyPeIQ1t910lYMZOZT69QizNWzZBtQxLSNsNtpAuwFqJYZlD9DKdoE2DBHLNbDv3S/2FMpJaK5GxVi3L1EGAhZ+LXsS07NfUtj1Y2nPXXsZQzGRM1sk4Ay33yfdtPxnG4w9tq3X4RsC7ueK+6V/B6t83Ia7lslwOuLIwd2tTrtsOpautjevS2n6dAtgUSq6rPCzGLFMXzSqFcftnM82xrmRZfvabbdpXJmKr9y7TLGt7d7cBoJYaktc+v2m72W6Mz1qzYRW/rkrZZCncjcd+bRC2qUvxMmFqc9o39qvr59zGNXArELECL6s3qVvq0p/e5vHs7+7w3ckxQRDywQc/I+/2eOvd93h47y6BTgiDkKI2DPoDsk7I5cUl73z4HnsHB4RxxD/9p/8RQaAIlCKIEhZNw1uPHvHy4ojGNvzq00/ppB32Dg758L0PiHRAiKL0Aji3dnc5u7zkcPcOD+/cJcy6/Nmf/WM6aUSqFKEOmNU1dw/3uJhMqKuaX3z4M3ppTtjv8cknH5F4aYntgdoZ7t27w8uLY7rdLk8eP0blOR/9/OcMOl1ypJSxcIbBcIvSOGaLgrcfv8UgjSHW/JOf/4rUOWKlMEpT2YYnD+/zzfkxcaD59N0PyXp9nrzzPgf7B8SI2VZpHVmWkeZdTsfXvP/Wu9wZbKGThD/9039EoJR0RdWKial4+9E9XpxfURjHhx99RJZ32T28w3sfvE+MJtGBrPKUZ2d7wKvzKw7v3OHxvQdEWc4//of/gDgIyZR8gV9UNfu7W1xMppSV4cN33qWfp+SDAX/yqz+moxWxUjQKauN5cO8eX58ckXdy3nnrMVHa4Rcf/ZxempAjoLmyjp1hjzIImDUVjx8eoKOQKgy4v7dF6MXr4sfe4lAEjKlSqF6MB/JEsRXBAWL3PdEClrSW1XneiQgTTeng/gAGrfaiClsfjEiAQATE/VD+pEPYSmAfARFVKEE8DKVRXpoGhGmAdXBnIOmZoYYiFMv0vP39GIh7saRRgL2OrMy9BhMJAOpHYmqVhZq4F2KR1X8PSUcUSj5f+9bW3EPeDwkDKdU97MCuExBWRzIHnVCASKIh7QYESEXKIJBjulA8NLwHFQjQyjJNGCtqB3s90cd0tXiCLBDDtbLtjRL1NFEL8gaxzL3TclznhakxDvJYOu16J+feB7baeSpbpqK0Mk9BP5aWCAr2O7CNzFMZSfVML5Zy5CTUhN0I185Tjtirj9trH4eKQItleq8TEGgBooOOpF3S8Pu/sn8CtzlrdmLlJbGxquYm0HC3AMfmc/xNgLJeh9+i/1fPHWwwEm/shdKCj6WeZLVflZ1ujGWptbAWa80qhdK0besbs35tU0i6cv1cncc6MC81G2vx601bd7sJJJYgwt4GGJLSqeu6/amo64qqkudNXWOahmYDiFjzZtHrUvvxeunveh7XIlv1xmt68/q5jet4M12mNt6/TCl93/ZjUtTeQ1nMSfB8/MknvDx5RZKkdNOQ07NTrHfUtkKHmuvRCFtLW/St3jaj0Zh33n2b3/zut1hkLpRvsNYwKQoCAn724ae8OD3FKdjdHfL0xXeY1jU29payKdHKQRhz753HnI6uONjf45sXLyi8pcHTmJrYOSazioSQ+/cecDFbUOF5/OAen3/1lAr5olXWyv1wPSV0io/efptnJ6d0e11m84JxVcqqzImB1Hxe4oxha2cHF8dMG8u7D5/w11//joUC4z0Yi6kti5khcpqPfv5HPD19hY5j0izh9OqKBpi7Gk3DuCgJvKeXd+lvbXG1mPPOowf87um31MiqEOfx1jFaVCRe8bOPPubVxSVGKQ529/j2+XNZqRppKDevDMoFREHCgydPeHVxyeHBAS+Oj5k7K6p+2zbFmi0Imob79w8ZlwtKD28/fMBvvvg9BVB5h3KOqmmo5gWxh4/f/4jvjs8Z9HKKYsqkqqShmHXExjCaLtB1yWA4xAQxlXFsD3qMZhVWqaVO/kfbFJDUcv75IOaisqAhDTzeKmrV9hCxYom+VQKhJkhjzmvPdgLzUg7kVbvy9pCWkiLp9CKuGzEC62hhEkpkte8bASaDSt6bZAGnlacfywp8+T2ysCLqDGrRJegsYOa8sBFtl9xataxHLaLKXtE24+tFHJeONADfik2NkqCrjFTObNcQxJpKKcZGykvLWoJ1jVSAJB6yWgJypxtzUTkCJcF92URt2qaDUg+9CjHdSgOuas8gluqQRgkjNKulgiWphXFIupqLxmMcZJEwFyUCoppamIZOJSA57gacNWLeZVpfEuMlxRRaMT7rW4gzTeEspRPzsrrtx2O8PM49dBbtNRjkvCodUdh6tdBqTbw0kAsbT7f2BJGm0orSCcNiW8ZF/YC49KcBPNig3mEVepZMB543go9ls7hNlmDJaLyR9dhIA9xMG9yi7jf3y3/bQLqunFFrAWv72a9VqLRCzRUIsGumw9wK6mttyUZZ74YN+VL/sWIvWlHsayzGxr5pGppmDS6WoKOq5Kde7lsqXYDHWoOyZEBeByAbgGODAdkUs66qi16bfzbm3691HRuvrQ+yATj+lozHj1XYooCr0YwkTfjis9/TS7r0e33++q9/TT/NUVrx8PAB3bhDU1qef/eCKE158e1z8qzH+cU14+sZWdYljhPu7t0j0AFnL5+jlOfVyxdEYcru9pDPv/yCNAxJUBxubzPoDYic4vk33zEcJHz7+Wd04whjas6eHbGb9sjQvHVwgI4iRhcXzKfXLK6uYLZgv5fzzTffkltDLww56HbYHnRRwNHpMYM84qvPP2MriUijiC+/+JJh3iVC82TvkDDJMYs55fgCW8yYXl6wnaS8PD7GVgu6ScIgTbm3s43SipNX39FJAr7+/Dd085x+r8ff/Pa3DNKMEMXh/h163S1sY3j24jl5qHj29Eu20ozL8ZTRxSU7eZcsjLi7v0cQhJwfneCV5dXzb0gs7A23+Px3X5CFKbFW7G9vkfUGOBSvvvuGrV7GV5/9hq00oDGGl999y16WkSrNk90hKgxwRYGrG+ajK1RRcNjt8vun35A2DVkYsNPpMMj7hFpz8uIl/W7G11/8nv28QxLH/P6bb9nqdgmBx/sHxFFEXBTY8QRVzplfXNGLAsbzBbYq0YGi9j/ul7JHgmugYDSu2McSx/DdGJJEo0LpXJsEbVZXQe4dxXTOnvZctUE0ixUugoexBHalhYKfzRuG1pJGcFqJniEIpaS1E7bMgBZQMpnU7GnHGLiYQ54qbCjHtHrJQIMrLVnd0I3hqJQVfBJJ6etO2AZ3iflMJhX7OKoQjucQJWKZfj+WtEYcyDG9caiioR/AuW1bwSeiOdlNJH3itOgzZtOaofO4SD4/TMGHIixNQxkrGrTzNNOGrQCunKSNOhmoGO60egmrRScxLRwD64kiOCnkNRXCIBS/D9OS7YmG+cywpzwTLXOa58K0HLaN/LSS9E5dOdLaksdwVEtaKIqkL8xO1KZ/EBHqeDTjnra4EJ7PIFvOfQRL1wY0+MbhF4Y4hCvfGpIFbVXL96wEfxIaj+W2OU61AT6clzyow6Pw6FY26lAoHLp9LH+yTvQOXv58b+oqbukslhoHv5lukb1u/TGUXwOTlZhyY7xrM62bTeaWYlHflpLerB56kxJBbazqpb7crAQX3Ar0y/SJMCtLBmLpcrq2gF/v/cZza9dsxe00jnO35uUGg8St83h9U689e0PCa6UN8evHKNSGx8dqv1kWvXHw5ZGVWuHJH3XTWomDZxCyaErcbEZ9dYGKIl6enrHd22K6mNE4z/7+DufjCdY1XM8a6qaCMiS0HodhmPc5vTpn2BvibI21jqoqGS1mVJMx1ntOrs7ohwlF3aCdYX93l8vxiKaBSVUR4BktZiRhwOn5MZ0k5XQ8oRcGqCyhLGtG1lCUBa4uqHFcTduqFBUyLioOtroU8wanNaPakhQ1ZvKSJNScXpyy3e9xNZvitSXrZhSzBbWH63JBWNXMFSTOYLwizTuczOYMezlNbXFaMa8N9WSCKUsC4OTshO1uj1mxQDvY2R0wmywoWo1L2NSYckpgPeOiopvnnI+nbPe72MbTKMe8rnDMaC4rXACn5yd04pymEcbw7v4drkZXGBVQVBWxB784J4w9l5cX9PKUi1lBnkAedpiXC0a1YUGFKQsa5blsCiLrIYyZNxV3Bj3GiwqU5rquKZ3HzsZoDUdnMk8XsxmhgmwwYDadUDhPiUNVhsg5rJYKCZRQ/T/afawgyaFpFAvnCRwEFezFMKstsVfCyjkIU413jmnTWnxbSV1kORRzTxqKV0SmwHQUthBWQmmx/x7GUHtQVoJq5SCKFD7wzFszk8BBx0KnA9OFJ4kUC++J2wjpK8/EipYjrWAnlhREU0vaqvCQhwoST1FIsFUOUiPC2XklQdBoOQcyKQuet5bqaSFpiySCRSHgo3CShgo6UC48tRbAFJcinC0aGbeK23EkSP+SUgShSavpyHMYz6XLbuVFh6E60JQyL2g55k7SzpMTMW1lZDwEwr7oNlDmDrIuTBaijalbHQiZwjaeiTj1k1RSQaQCoBJQUjoxbXMpVCUU3oOVe7KTwLSSiqVSOQIPYSfANZaqbnvDlOIJEsQifv3/iY/HbY2GWAdvroZv0vKbRlvr/fLnTW3s8bdAyBvSLpuplZvvfcP7/NJbYsOtc8lItKyEbZmJFaNhN0SsdunwuSFw3dhb51rmwa6YiMY0wlxUNVVVC3NRVhRlSVkWFGVBWZSrfbmxL4qSoigoioKyLKjKJfNRU7VsyGaqxViDWaZW3uBO+qaf243rXp/v7/m5BcZuM0uCOzbAxzLdtZTY3vJt+fvenFdclyWVM3zwwYfECSyqBYf7B2TdjLmrGU2nOBVwfHlBWTq2tg959/135H63lntvPaGylnFZUFYVhobzyZiyrvjo8Vts5zHzcsEg77Pb26bGMFssqJzjaDxiWlWkYcSHH7wjLonWc+fwPj6MKYxjXlXUYcTxeMKiqXjvzgEHu9ss6pokCBn2tphaxXReYjxcVZaLqsJ7+PTdt0lDKIzj7u5ddBgyLwvG5QIIORnPmDWWw51d7h8cUhhDaD0PDvaxaOrZgsYYShSjoqAxlg/ffZc0jpk1DXe290myDtPGMJvN0VpxdjVmXMzp5QPeeeuJUL215e7hfRoNZVGwMIaFcZxORyzKig/ffo+trS5zUzIcDunv7DIzhul8QeM0J9eXzKqCOIz46KOfo6OYWVVyuH2AiUIWjWHUVDRBh29HY64rw+O9O+zudCmNIY8itnf2qaOI6WImzcTqhlFZEKD4+L23CSLFtCi5v3uHOAxZLGrKokDFKS/HExbWcdDtcZD3MV7ar3fTjhhFeaG+f6zNA5MC5o3nXpZgG+lGG1tNYxSF8VyU0ifktHJcl5Cj2YljKfn04MqAwkvVy8hIn5aLqWfawN0sRlWKwgGNdG2tHVwVSJMx6xnPQRnFVhzjGgEPpgqoHMwrz3UFqj3mqIadKCQy0mDPNiK2LByMyjY9oTyXU0nr7OcpvhFxKIUIJwsDV6X0STmdeq4K6ChNagMpFvBQVXJus1L0ElXgOR8LQBkmIaaQY/pCKkQqC1dzYT4uK2n4FnlFRwV4K+m8ci6C1nnR2rxHcD0RxmgYB/hKsfDgqvbzLYwXApJGBq4XMk/DJAYjDrCubM+pEp8RYjidea6qtk2A0VQtiKkrtZr7UsEEz9XCY6znsJPgGqm0SUxAYxVF7biqhCE6mVkmJeRBQOxC8JIOsk3rsvoDqZafDOOxXOuu17zLVbESpsOvQozw6dqvmI414wGg0CvzYTZW1TeDIZt7lmmdm7qON4EN71mVZWwyHevKmFtGYCvR5ea5bqZxNmPpOpg6356RY1WBY51ttRcGY9aAZCUKXX7WRtO7dfVO69DaPr+RXlrmpthkdDbGvEEpfN93ovK0bqm3gv/yJbUxzz90sM2Jkcn54d/5Eb+wtVakWcrHv/yYz//ma4r5nH/yj/8D/uIv/x+8c2zv7DFuDLYuiNOYdx/d5fJyzOefv6DT6XD37h2++vprlFIMd/Y4P3tJ4C1xFPPHf/bH/Prf/g1FVfHLT3/JF19/gZnVdNKcLLTYpiaNYvYO94jCkK+ePsc4+OSjj/jsiy9R3tPt9PDTERhLEkf8yZ/+kr/6N7+mMYb3332L44trzicztFb0tWZqGpIoItnZ4v6ju/zuy2csipJ/8IuP+MvffkXgLf1+jh3PCYwljWM+/qOf8bvffklzfs6dgwO01jw9vwSliLs51WyKto4kS/nojz/ms7/+gqIo+NNf/gn/7je/RjtHb7iHm42hrujGEXc/eMLF2Ygvv/6aPMl48uCAL54/QynI0g7FYkxiLVEU8cd/9kt+/Re/papLfvlHf8TvvvwSWzfkeR9jYhpTkcYRe3d2iMKI3/3+97im5tNPfsFnX3xO4CHPu9STMaZuiOOIX/2jX/JX/+7XGGP48J33OLm64OzyijgI6Cc95qYgCxXJzhYHD+/yxdffURQlf/onv+Lf/tWvcday1+0zn42pm4Ykjvj0k/f5ze++xkxn7A4HVB6up1NaRv7HZTwQsvheB16VBhQcJhFXtcF6SZdsewhr8Foz7MC49kwqQxjAbqg4MfLdNdCiMUBJQ7mHfc/ThSHwrZuodQIWlPhBJAbiQKESD8pzUhuCEPa15tQ6IqT6InEQGrEIv9P1fLuwxA56kUY7z8SLh8hQiw6lQYSWvRiOqgavYT/UXBiH8sKM5F7syL1W7Gael6VHG083UmQeLpwnQnxIlJWvo0kABzm8LBwEsB9oJsahaZkFWj2EgiiFufVcGCcCVKs4w5MhTrGxAwxcabjTgReFI8KzFWsKI+aLtPOUG2GSbCzx8KwyhCEceM2xdaTIdUqcuMYaLeLYZwuL8rDdtuK9br+Ht7XoQIpAQGI/hqNKrv3dOOG0qYnwqwqmxIheZTfzHBWOmVV0o4DMw8xaIn74Hv5B4KGUegD8K0RU64H/1Xv/L5VS28D/DjwGvgP+c+/9tZLI+S+B/wQR6v659/7f/21u+jfHDf/afzo8yimc8tI627eUu3J4pXFKLr736haguLUiZw0+NnMobwQezrVlnBqcwyu1Fly2/hwrtsOKh4dbVm28dkZrMHR7ma+W6KulfJblrm4DeKx1Hc3aH8TaGyBnJU69DTw2xLTr870Z179PxPl9gGHlr/YaW7H2Ibl9yq/DlDd8tvpDT16Hq28e19/PPZwmCeW0pLe9w/vvvM1f/dVnVE1NoEOyNOHtR4+5nJXMqjmTccnjJ4ccP49BeX7z+VO8Ken2B2R5yK9+8SecHh8RxjMuj0dsH+wwTPp89dVTZosFAMNeyMP9ezilGI/G2HHJwc/exiwgzwN+89lnNNaSJClRkvDJ419wenFK1jS8enrCgycPCYuK4/NTLsZz8DDsZGzv7XAYhlxNZrhFRW4C+lnCo4NdvvjsC+qmIYpDVBTy8YcfcD2akZuak69f8NaTJ1SjEePplIvJFGMt3bzD7rDL/cM9Ti+v6VhHPZWut28/eMDvfvNrqrpC64DtEH729ttUZUFRFUxORjx+5z6jo3PK2vD5069pnKXbyelu9Xj7nbc4Pj5F+4br4zG7h7ts59t8/fQF88UCDwzymHtbD/BeMxtdsZgtOHzvkGZS0tnZ47e//YzK1aRpQtRJ+PTeR5yfn1I5OPnqBY+ePCCqHEfnp1yMxzggH/a5u7tHEuWcXl/ibE0WZXS7GY8P7/E3v/41dV0RhREqDnn7/feZjUbUdc3JF894+/5dRpfXVHXN1XhCjAgS247zP9p93GYwqBYQYbkTw4VtqJWwB1uhiA9LLatdMzeSZgkcmYaT2mMCCbo+kpX1HMUgVMxmngDHXgRz44XJUGLwlShhPLRWhI0YcHUCx0DBiXMoLSv5PJDvmTHQCxXlwpM4z5aW1PTYS9DrKkklWMApRWY9TQWRsmwHcGHcqnS4G0hqZKLlcVlCaD1ZC1yuvICxANFEeCturH0F8wUo79hXMGkkZWaRShXlYYKkPVTrp9FRntzBtfcEbb4hCIUtmHvx6SgKCJ1nS8HCOhFxt2WuaimEDaQXTeUhxjFUcOodtk3VpSF4AxMPg0jSPIH3DJQ4Qs+czHdHiSbDAmhF5jymhCywbCdw2lTUrVh1O5AKmZmGThBQlYbYe0Ll0VbEtLQ3WvgDxPPfhvEwwH/jvf/3Sqke8JdKqX8N/Dnwf3nv/wel1L8A/gXw3wH/MfBu+/MPgf+l3X/vze5ZBj8JIqvAuIxmbXzxtEoO33ptKC8On5saD6/Ebldt9CKBtXPoayDklu7jFvBwzqG0FgCAW7ESm03QlimVzTLZVc+VW2zB7RQDLQhapRI8eOvwdg0avHcr0NGYBmusmI+1wGNZ8bL+uOXYb2pQbpujqXaO12wLNx6/HtC/n1ZYH4MV2FjtvVtpNVbFtjc+ZyN10rrJ+aU8no10C0s+Zj02tfznzcP7O7+HwaObmtPnr8i6Ay7PrgnigCd7jzk6OeHZi1eMxmMAilrTTSOOX43o9IZcvvqWx4eHnF6cUS1KXn37nKvuRYviYpqzC7a6HWpVgqt5/OghRy9fcX51xaIsCKIYW0OeRbz87hWddMB0cs69/T3GZUU9nXF6ccqsXBArWDSGTm3QdUaQxjTTig/u3efs6JjJouTl8RlBHENjCHXMq2cvidOU6XhCluUc9mOmo0tOT6+YLhopK62lLX1+ckEQpTSzOe/sH3J8dsy8WPDiuCJJErR1LHRK/fyYLO9TjEeoKOSdvX2OTk85PjliOp0QhAFNbemkKWdPj8gGA8rrE+4ePuD86pymanjx6oSL8RhlPEZp6vqMbtZlauYYU/Du43f47uVLzk5OmI8nBFGIqR2dLOX4myOSpMP4+pKdvW3KuqKczjg9PmM6XZDiWVQWF4ZYZ1FJTlXUvPfoLY5fPmM8nlIVFXGSYI0mimKOvn1GN+sxmczI8i7D4TbnF9dcnp8xqxaEDmzppc340TVZN+Hq6prHuwPOrqYY52j4Xsv0v/P7WCFpAEXb06PyxEox6KUsxgWTRsy17mkYVQ0aRYrHeelHstNJMGVDiWNUCUMxwDPynhzpDlt70eztDhLKUcVEiQnYQQh141gglShKSXfcYRrivTjljhpZze8C140jQ7qzVq3p4k4vpJkY5khVx1YIWE/pBdTFSlISaaiJYkU1t4wb0bbsAGMjfWZytdTwQb8TYueWEs95JeAk9gIAUiR41168LnqZopkJALIeDgIZx9LzAiWvd1KNrz1We65qAV4dJSmXTvu4bKtutnsh9cQwReZ+N5RrVLelxFbL73Zb1y5rHZf12mH1qq2+yZTCeBG5bg9SylHJHHFq3Q4gcJ6Fk3NPlGZhHVkQsBUHlPOaghDVGQAAIABJREFUq0YA2B0P48YQKyk7RoF3YjhmKjm/4gfY5x8EHt77Y+C4fTxVSv0OuAf8M+A/bH/tfwP+b+Rm/2fAv/ISvf+NUmqolDpsj/OHP4c3yhBvPlyBDwESqkUhug1DIj5dtmxun/k1tf9mgemb9RtwEyA4JzVF2usVmHDOrbUct6tV2rTGjVNQ3DjuWvi5Tu8swZIzFteIHmTZRG5ZKSPAw9C0JbTrypj1LCqlXku5OGtvVpC0U7p2RRWNxLIPzPL/2wO+4aK94e5qEcCqp4wXYKg8qED+MJRego/NT1C3HvMHHqvXAcbyV/4A8fH3cQ8rpRiVJXENo3JOng8IkojnL17S6W/R04pJMWa4tYel5Hp0wfVkRG/YwxmDncyo65Jh1iVSARfjSx4+fsKLZ88pw4DZbES3t02YZ5y9PCIIFcPOgHm1QKcZ/V7IyeUlahaQxhNCZymTgPFoxrDbpwdcTsZsP7jL5PSckWkYja8ZDrcJopDjkzPm3jLIOmhbUzUNu0nOs7E0SAsWAXmcogLF6OKSrBOxF4XMZ3Pygz0mpuFqUTCrFmTdASZQXFyeM/eefpISOcdoUXBve4dnl5eUJcxmEzr9Pi6MeXZ0QtqJ2FMdJos52XBAQMPl5BrtPVlRYk2Dnc2p65pht0ftYTQe8ejwLsenx5RhzHQ8IhsMCaOAF89fEmURnTSlbkqwAXmecjUeoZUiDkN8AGmpGU8m9HtdBkpzPhmzdWefRXnOVVXhywWDwTZhGHJ09AoTKYZhF2csZVWzu7vHq5MjpoEims7EoC1OOTo5JYlDBt0+o8WMrd4W42rMVWWZlHPyuoNynrOLsaygEWFk+QfMl/5e7mOkH8fcQ+Y8eUdhZp75tJDKEC1ln8tV/bfW0wM6MehG4eYVk1AC+XbrMxEAaGk937WerKuwU89sWjENhEEZeinX7Gn4ui1n7obgI4UtDUUkKZl+IMyBR1bfJxa6ePI+2BnUc8N1JGWxw3bN0kVooIkX0KAShV040dMoKQNVbcloJ4BXBjIPnR5i2LEwzCPwjaQlvBLgMVZS3tpVEA7AjmFeexahAIKua9mXAF5YiBz0MjFY05VjEYvGpSedJIicgKqz9vyzIbgJLOaGRSiszKA9px7wnRdg0o0EEKjCUcQyT72QljWXa3ZqIfeezgCaGbhJyThqS6JbkNVxcIqcU087wkxh55ZrbzFaxunsep5OjICUNIN6AboWPxJTSQXR923/nzQeSqnHwB8BfwEcbNzAJwj9B/KH8GLjbS/b127c7Eqpfw78c4Dd/tYf/lDvN+CERBWHxEFJp7SpC9aARCvWwIRlauM28LjNPKyfc+v5Ot2yZjw8rIFAW3p6s0TWsRz5ZrD0ilXqZK25EFZidcrOYxqDrW9qN6yx65Lctlx2CXhWjquwAg1LHcuNvi52Q+fBmt3QWrV27G0X3iVL8QP3xB/cWgDjgwCl5VotWRC8HPf/be9NYiVJ0vy+n5n5FuuLt2a+3Gqv7q7u6u4ptQYDitJFF4IXCtACnTigRrpIB/E41HbTQQLIg6AFIjACKICQIGhG4FwE7ZBGGA7BGXK6u9aszKrMrMx8+xarb2amw2ceES8ru6o13ZlZ2R0f4IgIDw9z888t3P72Lf/PB96CrzpJYxFaWEiaFzXX77LD5eu7pV7lGYzhtd6AVpzyw+99nzv37jAdTaicJzaefDZl5kq8izDW024P2NnepZNFfP7FXaxz5KMh4BgWY5RXRBiU8yRJym98/10+u/sp+WzMpBD20LqqObMTnFOktUZHhq2tK9za3uHOvdtYD9PzEREwqSZMak+sFNqCQfP2229z8vgBk9GQ0lYYr0iVZlQURN6RxQoXedrtFm/duMH9e59TFDNsbekAVV1zVNW0PeiyRnnHm2+8Tn1+xt75Oba24KUK6ayqKLwjBdARSRzzwx9+nw8//Jh6PKKoLB2tiCrLqR2Dh0hrHIab12+xliruPXiIwlCMztE4RrMROEiUIk4iTBLx3nv/LPc+v8Pw4oK8rKWsQV0xqWd4Z+knEVlkWB/scuPagM/ufkJdK2bTC7EE5TPGzhN5yS6qvOLd736fg0f3OJteoMoa7RUex9DOwHtibTC+pttZ4903bvKTDz6knFnG4xmZ8pTWcZJPia2n1kCa8fa1bSYXpxwNx6LnwN1QIJPP15A+PtNxPOj2pbJsKtkJUeUZG/Htg1CVr3sojazyt1JFVoMqvKRRAt3AOTF1EjtRaslYuZFCXoCZSU2UlpOV/bkX14y2oT5KJPVfbOlRsQChrJa2J1YAWmUk2PJaKoGX0VRcB9ZKFsx5sDhETuqTxE6AkLNgas8YuSYNXFhYRzgqKgU7CagK9ExcGd6LW2OCBJCmTq4P4FoCeQVmKu6fdQt4ATlpeN6XXuJdMkDNJOZi6iGppM3SCQ17oaQP1xLhDUmnQm/ecnLOCwTwRE6CQVuN+6WEKJHvs1pcHbNQmyY3wih6I1TVjWdSK0fVUnhuGKw2sYepEkCwG8s1xZXnJNwn7QMnC4F3xUlasatA5ZDEwiGSVALmnPvq5/HPndWilOoCvw/8Te/9cPm7gKh/nuf+8m/+rvf+R977H/U7nbnF48sT/mWXx6Ki6eL7ebXTL8VwcGnibcADcxdHg0ya9wsQMn8f3C+LLJqmH4Gh1DZxF4utId+aF26bb0vxGnOujwUJWFUJmCjLkrIoyIs8ZKXk5LMZeZ5ThC1/YiuKfIkgTDJU5qRlX2ItrebnWZCHPXFsQ0L2FM6Ry7EsT9+eWnH3iXv3VQEjTWXixr/WgMZl8rZFReDF61fFpzzLMdzO2ty8dp0PP/6A0XCKT1NKB/3t63T6XSrvUJnm8OwM53O6/ZQPPr5HnTtqp9Cx4tVXXgWvqOqKJFY83HvEt995i08/f8jptMDGEc5D0u2wvrkV4ogqinLExWTIjWtX+fDOR4s/vYLdazcwROS1xUSGBwd7vHr9Gucnp5yMLlCJ9LOOI9Y2t1DeUXoHtuRsOOH1W9f47Iv7lArSLBY67e0NojhFOctMOQ7OTlgfDPC15XhyRhxl6EALvbazg1Iw8w5tHI/Ojnnrtdf5+MMPKcuSKGvjlCLp9TGdDr6uMNpxenaEMZ5ut83HXzxCJS2st1gNV2/dRKOobE0Ww/1HD3nj9bf46PYdDo6OUSYRAqpOj/7mJt7WgGeaFwwnY155ZYf373yO9REoT60U2zdvgTaUdUWkFAf7J7xy4yp7h485uBjSiTMqgDRle/sqyjopqFdX7J+d8fa33uCf3L5D6SBtt7DG0NnaIktTWRwoxeHZCd12h8rVHI6GZGlCYWUB4FLhzhj9HCPwWY7jVtZGpTLJOKAKE2lhJBYgDZNz7oGwr3Se3AZLiBJQEiuJC1AxnHnotqVND6jaSwVTJZNUGiwoTstEnGbC3lk5WZF7JTVTjAqP6lDzJU4kewUkYyVW0maJuGrKpWOzlkzwhQdCmw2VeorETEw1+FgsL86HYm3huNpLm15JSutEQaslE7zzoKzENUwIMRbh/1ca6buOBACUgX48V9KXNNwsY2CkhANkYgO9eagHk0uXaYPEusQCEpJEXBzWCWirQptN4IHS4g4iljY9QhSW+KAnJUDCg9TRQVKhh5XouXGjFCwt9JX0x4d6LspLH7wT90rlxII18V+5nvz5gIdSKkYG+t/33v9B2H2glNoN3+8Ch2H/I+Dm0s9vhH0/UzzgUFgUzkuGip9v814sHX0ZpNCk0i6zgDqLCwGezaS/SMN9AtSwsIoA8+8W4KMBMIv00uWslUvgojlH8/nJCXgJmMxBR1VRlxVVUQiomAWgMZ2Rz6bhtQEdQvzVAIa6qgJRmV1iOW0IvRbF2Bbgivnkr5ZdJfNj5P3cBdSkDHs/v6Y5TXtTyXZ5W2JYvRRXEn4zp1/3l4HifPQuQ9DGQhXqC89tWt5/6bivAjHPYww7PAcnR5xPJqxtrvP2t99ma33Aa29e441Xb6JQ2DLHUzEdDtl/+BDtRvwz773L5tYm29vbvPPet9nq90mUYlqJPvceH3B6fkQrS/nBu9+n193gxo1dvvP2G0RNvZ6yoqwsj/ceMytKXnvjDXZ2dtjevMK3fvAdBv01NJ5ZLf+Hw9NTji5OiZI27733A3rdNW7s7vK9b71JyxihjbZQ25qjo1NGs5KtnStsXtmlv7bG22+8xWa7L9oOD9Xz0YiD42MKF/Hud79Nr9Vle+cKP3j7W3TiGOVlEvN1zfHJMcPpjMFgnTdefYONwTpvvPEa13auoFBU1oH1TCYT9vf38dbxzjvvsL62w+bmNu/+4Du0Wy3wkNcyro6OjhhenNDpdXnne9+n2+1z/fpV3nztdaIkwXqP8jWz2YxHjx9R52Ne/9ZbbF+9xc72Lt/97ltsdDoSka88aM/p+YjT8wvSLONb3/0NWmmLKzvbvPP2t0miGOU8RIbKVnzx+BGTyZTrt25x7darXFlf57vvfIdrW9sYhOHVeJhMhhyenqF0zOtvvE4SZ8S9Lm9du4XyYrb/KovHsx7HimAyt9DOIlrrHYyHmxsp11Mj9UaQSc4jMSsWxZXtHjMT0VHw/ataVunIpO8BSolDSGNDa6sLTii7X+kFanUtE5z34Gey8l8fZJRpTAv4zo6s4NuI1cUjaZtlDYnRDHZaVJUEZ742ELZUH/gplAZViNVl0I2w3YjMw2ubQm+eegEStRcQkZfiDh5sZeRe0dfw9rYwkIK4IrwSS0PpoJsa6CWkDq51YSuRY6exgAKF8Hl4pdjYSKmUZgC8viXnNsAokHdFdWDOjRTJIMFZ2MzgWkfanGg5J0pYQmug2zMUsaYDvL4ZmE+RY8NQprKSMTTYbFNasWi9taGIveh9RrimPFituim2k5F5eGtbsW7E/TTVoicNlIUE7q4NIsqgp90NOed6KNT3s+RrgUeIjP494CPv/d9Z+uoPgd8O738b+AdL+/+6Evkt4OJr4zu8ovCa0hkqb6i9xnoxtXoMXhlAo5QRNwAa7TXag3JOskysxYVS1a4qsWGrq1J86A1h1qXaIG4ptkTNAx/RCnTDDQFONZToHmsdlbXUzsqkqS5XrW3K2c9jLKyT7JOyoi5L6rLEliWuqqRfYX+VFxTTGflowmw0YjaekE+mFJMZ5WxGNcupiwJbVvhaShZqD5HSRFoTGyObjoiNIdKGyETEYUvimDROyJKUVprRylqypRmtNCVLUtIkJUkSkjghjmIiYzCNC4bgzmjcNsvpw0sxLs4+AezcgrisAS3eLsCR3BM7vx/OW/nslzYn5S2bzw4bQIsNYEVg6wK8PP8xrDxESMpfv7fBBz/5mO0r2+x9ccDZ0RnKCb12GsVi0YhS0jjl0eER5+enXL16hT/6P/8YGxsckiGgvRA1GQVX1tb4yY9/ysZmj0le8un9L+bj1ZuEqhLXgtGacW55/PgxV69f4x//yZ9iIyN0zgoipYi0JtOGtU6bH3/8CVk7QWcpf/bhJxTGSPqflnvdUoYE6EcRX9y7x87mNu/f+VRWwCDFCC14r2lrQy9JePDoEUop1jfW+eM//6cUUUQMUiHZQ6oNGYr1bpv3P/kpg41NHu3vczwcYpWsmGKlcN6TKE0SxRydHDOdnnH15nX+6P/+h+gkxeCJFFJMUUckCq5sbPDRB++zsb5FWZR8dv9zajwGhSbGe09kYiIdMSsq9h8/ZOvqFf74T/4UlWbBUiQp+toJR8Vap8tHn7xPu98na7X4s/ffp4oNHk+sAOeIdUSEJ41Sbn96l/Uru7z/0cdMtMNpqWsRaQO1BFmuJTGPH+/hXU2vLbFA7muYS5/LOEbM+ilgI83BcELW0+wPa0ZO42LopbLCzjxsO8AohmVB4WviNny856hTsXYoBCD0HKwBNtbsjyckXbio4DjX1EbRSsQNknrYtJLdknvHuKpIO3DnEBnAgWEUBy0L2x6qSLM3LiCTmi+Px1IBNkkW1Xb7trGIKIazmrgF90/BxcLI2QRIZk7qvFRGcVqU+NhDAp+dSo2UKA2uFx8o4BWUseIkF575g1lwRYRaJTboctODM3BW1cy8Q7Xg3olYWEgWa6nUShxHHStOZiVRJq6gs1LcS4kREBF5qYfjFeTeM7IO3YHPzoTES0fB8uHlfq4DVaw5nOaYVNxSDy88ZSyVbV2o5bJuxSJiNRzlOWkP7p16qlhDLBYg5SGz4nLzCi5mTsgfDZyeyXVPq0Wow9Ofl08LELw82P8y8EfAT+V2A/DvIb7F/wG4BdxHUrhOw5/jPwf+CuJu+hve+z/9qnO8snvL/4e/87ekQBZistJaHpJaK4wCrbxsBE4PL3YRWbnLaliFla8K5nmUF9CiNF6Zuc3Eeb+gIq9rARLL1hHfmPQJIELQKiGugMZ9sxQz4WwdCMFCZssS/bit7TyYc25RQCZwW112fYibpMRWFlcHi8XiZsyDN6WpZqUPTSru5VoyiwiIZQ+EGDdc883cdbFMwLWIa3mykm9gSfULXTUxMUopTKjKqbVZxIk0wMwIOGs+Ky33d65r03zW8qqb6r/yWX6j5zE2iwsi3Bt5+7f/lz/4M+/9j57nGN7dueb/rX/136Tb6Unq2dY2+wf7WKdJI03lS27svsLFtGR4cYKtLIP+Oq1MMxydURSWfpJQlDNMHHPjyi73H+/hbEUdRWRxytbWBg8fP8JbTytLyYsJW1s7OK8YnZySK89adx1vK/COST4lUgrlJHXwxtUrHB4f40OZ8STN6GUtDk5OKKxjI4rJbclgsE5sC07GObGJsJHGek/aShldTIi9I4k0k9pxY2eXs/NzaluBq+l0urR6LR4fnlJax4b3VDFESZtBO+Pw9IJEa0wUMcGztdHj6OgCV1VkcURZV1zducpoPCLPS2qr6G4MiBUMx0Py2tJVmspXqCjh+pUdHj4+JlIVtdf4pMPVnR0ePLyHqxztOKI0BduDq1RVzWQ4ZOwU17YGTHMLvmQynZFGEZUr0XjeuHqdh/t7WGeJcah2l81+j3v7h1hr2YgipkrT6/dJTcr+2Skey9qgQzGr6Xcyjk7Ooa6Jk4i6drx2/SqHBwf4yuJrS9Rp4Y1iPJpQO+FsMDTpkfAf/Nf/8aUx/LzG8fWdXf+3/rXfEcuGhUEK+5WscncSxaj0rMWy0q6sIsaTO2HkTBzseWHFbCFl1m8m8KhUrIWAvKmVoNELJ+b4nVSRF57ICMPphVP0lNQoqb0ELz70QqG+buCwhusxnNQSPxTjKUKhtpmFc2A7A1+KO2FTw0Gl6Bp5VpZOAlj3nACRjRhOSiTF1wmIzbRnVofKtDUcemFZzRwMlWT0PK4UXSOLgwq53uNgidhsCSNpO0z+hRPMVFgJiFVOTFJrkVgnzpxc06NS+oYXN1HXyHXWwHZLyMuMkcDOYaVo4anDFNBC9NTWEstyYuFaDEeVgIXYS8xNx0iV2TGwk0pcRqXEQnFYiNXCWc8MGETwOLh7tjLFae7ZiYVUTCHjdFbLIqVw4irqaQkonnj4r/7H3+PR0d5T7R4/T1bL/8vPdtf8i0853gP/zte1e+k3KGpCuLBqphBwSGl4wicp0RYCKFEBaDRm+mAnuxS/4fGhWfRisvLwVGIv4JLho5nMF1aRpYn4Up0YN/epN2cQfBHAha3nLKeNGwM8OAIXR9iCRaQuS7HM2ACkAtiYp5OGIFDp4uJ1mYBMBSDRXMf8982k7f0T38/n7zkweRo7qa2FGmZelsU7vFfBMaYWoOJL6blBPQHUCWBUC6gfFC1gyOHRDU8bCoH2PqjYXxqOTw7NLw/V5zGGFYDW1CH7qcwrajz9fo/JeIxSGXc//wyddWgnMeNZhYkq8lJR1ZYo8pgoIZ8NybTiJ3c+od/pYgPotq5kUhQBsPSZ5TM0EQf7h1g87XaHejJGk1MGFl0F9Loxx6cjekmLj+/fp5MmaGVwtSeKakoEPGdRTKFqnPKcXFxQVjWddsY4L8miFrVzJFUNtqbXTjialrRMxJ3Hj4giQxan5FUFdY2dSnB1K4qE1jkvSF3Bpxcj+t0W47IiMQbvLLPc4WxFp50xmknxuvuP99AKslabsp5R5WPqJKNyjsRERJGwq6ba8f7dz+m12tRWUt5TCmbljKqq6Hfa1LZGE/P4YB/vHN1uHze+IM+zeVaZRtFqt5mdz2inCT/57C7tNEUbRV15OnimeYX1jna7TY2izkvOT8+Y1ZZev8tknFNUjspbZpU8D9YHa5wML8jimE/u3SMymjiKqcqarLbUsxLjHJn31MgEo5EYhafJ8xrHEy2l2iMl5c1bTibB01L+eYde4h+SUHm1QlwbxssqWCs4L+X7z61MMqdGoUsvcQFAbGFXw6jy4t5QwsaZRopTCNYumTAHTto6K6RGzEMnk3cZS5vOi3sq9rCjJD7EOfARPK7FQnKhwddifciRjJNWHNrUcOLFvRglimlIv+15scDsIJPptJa4kntWgMTQiFvKeMCIDtJImF81UkHXVcLTMUOemQ4BG1vh2XZeSMzIg1raGRpx4Sgk5iLzkpUyLkTXhYJRKUAvR64pUQIONr1YR09LoUF/FLhD6gSowvmVtNlRQr1eWrG6PKwh0YoT7XFVAHIO+l4Izs6nnljDvgNVi1WlsBLn4bSAzk1CgKwTnX+Vq+UbxFzaTCvzHWKx8MsTol9MmnNLzVdbbJooATleLdrxS6v65UiSBmksBy0+5UzeS760DX7zJgbEPeFGmFOj14Frwy7Rizu/oFEP7QCYKCI4lGTSbvrV9EkvgYtLIKMBbmquygaINO+/fCyXgEcDsObcIbapDbOoETOPoQlxHywBOPVEZgxqYdW4ZO0I+wVHBWDSWD+WrSAs7sPTb3C4r/MOfPV4eFai0GAd7W6H7a2rfHz7I9bWBsSqBgNl7YiVJzOKyWTI2loPZ2M21zucnZ/Qa3fodXtcDE+xNrjMoozR5Jhr166x1t3k/uP7tLttvKvpZhn5eAIo+q2Mma3othLw8Oort/jxhx+w3l+jm/UZuhHOOjKlabd6HJ6fsHt1m42kxclkQpy1ANjMepycnWKVJk0SnDJYY8jSlJtb23z06W36vQEmjUiLczSKFOhlbU4mY65tDvA6QscJZmzwxtDrr1EUh2inaQdLWFHnbA4ytja3+ejuXbrtDklk6NWeqvJE1LQ7bYazGev9DrGOWNve5O7FOVk7pd9fZzqZglN0jaKTZhyen3DjxjqD/jqff/GQXl/iCHppi/G0QPuaJGuR51OyVkqN5tYrr/DTn/45g7U+WZphnMPX0DKaQTvji/MLru1usxa3OJ9MaKepkDB1uhJn5SFLE5y3YLzEbbz6Gj99/59KmnKSEqshUSmzTDfNOJ/OuDUYkHuHTWNm4wm1VqRxhJ/MfiboeF6ivGRNxAa6nTb7FzMSY4i1J3GemXO0SzHPH9WeLa2wRkEacz4piYwidRqosbVkoNiWZzzzrCcQpRmHUzkO5TFeUXlLq5TMiBMcPQdOK9JOxulwhonEte6psVZAg07gdObYTEDFCePKMlOeJJB+Fc6RlZJWOjKeuJLJsNXNOL7I0UaD9xg8pYXEQjuF48KxFUEWG2qtGVmLBiIn/UwLST+dpR6XCxBKOwmnoxKtDc5atJXg21Yh7p5jK24mbxQ6MQxnFrQiquWJ6yohI7OpWDW6MURJzDCvaUi4lfNMQ5vrMZw6T9eLnpJWwsW4QGtNasUbUNcSD2NacJKLdUUnMePaUWkntW6sovaOpIRBDGPjSCsBIr12xsFFTmyMuHtxlNaTWkgTOC5h20BhNF4rSuWwCEmZRsDHVz2KvzHAgwYIKMJ6N+CLxuLgPU0JeoK7pQEUC8vHkqUjTKPLWSrNklraWw5sDBpaSu9sJjv9hFl/DneCm6WJbaA5azMpB3BhQ4BpbYP7pVoEXzbxD/O+OLHVGWOITExsIow2l6wvy+6QBSha+o6FFSQcdAmEzNNnQxxKs3+htSYLaAlIhWDaBfAQAGWDVaTRR3O+BkRqpUERgAYLS8gS8JhfTgAeaMRFo5ZAyLL76GlDxy/dmRdUnlYbTdzO6PTa/PT2+6yZlN3BBj+58zGx1ty8+SaHR4/JTM3WzZsU5ZSL4Tmf3n3MjZ2rVN7z8YNPWeuuMVjfZO/RPXpdjWJAf9Dh9p3bpMawe/06n352B1vV3Ny9wXgypipzru7sMMrHeK356IMPuLq+TtpqcfvB53SzNhs7uzx8dI9M1exurrMx6HP7zn1aKG7euMm9gz3uHh+xvbFF21VMx2N2Nta4mBnSdotP7nzKoNNl0O1x++F90ihie2eL+ugYZXOub62T9Trcf7SPqmp2d3a5mIx58PgR7X6fThRTnBdstGNSOnR6XX76ycf0s4yrgwHv379PrBS7V66hzk/xtuTmzhZOw/FwzPHHH3P1yi6l99x+8Blr7YytXo/DwymtxLE9GNDpdfnwk9t04oSb11/ho7ufcF7V7F57FTMZ4eoZN25cZzI6x2rLT3/yp2xt7pBlKfcefEan1WJrZ4vHXzxA4Xh1Y4PBWp+PPv2cBMWrt17h/sEBd/cecvXKrjBTnp9wdesax2eKVsvw/oc/Zr27xmBtnc/ufkyaJly7skO+t0fk4frGOu0kZe/oCFPXbKz3OJ0VDCczNGK+fpHgQyuJR8m052Aypa+hH2sOi5LaywSWeLEqXGvHUFmOak80K+gnCpzi1NZESHGzSQFprYhSaBnP3iynB/TjiOPSUeLoGlmBz2rYaWnK2lHiKSYzupEQXx02bYZU08jClZYmUo79vCT1sB4ZJtYz8o6WEs6PqYXtSDGN5Kl0Os7pR9BSmv1aWFc3klBOvoRrLQPeclRaUiyDSFM7xamzJMBaAtNSKM+LQFl+PC7pK+gaxXHIBhoYmXhdCbstqGoYOk9U1LS1IgKO8WQIkJhVkFXelT3gAAAc3ElEQVQCFGLgMK9oe1iLNReVZ6aEN6WlJKB2t6WYVZ4cz2ha0DGip/1a+rmeQF2CLmAnE4v047Ki76Eba6aVZ4ijqyQgd1LDZqyZGY/XnrNpTjeCrlIcVKL7jUQsOK6Ca5kC57moHYmDTGksMA7zQPI1j+FvDPB40n7hlzYaAOIbc30DOi7bHX82wFpAD+aBj0+xdgDoxhrwxET3RCyMD3EiTRxH01G3ZMWYWzZo0mgXmTVz0KOYB28SRRLbqg1JFJPEiQCPeT+CxUY1Dgd1WQHNUU8Cj/lP1RxUqWXgMdd1U5xvwZYqlW8Xhe4WZGWLWI8GdDSEaS581oFPZBHHsYjfgIWlgwZ4LFtpltwzP8vY8U2S2lqSsuR6sgZXbqAjze3PPqXTajGdWR48/Iz33vkeh6MRjx494urONf7SX/oWn3/wgMPzY4qywBjDeDomMZ4f/eg93v/gQ5SO6eoO33v7DerC8vGnt8laGZOq4vHRHm+99irew2f373Nta53vfucHfHj7NqUr2D/YJ06kCJo9fMRvvPcun376OcVszEZvwG9+/4fMLi744PO7JFmGAk4uznh1Z4crO1t8+Nk9Bv0Or199BVvUxLHi4f5DkjShKCseHB7zg2+/xuO9Y47Ph9ywin/+3e9z7/FDHh0eEkeGWimG4zHpoM+3v/MmH93+nHZs2Mr62N1rJEbzyYMHtNKUWV7w+Gif7731JsPJhIf7B1xd3+afe/eHfHr/HifnF1SNnmYFWo9494ff5YNP7qKUoq+6vPvmt3BUfHj7Q9I0Y1zVHBw+5FtvvI3Dcffzz7i+ucN3vv9tPvzgNmVdcba/TxLHTPOCvf09fuO9H3Dnzl3y6ZT1fJ3ffPddxpMpH9+9Q5K2AM3h8TFv3rrJtZvv8OOffMDmxhbffvNNYiKUMjy8f4csy8iLgvt7e7z37e/yYP8+hxcXkK3x7muv8+jwMRfDifDZKEXhxZXxNdxLz3Yc46HyxEYCSI2G/bwiiw2+tJwEYq44haNJzbqBvvMUBmzlmRhPhqLCc1AK+DitPaaGViJtRgYOipokMUSFZYwETvYzOModHSU06meBZ+NQeVpKU+PYryQuYwT43LEWCwiJNJyXFpVoOqW4IU6sAIWD0tNR4jKYOEDDvrN0jMLVnrNKYkisgXHuWI/FveSAiXPYSNH24go7riTu5aDyZFYmbRP6uVfVdCKFq6RibqzEOnBaSLZS6iV2o8YzNNB2Uun3tIZeDKcW4lxo2VMnk/NR4UgTTasSVtFSSXDvXu7pq0XasPJwqBwdrbDWcxoyfERPXsCWA2XgonToWNqceQksXW/Dfu5peWl3jLh4Dq2lG2mq2nFWyX2pDIwLTy8WLpTCQ4XD65DNA1/niPj64NLnIbd2X/G/+2/8LlEIJG22SCui8F4rMMoLEyYSUCqbp8lmmL8H5lOpkqwYz4JxtAEN8xTRZqJdRjJLwGMRy+EXFoy6pigl/bWq6rklRmI5JEtDCL+Wsj6atNcwYeNkUl3OijFaY0xEEickUYwx0ZdcPV4Ju6niq++vv/RuOcD0MqhajmO5TDj2BPCwl10t9kvcKT6E2fjQ7sJqJK4UvXAboSTNrdH5MgCZB5VettIsW6IW7p3GzdK4ixR/+3/9n74UmPes5dbVW/5v/Mu/TeY8WavH1FYk7RYez6i01LMxznvWt7dxtiYfTYidpZ0OGJcjtvs99iYjvFOkdcnIeV67cYPDgwOMd7SijBKPSjRJknA6GuHLGoWn1enSzmLG4zHGK1qmzaie0um1GVU59dQS24qph1ev73J0dIyxlsxkWGNwlCSdDmfjc2zpMd4TxTG7a132z85peTAqYaY9SeSodExdSAB0CdzY2WQ4uqAsLF1t8Dpi6io2eh0OxiNc5cm0YoritZ1N9k9OSawl0wlTrUhijVOGcVlAXVN7z+b6gKoqyGcFHRSRyZjakl6vw0k+RlcOVTsmwOs3r7J3eEyMoqVjCjwmVmidcDqdoqoacGS9HlGSkF9cEHtoxR1mdUF3vc1oPMVZjysKcuC161c4ODomsp6eSSkjjfKWtNXhcDTGuhrtHCQpG4Mtzs6PiD20OwMm0wuyzIgPfDYVym7g5tYGw/MLrLXEKEwcM6sqOmnEpKglqD2M5P/oKcGlz0Ne2dn1//a/8jtkgY8hV8hkFkdUecUQmYBf1WKZOXHiTnHhGZ3FhnHtKKz8P62CV5Gg08aiUygJgiSNKKc1Q+QvvBtYTPesuB6cD/EDRlMCVeUkqFXDqwqOvcRytICZCmRaqaHIBcyAsG2ue3jkhcxMhd+3lLiIqtJRht+/Gngvpi4QZSmxMESxZlo6Zl5AoTGw4+GxlxRTjfCctAFnFL6U4MxCwbXA3nrqhEG1VBIHotFU1lM6uee1EWa3Ay9ApkmH7QE2MdjCMvai86vB6rRv5XunZGHe6MlWQr1faXhFwZEX10dzTV2A1DAr7Jxvo2tgA2FY7SBzbqmEoK82CldKm7mCW0YI0KYhE8YpCWD1inmF4gr4L3//FwgufT7iFxMfSy6WZVcLS/EefmHQh+BLCtVim/ZgsZJvwkea7+fpnoG9E5pV9eUl9hx4wHyiW0ywTaqspa6rACaYx27gGsuGW0ym2qAi8F7PYxO0UkTGoLUmMhEmiojj+JLFo+nEJSfSEmBsrD9zjSwHzTY6e0LfzDW02DN3tczru3icsWgroMjqkCrsHM5r9FJWywKsNG6spTiNJ8HD3PIyv5kigfmm+c0ceCzQ4JeuYH5zX7BYZ6WcebfDWZ6z0VtnfH4sVqEoYqPdxeU5ejqjdg4TSw5dSU2kNXunp1Te00pj4k6bzcmE2fCCylZk/XXOR0N2Buucnp+Sj8Y4pVnvZPhKXHiVram8RseGYW2Jdcrw9AKLJzKGbjsjm5XkFxOq2pF0e5xPxmx0NphcjCnyEqs8a4ki8REVnovxjApD0kqYFBW9NON8PEL7Gq+hH8tTtRhNsaXDtNqMipJempJOK0bnQ+EZ0Ip20iItZpyNppTOkXZ6nM1mbHW6HF1coJ3HKUU3S1CVxRUlZVWhkozcWkkV95qzc7kmbaDXSoiLitH5mLqytHp9TiYTtvoDTs5P0W6KU5p+1kI5i6oc3uVgIkwSMyktxkQcH5+hnEcZzaCV0corZqMZtnKkvS7H0ymb2YDz8zOmeUENdGKDjlLQCjsb4bwj7fYY5hNarS4Xw1NwDqMV6+2Edl6TT3KZTbMWeZ7Tjz3GwiyvABn+7ZB18KLEIamaUxMCO3twPPRkZcVUQycSZtKJBW1kBX3qYCsL5e0LOy86tpmBz+FciUVipiVLZGcABxeQ5fV8wl5XErzptFhZzhB3QaQlXTMygTI9haQQxs1ISz+HFq6swfEQksIKgZmH7UjcImMtGSpjJ4Cn3YLTsaelPKWWgmrrlVyTCpaPCwtXenA+BV06agNYcfWUhQSOppH8JgEGfTg+hwxpMzaw4cR9FBkJIB3VsNkVVtBZ4TCxcHGshyycoZcg2omSoM+dARycQVZaCi2T9Y4WtwwaogjOnWTcqKCn1AjgGWRgcuE8SYwQmQ0tXOnDyQiiwpJrCWjdjoX9dRzA41CL66udiZ4SvBSpS2CjFLdMFAHiaWPQg+FE2lKp0MC3f5mU6c9S5m6V/x/7vzzdqC8dId6ty3ufdJs0gEOwh7oMQubI5TLomGfFNPvmzKSNNSMwbaLm/B5iQw3ZHKF5sXCYuaUjimSLo5jYxHPg0cSiuGCxcQ3YWOrD/BqXXR8sEaMt/+bpiISgAhoLyZNxIU47yTRyuqnWh8dLbRxtUF4KRs21vwQi9JMxKE/giafkGL004pHru9pN+GI6Y3R2iAYMilarzeFoSKJg0yTgFL1uB1OUnFycg9G0vEdHEVoZzkYT+loCtZTW7Pa6PBhdcH56Mq+6POi0OJnOMM7Rz2IshnaSsBUbvphckCtIvafUmlaWcjiZirnXObRSbHU72OmY0fkxGk/qIclSxlWNr2v6RqNjSCPDtVbK55Mpk0lN5sXi1mq3ORpPaClZKQGsd9rUdc356AKUouOhlcRUwEE+ZSNWpHimWnO1lXJ/MmF0fk4LqFF0O20OxxPhPYgjKg+tLCUqCk4mQ9CazHt0ZDBJzNE0p6PlOpVSXO12KCdjhmcnmLA6zdothrMZkXP0OxkeQztN2UhiHoxOJBXSe6zWxK0WR+MJbaDjJItuq9fmZDZjfHaKUpB4j8lSpnWNrXM2WikOTxonXO32+HT0mEmRk3oBUv1Oh6PxmBToYvFAP4moC8V4UhEJPQI2WBDG9utLij9LcWFVvR5DkUM1kv55B71Ec1pKtlSipKZMFAf2y5lMRh6hKjex4jz3dJWkxU68xAjkNczOxQ2hkUJ0o9pz7kPKqRO+i3UFvgCvZWL3DrJYMco9XQQgTS10Upmkp+eS1tkUYyu8cF+kSgBRicRd1BX4ibSpg/tnHIJqNOK2yCI5Xz4U64YitKthWITCbMi1rEXCBlpfBD1ZAQ/jirnbbBZYTRMF5QhUJJO0q0RnF7mArwqp47KWiG6LM7E8KCcgZ2plfMRKiNG8Fip2mwu4SbxQxrciuJiFQntI9kk36KkcCrAzTq5j6iWzJiNQxmvYNEJ4ZqfhPllopYqLXOryeEIabSx6m1yInrDSbhS+/6qn+c/FXPqsZW4pb6wbl6wcT9sIFg61OD5YKuaT5ZLtfpFiejlDpQEhyxOsfiKzYj4pzsHFgqHUhwde06pYCez8e7xYOuIoJs1S2p02vV6f/lqfwdoag/V1BuvrrK0N6K8N6Pf79Ho9ut0unU6HdrtNq9UiyzKyNCXNMpI0lS1JieOYaL5FmMgIiAkWFHk1l8nNdAOoGjfJ8uYvFa1bfOZL4OaSzPXX3IOGVG0pkHROrBa2pZTbL20/04Kx6MvPHEcvSLx3bLQzHhydy0SUZRTG0FtbwzgrdMtacTopMLbCGMXZ7IxWmqFQTE3M6zdegaIIJm7N2XjC9e0r3D06ZOrFSlBrTdJt08lS0mCxG1cVdVHSG6zzaHiBThNaScJMK27uXGE6zYm9kCId5RO2BmscjEbU3tLq9imVokhiNvp9ktrKQ105RnnOYH2du6fnWKNJkojcKNY3B8zKkggxER8VM1pZi2ltGfuCLE3RSjHSmqtra6iqlqBJD6fTKVc2B9w/PUUrmcRnWtNb6wtzJwJsTqtSgGoUczib0mplGK2YGMXulQ2KWUF41nEwnnBlc4N7J0d4LJ1uB6UhabfpJwmJkxXrqKwppjP6a+s8OD4miWM6ScLMGK5e3aacSoBnEWn2p1M21tfYv5gwrWrSTosayJOErfV1TC1kBheVZTIccuv6de48eoBC080ySqXY2NkgL0tMeKAPy4I4S5h5GDtHbGSCGwEdo4mcgI4XuRr0hJTMQvgd6kjM65EBZ52Y1rUwbeaRTOgzK64GtFCGtyPwlaTOugjOtaSuHhdyfBkLnX6l5L/c6KfQMDKy8BnVYiHxkcQMZBFUlRdq9QjOtICe80rGQBVLv3IVeKBCmzaSVNpIwUUt7gNiiQHRkUz0IOcZGQE901rAUh6JJWHmJb3UW6k7QywWmVjDWS3XUUViadDhnirEcjKLpF5K7sSFUxo5ZopkxBB+Tyz91AZOKxkHRUPf3mS2eDl2ZsSKgxc91Vom/gkCUOrA/UEM56aJ65B9ebhPuZL+p15o6+sYToNl6Lhc6KlAwFFehcSPCCZG/vcNrb3TgJO4EBXA39c9i7/RFo+fZe1ovnv69KQuvZs7XRYfnvqbxsixZPq49INlQq1FqfrwfQiSaOqwNNaJZrKfu0/ihDiOiEwk+xtAoJs4CL2I9VAGo7RYbPyiXev9pVTWeXaM15fcHnP3x7JFRClxisIiAeiSrv2XwR7hwJ9nVl8CdqgmG6X5uPx+oWc/P/svR14k+DgdTYmAdhRT1C4AL6jLQrxI1qOpmTmYPd7Ha02UGrQrWetnnI8uUF7Kcs+sIwL29vawQCdrUZU1RkGWZYymci6PrHIqHIdfPMAqxVocU1UF7ThiUuVE3gvZTyXZYkcnJ3ggi2JcXRHj6WQJo+kEh/iXq1r+ASd7+1hgPY0YlY401lTegxWW1kDrwmgyQU8mYAxxIvWie62EUT5DeWHrnNXiVjs+OMF7SNOEsvYkWhHFmtmsJCYQ/NWeqXLkh4fz2CflPWtpxGhaoMI1VeEhf3h4jAKyyFCVNVpBK40Z5zMUwhvhbI0F9h7cA6XIopRZmdNKYya5FKiIgKqWVf3x6RkAkYkoa4UD1jstzseTOW8EtbT56e3b1MBamlKWBWkc49H42mIIdPHAJM8xLpdHRnhgd5HaGx55P3lG4/PnEYXEJChk0htL+Bw+kv2NNcE7ASMqTOZGS0n3pp5JU1vk3Iqe6sC2qZRMwL6Widcyzxglt2HlXMvqP0bAQlhY47xYV86dpPxamIM1C7haYjJc0KVBJuY4PPasl8n2pF7UIXHIan8knHp4I6v2OlxHHrg/6nBNKQI2YgJXiJfjhoFbxBv5bUwoDW+ZA8wKAXXnZcheUgLEMuC0DvESyMTtVKCbD+RoNtybKlxnY2Gw4TfHTZ9Y1JW5CBYIG1wqVsnvfSWuFC+qJlHC25IouZ+Eaz8L3CJKBQ8hcp3GiXKNl/askhNnCKAr+XqLxjcGeDTil16ffL+8Tz1xvHrKd4uIxa/GHV+K75hbOZrXRbqrW3K1yG+XVvZao3woAY8XyvIkJglU5A0leWSiOehY5umYvyqFUWZOn+acVMRdVJX1QsEdftOAhssZOwtw9OTmrJt/f1nvTVbLZevSz3aBXA5Y/ZKGG33Ob4p64vXLhy+/efLzN1kU8hAwGmpXUwGp8hyfX5AGvWbh2CKEIiU4imKCxpNPJszqMamWB1oXWRV5ZLVGlVN6RaYc56enxMjqLzAuMwttp8pTFhNq7zEKjk/OyMJDs4U8FBrQrm1N6SRVbjieinULeSi0wvlzxFydh0BW4+D49IK2l2tqKZmIGvKrGEue52jlmeYl3groqggBc14ejkYjhQxDnw9OzknxFOF6NNKuPOwd+XQGeMrSU02HmHAd2ZKeYgBrqZyVdMXzIUn4EyfhmptjUzxFPsZ7qa57NiuIwkjPQn89MnwNlrKc0Vaei+FQgtiVrEATZKXnkWqhPh/j8CQejg+PCSTsdJHVowsZEKkGW4lPvQJ86ebkYc1E+6LEIhOkRSYiFSYmjUzAje4ruyhIVlWhoJmWGAiPjMk4uDmcl2utAQKonQRWTItM+nqpTa1CkThkRT8MlokpC7CBW3rqVNLnqYcoWAwaXVdhzBHajKQLjBr9qzBBI+6IgAehkv9eriAqZV/hBbTMwjGKUAyvDkDNSj8qpE2PuDo0AjSrABAKQFfhey99qoKemmeJDu6KsQttBt2rZd0rAYQxhMDS4F4JeqoQ0KMJXoFADDf1YML5K7dwMzmENbz2QSdK9BSwhQAYJBOmWfj4cB+L0PGm/1/12P7GAI8meBQVJvx5YGdwp/gF8FBLcQvKgw/cDUot1s9zhgvFnO5chWwQmDthliZCNXcZLPenmXwbevBFnZcQw/FERop49aXZKIoEcKQCOLI0C8AjuECUZh6BsmR+UIhrwsz/1uEQ5+ZtN79Zdok0TIyLQM+FpaQBI3ItduGymuu/sXhcBh6N4htryDKnhlrqr1fCrRJg0Xz/gmlkods50Ft6gfDHWMJ/cxfOElD5EgSaW25epK1DrjXNEuq8pFAQJxFlWaONonSKyHuINBGB9VVriqoiSzR17ahrT2I0tg4gUynaxghQqGtK64mziKKQVCirFAZZwinrSZRCRRpbVKhI1htVbUliQ11ZeXAYTaa1VO30jpl1JElEUdbyUIkMqg65iR4SNN5obFmClloreW2JjaayDu09NjIkTtInlVJUdU2SaKpKxp2JI1TtxBwLtFDYSFMXlZh7k4i8qDCRonYSQ0FkiHwIH9cKW9WoSGEd+NoTJxpXOrxWeK1pAVYpbG2ZeU+SRFRVjdaix6gOenKS6ulDm9bosNK2JHGMLWsiBcpoSd8MBSUL60jSiKKS/4cxhqQK5wc62uC0wpYllQaMoajroCfJxrORIfGKysu/I7eWOOipBkwcSU0i+2LHMQBJRF3VgCJKNLayaKPlv+08Lo7wtcSreKMpK0sSaawTi2ycaFzlcEphjEI5j9ea2jrAEyeGqrLyPNZKuIIig7LBWhzGrDc6TOyOKNZQOxxKxqmrcUrGqXWOODaUlcVrhTJK6kFpI3W88PhIrqmpm2OdwxuNt9JnHRuwVtpUYvVKEkNZORySTeZqh1NaYre8m7epUMSxpq4sOlLyyHQeF0V4u9BTXVt0pCmDnlQserJKBYuexWuDreWcSWKo6zCFa6SvkQEr10R0WU/OO5QJ/UT+z9o5vFJY56mdtFkGNyEhndgZjQ7ZNYR+KqWIjKJ2jsjokCwBOorA1Tg0tVLUtZVrt3JOFUf4uka5p46suXwj0mmVUkeIhfH4RfflBcsWKx3AL66HV7z327+szvw8shrDl2Q1jkV+ET089zEMoJQaAZ887/N+A2U1hkWeyRj+RgAPAKXUn76IvPVvkqx0IPKy6uFl7fcvW1Z6EHkZ9fAy9vlZyEoPIs9KD9+IrJaVrGQlK1nJSlby6yEr4LGSlaxkJStZyUqem3yTgMfffdEd+AbISgciL6seXtZ+/7JlpQeRl1EPL2Ofn4Ws9CDyTPTwjYnxWMlKVrKSlaxkJb/68k2yeKxkJStZyUpWspJfcVkBj5WsZCUrWclKVvLc5IUDD6XUX1FKfaKUuqOU+t0X3Z9nKUqp/0YpdaiUen9p34ZS6n9TSn0aXtfDfqWU+s+CXn6ilHrvxfX8lytKqZtKqf9LKfWhUuoDpdS/G/a/lLpYjeGX8779IvKrNoZhNY5f5nv3F5EXOoafXoTt+WwI0+pd4HWEffjHwDsvsk/P+Hr/BeA94P2lff8p8Lvh/e8C/0l4/1eB/xnhmPst4B+96P7/EvWwC7wX3veA28A7L6MuVmN4NYZf9jEc+rcaxy/pvfsFdPDCxvCLtnj8JnDHe/+Z974E/nvgr73gPj0z8d7/P8DpE7v/GvD3wvu/B/xLS/v/Wy/yJ8BAKbX7fHr6bMV7v+e9/yfh/Qj4CLjOy6mL1Rh+Oe/bLyS/YmMYVuMYXt579xeSFzmGXzTwuA58sfT5Ydj36yRXvPd74f0+cCW8/7XQjVLqVeA3gH/Ey6mLb3Lfnpe8jPftlya/AmMYvvn9ex7yst67X1ie9xh+0cBjJUvixZ71a5PfrJTqAr8P/E3v/XD5u183XfyqyK/bfVuN4V9N+XW6dy9iDL9o4PEIuLn0+UbY9+skB425Krwehv2/0rpRSsXIYP/73vs/CLtfRl18k/v2vORlvG+/sPwKjWH45vfvecjLeu/+wvKixvCLBh7/GHhLKfWaUioB/nXgD19wn563/CHw2+H9bwP/YGn/Xw+RxL8FXCyZv15qUUop4PeAj7z3f2fpq5dRF6sx/HLet19IfsXGMKzGMby89+4vJC90DL+oiNpmQyJlbyMR1f/+i+7PM77W/w7YAyrEP/Y7wCbwfwCfAv87sBGOVcB/EfTyU+BHL7r/v0Q9/GXEfPcT4M/D9ldfVl2sxvDLed9+QT38So3h0MfVOH5J791fUAcvbAyvKNNXspKVrGQlK1nJc5MX7WpZyUpWspKVrGQlv0ayAh4rWclKVrKSlazkuckKeKxkJStZyUpWspLnJivgsZKVrGQlK1nJSp6brIDHSlaykpWsZCUreW6yAh4rWclKVrKSlazkuckKeKxkJStZyUpWspLnJv8fQTrjV6ThiJUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 648x648 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}